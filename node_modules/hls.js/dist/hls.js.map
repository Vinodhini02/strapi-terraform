{"version":3,"file":"hls.js.map","sources":["node_modules/url-toolkit/src/url-toolkit.js","src/polyfills/number.ts","src/events.ts","src/errors.ts","src/utils/logger.ts","src/utils/attr-list.ts","src/loader/date-range.ts","src/loader/load-stats.ts","src/loader/fragment.ts","src/loader/level-details.ts","src/utils/numeric-encoding-utils.ts","src/utils/keysystem-util.ts","src/utils/global.ts","src/utils/mediakeys-helper.ts","src/utils/typed-array.ts","src/demux/id3.ts","src/utils/hex.ts","src/utils/mp4-tools.ts","src/loader/level-key.ts","src/utils/variable-substitution.ts","src/utils/mediasource-helper.ts","src/utils/codecs.ts","src/loader/m3u8-parser.ts","src/types/loader.ts","src/loader/playlist-loader.ts","src/utils/texttrack-utils.ts","src/types/demuxer.ts","src/controller/id3-track-controller.ts","src/controller/latency-controller.ts","src/types/level.ts","src/utils/level-helper.ts","src/utils/error-helper.ts","src/utils/binary-search.ts","src/controller/fragment-finders.ts","src/controller/error-controller.ts","src/controller/base-playlist-controller.ts","src/utils/ewma.ts","src/utils/ewma-bandwidth-estimator.ts","src/utils/mediacapabilities-helper.ts","src/utils/hdr.ts","src/utils/rendition-helper.ts","src/controller/abr-controller.ts","src/task-loop.ts","src/controller/fragment-tracker.ts","src/utils/buffer-helper.ts","src/types/transmuxer.ts","src/utils/discontinuities.ts","src/loader/fragment-loader.ts","src/crypt/aes-crypto.ts","src/crypt/fast-aes-key.ts","src/crypt/aes-decryptor.ts","src/crypt/decrypter.ts","src/utils/time-ranges.ts","src/controller/base-stream-controller.ts","src/demux/chunk-cache.ts","src/demux/dummy-demuxed-track.ts","src/demux/audio/base-audio-demuxer.ts","src/demux/audio/adts.ts","src/demux/audio/mpegaudio.ts","src/demux/audio/aacdemuxer.ts","src/demux/mp4demuxer.ts","src/demux/audio/dolby.ts","src/demux/audio/ac3-demuxer.ts","src/demux/video/base-video-parser.ts","src/demux/video/exp-golomb.ts","src/demux/video/avc-video-parser.ts","src/demux/sample-aes.ts","src/demux/tsdemuxer.ts","src/demux/audio/mp3demuxer.ts","src/remux/aac-helper.ts","src/remux/mp4-generator.ts","src/utils/timescale-conversion.ts","src/remux/mp4-remuxer.ts","src/remux/passthrough-remuxer.ts","src/demux/transmuxer.ts","node_modules/eventemitter3/index.js","src/demux/transmuxer-worker.ts","src/demux/inject-worker.ts","src/demux/transmuxer-interface.ts","src/controller/audio-stream-controller.ts","src/utils/media-option-attributes.ts","src/controller/audio-track-controller.ts","src/controller/subtitle-stream-controller.ts","src/controller/subtitle-track-controller.ts","src/controller/buffer-operation-queue.ts","src/controller/buffer-controller.ts","src/utils/cea-608-parser.ts","src/utils/output-filter.ts","src/utils/vttcue.ts","src/utils/vttparser.ts","src/utils/webvtt-parser.ts","src/utils/imsc1-ttml-parser.ts","src/controller/timeline-controller.ts","src/controller/cap-level-controller.ts","src/controller/fps-controller.ts","src/controller/eme-controller.ts","node_modules/@svta/common-media-library/dist/cta/CmObjectType.js","node_modules/@svta/common-media-library/dist/cta/CmStreamingFormat.js","node_modules/@svta/common-media-library/dist/cmcd/CmcdHeaderField.js","node_modules/@svta/common-media-library/dist/cmcd/CmcdHeaderMap.js","node_modules/@svta/common-media-library/dist/structuredfield/SfItem.js","node_modules/@svta/common-media-library/dist/structuredfield/SfToken.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/DICT.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/throwError.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/BARE_ITEM.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/BOOLEAN.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/BYTES.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/DECIMAL.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/INTEGER.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/isInvalidInt.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/STRING_REGEX.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/TOKEN.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/KEY.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeError.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeBoolean.js","node_modules/@svta/common-media-library/dist/utils/base64encode.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeByteSequence.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeInteger.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeDate.js","node_modules/@svta/common-media-library/dist/utils/roundToEven.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeDecimal.js","node_modules/@svta/common-media-library/dist/structuredfield/utils/STRING.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeString.js","node_modules/@svta/common-media-library/dist/cta/utils/symbolToStr.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeToken.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeBareItem.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeKey.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeParams.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeItem.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeInnerList.js","node_modules/@svta/common-media-library/dist/structuredfield/serialize/serializeDict.js","node_modules/@svta/common-media-library/dist/structuredfield/encodeSfDict.js","node_modules/@svta/common-media-library/dist/cta/utils/isTokenField.js","node_modules/@svta/common-media-library/dist/cta/utils/isValid.js","node_modules/@svta/common-media-library/dist/utils/urlToRelativePath.js","node_modules/@svta/common-media-library/dist/utils/uuid.js","node_modules/@svta/common-media-library/dist/cmcd/CmcdFormatters.js","node_modules/@svta/common-media-library/dist/cmcd/utils/processCmcd.js","node_modules/@svta/common-media-library/dist/cmcd/encodeCmcd.js","node_modules/@svta/common-media-library/dist/cmcd/toCmcdHeaders.js","node_modules/@svta/common-media-library/dist/cmcd/appendCmcdHeaders.js","node_modules/@svta/common-media-library/dist/cmcd/CMCD_PARAM.js","node_modules/@svta/common-media-library/dist/cmcd/toCmcdQuery.js","node_modules/@svta/common-media-library/dist/cmcd/appendCmcdQuery.js","src/controller/cmcd-controller.ts","src/controller/content-steering-controller.ts","src/utils/xhr-loader.ts","src/utils/fetch-loader.ts","src/utils/cues.ts","src/config.ts","src/controller/level-controller.ts","src/loader/key-loader.ts","src/is-supported.ts","src/controller/gap-controller.ts","src/controller/stream-controller.ts","src/hls.ts"],"sourcesContent":["// see https://tools.ietf.org/html/rfc1808\n\n(function (root) {\n  var URL_REGEX =\n    /^(?=((?:[a-zA-Z0-9+\\-.]+:)?))\\1(?=((?:\\/\\/[^\\/?#]*)?))\\2(?=((?:(?:[^?#\\/]*\\/)*[^;?#\\/]*)?))\\3((?:;[^?#]*)?)(\\?[^#]*)?(#[^]*)?$/;\n  var FIRST_SEGMENT_REGEX = /^(?=([^\\/?#]*))\\1([^]*)$/;\n  var SLASH_DOT_REGEX = /(?:\\/|^)\\.(?=\\/)/g;\n  var SLASH_DOT_DOT_REGEX = /(?:\\/|^)\\.\\.\\/(?!\\.\\.\\/)[^\\/]*(?=\\/)/g;\n\n  var URLToolkit = {\n    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\n    // E.g\n    // With opts.alwaysNormalize = false (default, spec compliant)\n    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\n    // With opts.alwaysNormalize = true (not spec compliant)\n    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\n    buildAbsoluteURL: function (baseURL, relativeURL, opts) {\n      opts = opts || {};\n      // remove any remaining space and CRLF\n      baseURL = baseURL.trim();\n      relativeURL = relativeURL.trim();\n      if (!relativeURL) {\n        // 2a) If the embedded URL is entirely empty, it inherits the\n        // entire base URL (i.e., is set equal to the base URL)\n        // and we are done.\n        if (!opts.alwaysNormalize) {\n          return baseURL;\n        }\n        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\n        if (!basePartsForNormalise) {\n          throw new Error('Error trying to parse base URL.');\n        }\n        basePartsForNormalise.path = URLToolkit.normalizePath(\n          basePartsForNormalise.path\n        );\n        return URLToolkit.buildURLFromParts(basePartsForNormalise);\n      }\n      var relativeParts = URLToolkit.parseURL(relativeURL);\n      if (!relativeParts) {\n        throw new Error('Error trying to parse relative URL.');\n      }\n      if (relativeParts.scheme) {\n        // 2b) If the embedded URL starts with a scheme name, it is\n        // interpreted as an absolute URL and we are done.\n        if (!opts.alwaysNormalize) {\n          return relativeURL;\n        }\n        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\n        return URLToolkit.buildURLFromParts(relativeParts);\n      }\n      var baseParts = URLToolkit.parseURL(baseURL);\n      if (!baseParts) {\n        throw new Error('Error trying to parse base URL.');\n      }\n      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\n        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\n        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\n        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\n        baseParts.netLoc = pathParts[1];\n        baseParts.path = pathParts[2];\n      }\n      if (baseParts.netLoc && !baseParts.path) {\n        baseParts.path = '/';\n      }\n      var builtParts = {\n        // 2c) Otherwise, the embedded URL inherits the scheme of\n        // the base URL.\n        scheme: baseParts.scheme,\n        netLoc: relativeParts.netLoc,\n        path: null,\n        params: relativeParts.params,\n        query: relativeParts.query,\n        fragment: relativeParts.fragment,\n      };\n      if (!relativeParts.netLoc) {\n        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\n        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\n        // (if any) of the base URL.\n        builtParts.netLoc = baseParts.netLoc;\n        // 4) If the embedded URL path is preceded by a slash \"/\", the\n        // path is not relative and we skip to Step 7.\n        if (relativeParts.path[0] !== '/') {\n          if (!relativeParts.path) {\n            // 5) If the embedded URL path is empty (and not preceded by a\n            // slash), then the embedded URL inherits the base URL path\n            builtParts.path = baseParts.path;\n            // 5a) if the embedded URL's <params> is non-empty, we skip to\n            // step 7; otherwise, it inherits the <params> of the base\n            // URL (if any) and\n            if (!relativeParts.params) {\n              builtParts.params = baseParts.params;\n              // 5b) if the embedded URL's <query> is non-empty, we skip to\n              // step 7; otherwise, it inherits the <query> of the base\n              // URL (if any) and we skip to step 7.\n              if (!relativeParts.query) {\n                builtParts.query = baseParts.query;\n              }\n            }\n          } else {\n            // 6) The last segment of the base URL's path (anything\n            // following the rightmost slash \"/\", or the entire path if no\n            // slash is present) is removed and the embedded URL's path is\n            // appended in its place.\n            var baseURLPath = baseParts.path;\n            var newPath =\n              baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +\n              relativeParts.path;\n            builtParts.path = URLToolkit.normalizePath(newPath);\n          }\n        }\n      }\n      if (builtParts.path === null) {\n        builtParts.path = opts.alwaysNormalize\n          ? URLToolkit.normalizePath(relativeParts.path)\n          : relativeParts.path;\n      }\n      return URLToolkit.buildURLFromParts(builtParts);\n    },\n    parseURL: function (url) {\n      var parts = URL_REGEX.exec(url);\n      if (!parts) {\n        return null;\n      }\n      return {\n        scheme: parts[1] || '',\n        netLoc: parts[2] || '',\n        path: parts[3] || '',\n        params: parts[4] || '',\n        query: parts[5] || '',\n        fragment: parts[6] || '',\n      };\n    },\n    normalizePath: function (path) {\n      // The following operations are\n      // then applied, in order, to the new path:\n      // 6a) All occurrences of \"./\", where \".\" is a complete path\n      // segment, are removed.\n      // 6b) If the path ends with \".\" as a complete path segment,\n      // that \".\" is removed.\n      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\n      // 6c) All occurrences of \"<segment>/../\", where <segment> is a\n      // complete path segment not equal to \"..\", are removed.\n      // Removal of these path segments is performed iteratively,\n      // removing the leftmost matching pattern on each iteration,\n      // until no matching pattern remains.\n      // 6d) If the path ends with \"<segment>/..\", where <segment> is a\n      // complete path segment not equal to \"..\", that\n      // \"<segment>/..\" is removed.\n      while (\n        path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length\n      ) {}\n      return path.split('').reverse().join('');\n    },\n    buildURLFromParts: function (parts) {\n      return (\n        parts.scheme +\n        parts.netLoc +\n        parts.path +\n        parts.params +\n        parts.query +\n        parts.fragment\n      );\n    },\n  };\n\n  if (typeof exports === 'object' && typeof module === 'object')\n    module.exports = URLToolkit;\n  else if (typeof define === 'function' && define.amd)\n    define([], function () {\n      return URLToolkit;\n    });\n  else if (typeof exports === 'object') exports['URLToolkit'] = URLToolkit;\n  else root['URLToolkit'] = URLToolkit;\n})(this);\n","// https://caniuse.com/mdn-javascript_builtins_number_isfinite\nexport const isFiniteNumber =\n  Number.isFinite ||\n  function (value) {\n    return typeof value === 'number' && isFinite(value);\n  };\n\n// https://caniuse.com/mdn-javascript_builtins_number_issafeinteger\nexport const isSafeInteger =\n  Number.isSafeInteger ||\n  function (value) {\n    return typeof value === 'number' && Math.abs(value) <= MAX_SAFE_INTEGER;\n  };\n\nexport const MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n","import {\n  ManifestLoadedData,\n  ManifestLoadingData,\n  MediaAttachedData,\n  MediaAttachingData,\n  LevelLoadingData,\n  LevelLoadedData,\n  ManifestParsedData,\n  LevelUpdatedData,\n  LevelsUpdatedData,\n  FragParsingUserdataData,\n  FragDecryptedData,\n  FragLoadedData,\n  InitPTSFoundData,\n  CuesParsedData,\n  SubtitleFragProcessedData,\n  NonNativeTextTracksData,\n  FragLoadingData,\n  AudioTrackLoadedData,\n  SubtitleTrackLoadedData,\n  ErrorData,\n  AudioTrackSwitchingData,\n  AudioTrackSwitchedData,\n  KeyLoadedData,\n  KeyLoadingData,\n  SubtitleTrackSwitchData,\n  SubtitleTracksUpdatedData,\n  LevelSwitchedData,\n  FragChangedData,\n  BufferAppendingData,\n  BufferCodecsData,\n  FragParsingMetadataData,\n  FragParsingInitSegmentData,\n  FragBufferedData,\n  BufferFlushingData,\n  BufferEOSData,\n  LevelSwitchingData,\n  MaxAutoLevelUpdatedData,\n  FPSDropLevelCappingData,\n  FPSDropData,\n  BufferCreatedData,\n  BufferAppendedData,\n  LevelPTSUpdatedData,\n  FragParsedData,\n  AudioTracksUpdatedData,\n  FragLoadEmergencyAbortedData,\n  BackBufferData,\n  LiveBackBufferData,\n  TrackLoadingData,\n  BufferFlushedData,\n  SteeringManifestLoadedData,\n} from './types/events';\n\nexport enum Events {\n  // Fired before MediaSource is attaching to media element\n  MEDIA_ATTACHING = 'hlsMediaAttaching',\n  // Fired when MediaSource has been successfully attached to media element\n  MEDIA_ATTACHED = 'hlsMediaAttached',\n  // Fired before detaching MediaSource from media element\n  MEDIA_DETACHING = 'hlsMediaDetaching',\n  // Fired when MediaSource has been detached from media element\n  MEDIA_DETACHED = 'hlsMediaDetached',\n  // Fired when the buffer is going to be reset\n  BUFFER_RESET = 'hlsBufferReset',\n  // Fired when we know about the codecs that we need buffers for to push into - data: {tracks : { container, codec, levelCodec, initSegment, metadata }}\n  BUFFER_CODECS = 'hlsBufferCodecs',\n  // fired when sourcebuffers have been created - data: { tracks : tracks }\n  BUFFER_CREATED = 'hlsBufferCreated',\n  // fired when we append a segment to the buffer - data: { segment: segment object }\n  BUFFER_APPENDING = 'hlsBufferAppending',\n  // fired when we are done with appending a media segment to the buffer - data : { parent : segment parent that triggered BUFFER_APPENDING, pending : nb of segments waiting for appending for this segment parent}\n  BUFFER_APPENDED = 'hlsBufferAppended',\n  // fired when the stream is finished and we want to notify the media buffer that there will be no more data - data: { }\n  BUFFER_EOS = 'hlsBufferEos',\n  // fired when the media buffer should be flushed - data { startOffset, endOffset }\n  BUFFER_FLUSHING = 'hlsBufferFlushing',\n  // fired when the media buffer has been flushed - data: { }\n  BUFFER_FLUSHED = 'hlsBufferFlushed',\n  // fired to signal that a manifest loading starts - data: { url : manifestURL}\n  MANIFEST_LOADING = 'hlsManifestLoading',\n  // fired after manifest has been loaded - data: { levels : [available quality levels], audioTracks : [ available audio tracks ], url : manifestURL, stats : LoaderStats }\n  MANIFEST_LOADED = 'hlsManifestLoaded',\n  // fired after manifest has been parsed - data: { levels : [available quality levels], firstLevel : index of first quality level appearing in Manifest}\n  MANIFEST_PARSED = 'hlsManifestParsed',\n  // fired when a level switch is requested - data: { level : id of new level }\n  LEVEL_SWITCHING = 'hlsLevelSwitching',\n  // fired when a level switch is effective - data: { level : id of new level }\n  LEVEL_SWITCHED = 'hlsLevelSwitched',\n  // fired when a level playlist loading starts - data: { url : level URL, level : id of level being loaded}\n  LEVEL_LOADING = 'hlsLevelLoading',\n  // fired when a level playlist loading finishes - data: { details : levelDetails object, level : id of loaded level, stats : LoaderStats }\n  LEVEL_LOADED = 'hlsLevelLoaded',\n  // fired when a level's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, level : id of updated level }\n  LEVEL_UPDATED = 'hlsLevelUpdated',\n  // fired when a level's PTS information has been updated after parsing a fragment - data: { details : levelDetails object, level : id of updated level, drift: PTS drift observed when parsing last fragment }\n  LEVEL_PTS_UPDATED = 'hlsLevelPtsUpdated',\n  // fired to notify that levels have changed after removing a level - data: { levels : [available quality levels] }\n  LEVELS_UPDATED = 'hlsLevelsUpdated',\n  // fired to notify that audio track lists has been updated - data: { audioTracks : audioTracks }\n  AUDIO_TRACKS_UPDATED = 'hlsAudioTracksUpdated',\n  // fired when an audio track switching is requested - data: { id : audio track id }\n  AUDIO_TRACK_SWITCHING = 'hlsAudioTrackSwitching',\n  // fired when an audio track switch actually occurs - data: { id : audio track id }\n  AUDIO_TRACK_SWITCHED = 'hlsAudioTrackSwitched',\n  // fired when an audio track loading starts - data: { url : audio track URL, id : audio track id }\n  AUDIO_TRACK_LOADING = 'hlsAudioTrackLoading',\n  // fired when an audio track loading finishes - data: { details : levelDetails object, id : audio track id, stats : LoaderStats }\n  AUDIO_TRACK_LOADED = 'hlsAudioTrackLoaded',\n  // fired to notify that subtitle track lists has been updated - data: { subtitleTracks : subtitleTracks }\n  SUBTITLE_TRACKS_UPDATED = 'hlsSubtitleTracksUpdated',\n  // fired to notify that subtitle tracks were cleared as a result of stopping the media\n  SUBTITLE_TRACKS_CLEARED = 'hlsSubtitleTracksCleared',\n  // fired when an subtitle track switch occurs - data: { id : subtitle track id }\n  SUBTITLE_TRACK_SWITCH = 'hlsSubtitleTrackSwitch',\n  // fired when a subtitle track loading starts - data: { url : subtitle track URL, id : subtitle track id }\n  SUBTITLE_TRACK_LOADING = 'hlsSubtitleTrackLoading',\n  // fired when a subtitle track loading finishes - data: { details : levelDetails object, id : subtitle track id, stats : LoaderStats }\n  SUBTITLE_TRACK_LOADED = 'hlsSubtitleTrackLoaded',\n  // fired when a subtitle fragment has been processed - data: { success : boolean, frag : the processed frag }\n  SUBTITLE_FRAG_PROCESSED = 'hlsSubtitleFragProcessed',\n  // fired when a set of VTTCues to be managed externally has been parsed - data: { type: string, track: string, cues: [ VTTCue ] }\n  CUES_PARSED = 'hlsCuesParsed',\n  // fired when a text track to be managed externally is found - data: { tracks: [ { label: string, kind: string, default: boolean } ] }\n  NON_NATIVE_TEXT_TRACKS_FOUND = 'hlsNonNativeTextTracksFound',\n  // fired when the first timestamp is found - data: { id : demuxer id, initPTS: initPTS, timescale: timescale, frag : fragment object }\n  INIT_PTS_FOUND = 'hlsInitPtsFound',\n  // fired when a fragment loading starts - data: { frag : fragment object }\n  FRAG_LOADING = 'hlsFragLoading',\n  // fired when a fragment loading is progressing - data: { frag : fragment object, { trequest, tfirst, loaded } }\n  // FRAG_LOAD_PROGRESS = 'hlsFragLoadProgress',\n  // Identifier for fragment load aborting for emergency switch down - data: { frag : fragment object }\n  FRAG_LOAD_EMERGENCY_ABORTED = 'hlsFragLoadEmergencyAborted',\n  // fired when a fragment loading is completed - data: { frag : fragment object, payload : fragment payload, stats : LoaderStats }\n  FRAG_LOADED = 'hlsFragLoaded',\n  // fired when a fragment has finished decrypting - data: { id : demuxer id, frag: fragment object, payload : fragment payload, stats : { tstart, tdecrypt } }\n  FRAG_DECRYPTED = 'hlsFragDecrypted',\n  // fired when Init Segment has been extracted from fragment - data: { id : demuxer id, frag: fragment object, moov : moov MP4 box, codecs : codecs found while parsing fragment }\n  FRAG_PARSING_INIT_SEGMENT = 'hlsFragParsingInitSegment',\n  // fired when parsing sei text is completed - data: { id : demuxer id, frag: fragment object, samples : [ sei samples pes ] }\n  FRAG_PARSING_USERDATA = 'hlsFragParsingUserdata',\n  // fired when parsing id3 is completed - data: { id : demuxer id, frag: fragment object, samples : [ id3 samples pes ] }\n  FRAG_PARSING_METADATA = 'hlsFragParsingMetadata',\n  // fired when data have been extracted from fragment - data: { id : demuxer id, frag: fragment object, data1 : moof MP4 box or TS fragments, data2 : mdat MP4 box or null}\n  // FRAG_PARSING_DATA = 'hlsFragParsingData',\n  // fired when fragment parsing is completed - data: { id : demuxer id, frag: fragment object }\n  FRAG_PARSED = 'hlsFragParsed',\n  // fired when fragment remuxed MP4 boxes have all been appended into SourceBuffer - data: { id : demuxer id, frag : fragment object, stats : LoaderStats }\n  FRAG_BUFFERED = 'hlsFragBuffered',\n  // fired when fragment matching with current media position is changing - data : { id : demuxer id, frag : fragment object }\n  FRAG_CHANGED = 'hlsFragChanged',\n  // Identifier for a FPS drop event - data: { currentDropped, currentDecoded, totalDroppedFrames }\n  FPS_DROP = 'hlsFpsDrop',\n  // triggered when FPS drop triggers auto level capping - data: { level, droppedLevel }\n  FPS_DROP_LEVEL_CAPPING = 'hlsFpsDropLevelCapping',\n  // triggered when maxAutoLevel changes - data { autoLevelCapping, levels, maxAutoLevel, minAutoLevel, maxHdcpLevel }\n  MAX_AUTO_LEVEL_UPDATED = 'hlsMaxAutoLevelUpdated',\n  // Identifier for an error event - data: { type : error type, details : error details, fatal : if true, hls.js cannot/will not try to recover, if false, hls.js will try to recover,other error specific data }\n  ERROR = 'hlsError',\n  // fired when hls.js instance starts destroying. Different from MEDIA_DETACHED as one could want to detach and reattach a media to the instance of hls.js to handle mid-rolls for example - data: { }\n  DESTROYING = 'hlsDestroying',\n  // fired when a decrypt key loading starts - data: { frag : fragment object }\n  KEY_LOADING = 'hlsKeyLoading',\n  // fired when a decrypt key loading is completed - data: { frag : fragment object, keyInfo : KeyLoaderInfo }\n  KEY_LOADED = 'hlsKeyLoaded',\n  // deprecated; please use BACK_BUFFER_REACHED - data : { bufferEnd: number }\n  LIVE_BACK_BUFFER_REACHED = 'hlsLiveBackBufferReached',\n  // fired when the back buffer is reached as defined by the backBufferLength config option - data : { bufferEnd: number }\n  BACK_BUFFER_REACHED = 'hlsBackBufferReached',\n  // fired after steering manifest has been loaded - data: { steeringManifest: SteeringManifest object, url: steering manifest URL }\n  STEERING_MANIFEST_LOADED = 'hlsSteeringManifestLoaded',\n}\n\n/**\n * Defines each Event type and payload by Event name. Used in {@link hls.js#HlsEventEmitter} to strongly type the event listener API.\n */\nexport interface HlsListeners {\n  [Events.MEDIA_ATTACHING]: (\n    event: Events.MEDIA_ATTACHING,\n    data: MediaAttachingData,\n  ) => void;\n  [Events.MEDIA_ATTACHED]: (\n    event: Events.MEDIA_ATTACHED,\n    data: MediaAttachedData,\n  ) => void;\n  [Events.MEDIA_DETACHING]: (event: Events.MEDIA_DETACHING) => void;\n  [Events.MEDIA_DETACHED]: (event: Events.MEDIA_DETACHED) => void;\n  [Events.BUFFER_RESET]: (event: Events.BUFFER_RESET) => void;\n  [Events.BUFFER_CODECS]: (\n    event: Events.BUFFER_CODECS,\n    data: BufferCodecsData,\n  ) => void;\n  [Events.BUFFER_CREATED]: (\n    event: Events.BUFFER_CREATED,\n    data: BufferCreatedData,\n  ) => void;\n  [Events.BUFFER_APPENDING]: (\n    event: Events.BUFFER_APPENDING,\n    data: BufferAppendingData,\n  ) => void;\n  [Events.BUFFER_APPENDED]: (\n    event: Events.BUFFER_APPENDED,\n    data: BufferAppendedData,\n  ) => void;\n  [Events.BUFFER_EOS]: (event: Events.BUFFER_EOS, data: BufferEOSData) => void;\n  [Events.BUFFER_FLUSHING]: (\n    event: Events.BUFFER_FLUSHING,\n    data: BufferFlushingData,\n  ) => void;\n  [Events.BUFFER_FLUSHED]: (\n    event: Events.BUFFER_FLUSHED,\n    data: BufferFlushedData,\n  ) => void;\n  [Events.MANIFEST_LOADING]: (\n    event: Events.MANIFEST_LOADING,\n    data: ManifestLoadingData,\n  ) => void;\n  [Events.MANIFEST_LOADED]: (\n    event: Events.MANIFEST_LOADED,\n    data: ManifestLoadedData,\n  ) => void;\n  [Events.MANIFEST_PARSED]: (\n    event: Events.MANIFEST_PARSED,\n    data: ManifestParsedData,\n  ) => void;\n  [Events.LEVEL_SWITCHING]: (\n    event: Events.LEVEL_SWITCHING,\n    data: LevelSwitchingData,\n  ) => void;\n  [Events.LEVEL_SWITCHED]: (\n    event: Events.LEVEL_SWITCHED,\n    data: LevelSwitchedData,\n  ) => void;\n  [Events.LEVEL_LOADING]: (\n    event: Events.LEVEL_LOADING,\n    data: LevelLoadingData,\n  ) => void;\n  [Events.LEVEL_LOADED]: (\n    event: Events.LEVEL_LOADED,\n    data: LevelLoadedData,\n  ) => void;\n  [Events.LEVEL_UPDATED]: (\n    event: Events.LEVEL_UPDATED,\n    data: LevelUpdatedData,\n  ) => void;\n  [Events.LEVEL_PTS_UPDATED]: (\n    event: Events.LEVEL_PTS_UPDATED,\n    data: LevelPTSUpdatedData,\n  ) => void;\n  [Events.LEVELS_UPDATED]: (\n    event: Events.LEVELS_UPDATED,\n    data: LevelsUpdatedData,\n  ) => void;\n  [Events.AUDIO_TRACKS_UPDATED]: (\n    event: Events.AUDIO_TRACKS_UPDATED,\n    data: AudioTracksUpdatedData,\n  ) => void;\n  [Events.AUDIO_TRACK_SWITCHING]: (\n    event: Events.AUDIO_TRACK_SWITCHING,\n    data: AudioTrackSwitchingData,\n  ) => void;\n  [Events.AUDIO_TRACK_SWITCHED]: (\n    event: Events.AUDIO_TRACK_SWITCHED,\n    data: AudioTrackSwitchedData,\n  ) => void;\n  [Events.AUDIO_TRACK_LOADING]: (\n    event: Events.AUDIO_TRACK_LOADING,\n    data: TrackLoadingData,\n  ) => void;\n  [Events.AUDIO_TRACK_LOADED]: (\n    event: Events.AUDIO_TRACK_LOADED,\n    data: AudioTrackLoadedData,\n  ) => void;\n  [Events.SUBTITLE_TRACKS_UPDATED]: (\n    event: Events.SUBTITLE_TRACKS_UPDATED,\n    data: SubtitleTracksUpdatedData,\n  ) => void;\n  [Events.SUBTITLE_TRACKS_CLEARED]: (\n    event: Events.SUBTITLE_TRACKS_CLEARED,\n  ) => void;\n  [Events.SUBTITLE_TRACK_SWITCH]: (\n    event: Events.SUBTITLE_TRACK_SWITCH,\n    data: SubtitleTrackSwitchData,\n  ) => void;\n  [Events.SUBTITLE_TRACK_LOADING]: (\n    event: Events.SUBTITLE_TRACK_LOADING,\n    data: TrackLoadingData,\n  ) => void;\n  [Events.SUBTITLE_TRACK_LOADED]: (\n    event: Events.SUBTITLE_TRACK_LOADED,\n    data: SubtitleTrackLoadedData,\n  ) => void;\n  [Events.SUBTITLE_FRAG_PROCESSED]: (\n    event: Events.SUBTITLE_FRAG_PROCESSED,\n    data: SubtitleFragProcessedData,\n  ) => void;\n  [Events.CUES_PARSED]: (\n    event: Events.CUES_PARSED,\n    data: CuesParsedData,\n  ) => void;\n  [Events.NON_NATIVE_TEXT_TRACKS_FOUND]: (\n    event: Events.NON_NATIVE_TEXT_TRACKS_FOUND,\n    data: NonNativeTextTracksData,\n  ) => void;\n  [Events.INIT_PTS_FOUND]: (\n    event: Events.INIT_PTS_FOUND,\n    data: InitPTSFoundData,\n  ) => void;\n  [Events.FRAG_LOADING]: (\n    event: Events.FRAG_LOADING,\n    data: FragLoadingData,\n  ) => void;\n  // [Events.FRAG_LOAD_PROGRESS]: TodoEventType\n  [Events.FRAG_LOAD_EMERGENCY_ABORTED]: (\n    event: Events.FRAG_LOAD_EMERGENCY_ABORTED,\n    data: FragLoadEmergencyAbortedData,\n  ) => void;\n  [Events.FRAG_LOADED]: (\n    event: Events.FRAG_LOADED,\n    data: FragLoadedData,\n  ) => void;\n  [Events.FRAG_DECRYPTED]: (\n    event: Events.FRAG_DECRYPTED,\n    data: FragDecryptedData,\n  ) => void;\n  [Events.FRAG_PARSING_INIT_SEGMENT]: (\n    event: Events.FRAG_PARSING_INIT_SEGMENT,\n    data: FragParsingInitSegmentData,\n  ) => void;\n  [Events.FRAG_PARSING_USERDATA]: (\n    event: Events.FRAG_PARSING_USERDATA,\n    data: FragParsingUserdataData,\n  ) => void;\n  [Events.FRAG_PARSING_METADATA]: (\n    event: Events.FRAG_PARSING_METADATA,\n    data: FragParsingMetadataData,\n  ) => void;\n  // [Events.FRAG_PARSING_DATA]: TodoEventType\n  [Events.FRAG_PARSED]: (\n    event: Events.FRAG_PARSED,\n    data: FragParsedData,\n  ) => void;\n  [Events.FRAG_BUFFERED]: (\n    event: Events.FRAG_BUFFERED,\n    data: FragBufferedData,\n  ) => void;\n  [Events.FRAG_CHANGED]: (\n    event: Events.FRAG_CHANGED,\n    data: FragChangedData,\n  ) => void;\n  [Events.FPS_DROP]: (event: Events.FPS_DROP, data: FPSDropData) => void;\n  [Events.FPS_DROP_LEVEL_CAPPING]: (\n    event: Events.FPS_DROP_LEVEL_CAPPING,\n    data: FPSDropLevelCappingData,\n  ) => void;\n  [Events.MAX_AUTO_LEVEL_UPDATED]: (\n    event: Events.MAX_AUTO_LEVEL_UPDATED,\n    data: MaxAutoLevelUpdatedData,\n  ) => void;\n  [Events.ERROR]: (event: Events.ERROR, data: ErrorData) => void;\n  [Events.DESTROYING]: (event: Events.DESTROYING) => void;\n  [Events.KEY_LOADING]: (\n    event: Events.KEY_LOADING,\n    data: KeyLoadingData,\n  ) => void;\n  [Events.KEY_LOADED]: (event: Events.KEY_LOADED, data: KeyLoadedData) => void;\n  [Events.LIVE_BACK_BUFFER_REACHED]: (\n    event: Events.LIVE_BACK_BUFFER_REACHED,\n    data: LiveBackBufferData,\n  ) => void;\n  [Events.BACK_BUFFER_REACHED]: (\n    event: Events.BACK_BUFFER_REACHED,\n    data: BackBufferData,\n  ) => void;\n  [Events.STEERING_MANIFEST_LOADED]: (\n    event: Events.STEERING_MANIFEST_LOADED,\n    data: SteeringManifestLoadedData,\n  ) => void;\n}\nexport interface HlsEventEmitter {\n  on<E extends keyof HlsListeners, Context = undefined>(\n    event: E,\n    listener: HlsListeners[E],\n    context?: Context,\n  ): void;\n  once<E extends keyof HlsListeners, Context = undefined>(\n    event: E,\n    listener: HlsListeners[E],\n    context?: Context,\n  ): void;\n\n  removeAllListeners<E extends keyof HlsListeners>(event?: E): void;\n  off<E extends keyof HlsListeners, Context = undefined>(\n    event: E,\n    listener?: HlsListeners[E],\n    context?: Context,\n    once?: boolean,\n  ): void;\n\n  listeners<E extends keyof HlsListeners>(event: E): HlsListeners[E][];\n  emit<E extends keyof HlsListeners>(\n    event: E,\n    name: E,\n    eventObject: Parameters<HlsListeners[E]>[1],\n  ): boolean;\n  listenerCount<E extends keyof HlsListeners>(event: E): number;\n}\n","export enum ErrorTypes {\n  // Identifier for a network error (loading error / timeout ...)\n  NETWORK_ERROR = 'networkError',\n  // Identifier for a media Error (video/parsing/mediasource error)\n  MEDIA_ERROR = 'mediaError',\n  // EME (encrypted media extensions) errors\n  KEY_SYSTEM_ERROR = 'keySystemError',\n  // Identifier for a mux Error (demuxing/remuxing)\n  MUX_ERROR = 'muxError',\n  // Identifier for all other errors\n  OTHER_ERROR = 'otherError',\n}\n\nexport enum ErrorDetails {\n  KEY_SYSTEM_NO_KEYS = 'keySystemNoKeys',\n  KEY_SYSTEM_NO_ACCESS = 'keySystemNoAccess',\n  KEY_SYSTEM_NO_SESSION = 'keySystemNoSession',\n  KEY_SYSTEM_NO_CONFIGURED_LICENSE = 'keySystemNoConfiguredLicense',\n  KEY_SYSTEM_LICENSE_REQUEST_FAILED = 'keySystemLicenseRequestFailed',\n  KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED = 'keySystemServerCertificateRequestFailed',\n  KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED = 'keySystemServerCertificateUpdateFailed',\n  KEY_SYSTEM_SESSION_UPDATE_FAILED = 'keySystemSessionUpdateFailed',\n  KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED = 'keySystemStatusOutputRestricted',\n  KEY_SYSTEM_STATUS_INTERNAL_ERROR = 'keySystemStatusInternalError',\n  // Identifier for a manifest load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  MANIFEST_LOAD_ERROR = 'manifestLoadError',\n  // Identifier for a manifest load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  MANIFEST_LOAD_TIMEOUT = 'manifestLoadTimeOut',\n  // Identifier for a manifest parsing error - data: { url : faulty URL, reason : error reason}\n  MANIFEST_PARSING_ERROR = 'manifestParsingError',\n  // Identifier for a manifest with only incompatible codecs error - data: { url : faulty URL, reason : error reason}\n  MANIFEST_INCOMPATIBLE_CODECS_ERROR = 'manifestIncompatibleCodecsError',\n  // Identifier for a level which contains no fragments - data: { url: faulty URL, reason: \"no fragments found in level\", level: index of the bad level }\n  LEVEL_EMPTY_ERROR = 'levelEmptyError',\n  // Identifier for a level load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  LEVEL_LOAD_ERROR = 'levelLoadError',\n  // Identifier for a level load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  LEVEL_LOAD_TIMEOUT = 'levelLoadTimeOut',\n  // Identifier for a level parse error - data: { url : faulty URL, error: Error, reason: error message }\n  LEVEL_PARSING_ERROR = 'levelParsingError',\n  // Identifier for a level switch error - data: { level : faulty level Id, event : error description}\n  LEVEL_SWITCH_ERROR = 'levelSwitchError',\n  // Identifier for an audio track load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  AUDIO_TRACK_LOAD_ERROR = 'audioTrackLoadError',\n  // Identifier for an audio track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  AUDIO_TRACK_LOAD_TIMEOUT = 'audioTrackLoadTimeOut',\n  // Identifier for a subtitle track load error - data: { url : faulty URL, response : { code: error code, text: error text }}\n  SUBTITLE_LOAD_ERROR = 'subtitleTrackLoadError',\n  // Identifier for a subtitle track load timeout - data: { url : faulty URL, response : { code: error code, text: error text }}\n  SUBTITLE_TRACK_LOAD_TIMEOUT = 'subtitleTrackLoadTimeOut',\n  // Identifier for fragment load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  FRAG_LOAD_ERROR = 'fragLoadError',\n  // Identifier for fragment load timeout error - data: { frag : fragment object}\n  FRAG_LOAD_TIMEOUT = 'fragLoadTimeOut',\n  // Identifier for a fragment decryption error event - data: {id : demuxer Id,frag: fragment object, reason : parsing error description }\n  FRAG_DECRYPT_ERROR = 'fragDecryptError',\n  // Identifier for a fragment parsing error event - data: { id : demuxer Id, reason : parsing error description }\n  // will be renamed DEMUX_PARSING_ERROR and switched to MUX_ERROR in the next major release\n  FRAG_PARSING_ERROR = 'fragParsingError',\n  // Identifier for a fragment or part load skipped because of a GAP tag or attribute\n  FRAG_GAP = 'fragGap',\n  // Identifier for a remux alloc error event - data: { id : demuxer Id, frag : fragment object, bytes : nb of bytes on which allocation failed , reason : error text }\n  REMUX_ALLOC_ERROR = 'remuxAllocError',\n  // Identifier for decrypt key load error - data: { frag : fragment object, response : { code: error code, text: error text }}\n  KEY_LOAD_ERROR = 'keyLoadError',\n  // Identifier for decrypt key load timeout error - data: { frag : fragment object}\n  KEY_LOAD_TIMEOUT = 'keyLoadTimeOut',\n  // Triggered when an exception occurs while adding a sourceBuffer to MediaSource - data : { error : exception , mimeType : mimeType }\n  BUFFER_ADD_CODEC_ERROR = 'bufferAddCodecError',\n  // Triggered when source buffer(s) could not be created using level (manifest CODECS attribute), parsed media, or best guess codec(s) - data: { reason : error reason }\n  BUFFER_INCOMPATIBLE_CODECS_ERROR = 'bufferIncompatibleCodecsError',\n  // Identifier for a buffer append error - data: append error description\n  BUFFER_APPEND_ERROR = 'bufferAppendError',\n  // Identifier for a buffer appending error event - data: appending error description\n  BUFFER_APPENDING_ERROR = 'bufferAppendingError',\n  // Identifier for a buffer stalled error event\n  BUFFER_STALLED_ERROR = 'bufferStalledError',\n  // Identifier for a buffer full event\n  BUFFER_FULL_ERROR = 'bufferFullError',\n  // Identifier for a buffer seek over hole event\n  BUFFER_SEEK_OVER_HOLE = 'bufferSeekOverHole',\n  // Identifier for a buffer nudge on stall (playback is stuck although currentTime is in a buffered area)\n  BUFFER_NUDGE_ON_STALL = 'bufferNudgeOnStall',\n  // Identifier for an internal exception happening inside hls.js while handling an event\n  INTERNAL_EXCEPTION = 'internalException',\n  // Identifier for an internal call to abort a loader\n  INTERNAL_ABORTED = 'aborted',\n  // Uncategorized error\n  UNKNOWN = 'unknown',\n}\n","export interface ILogFunction {\n  (message?: any, ...optionalParams: any[]): void;\n}\n\nexport interface ILogger {\n  trace: ILogFunction;\n  debug: ILogFunction;\n  log: ILogFunction;\n  warn: ILogFunction;\n  info: ILogFunction;\n  error: ILogFunction;\n}\n\nconst noop: ILogFunction = function () {};\n\nconst fakeLogger: ILogger = {\n  trace: noop,\n  debug: noop,\n  log: noop,\n  warn: noop,\n  info: noop,\n  error: noop,\n};\n\nlet exportedLogger: ILogger = fakeLogger;\n\n// let lastCallTime;\n// function formatMsgWithTimeInfo(type, msg) {\n//   const now = Date.now();\n//   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\n//   lastCallTime = now;\n//   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\n//   return msg;\n// }\n\nfunction consolePrintFn(type: string): ILogFunction {\n  const func: ILogFunction = self.console[type];\n  if (func) {\n    return func.bind(self.console, `[${type}] >`);\n  }\n  return noop;\n}\n\nfunction exportLoggerFunctions(\n  debugConfig: boolean | ILogger,\n  ...functions: string[]\n): void {\n  functions.forEach(function (type) {\n    exportedLogger[type] = debugConfig[type]\n      ? debugConfig[type].bind(debugConfig)\n      : consolePrintFn(type);\n  });\n}\n\nexport function enableLogs(debugConfig: boolean | ILogger, id: string): void {\n  // check that console is available\n  if (\n    (typeof console === 'object' && debugConfig === true) ||\n    typeof debugConfig === 'object'\n  ) {\n    exportLoggerFunctions(\n      debugConfig,\n      // Remove out from list here to hard-disable a log-level\n      // 'trace',\n      'debug',\n      'log',\n      'info',\n      'warn',\n      'error',\n    );\n    // Some browsers don't allow to use bind on console object anyway\n    // fallback to default if needed\n    try {\n      exportedLogger.log(\n        `Debug logs enabled for \"${id}\" in hls.js version ${__VERSION__}`,\n      );\n    } catch (e) {\n      exportedLogger = fakeLogger;\n    }\n  } else {\n    exportedLogger = fakeLogger;\n  }\n}\n\nexport const logger: ILogger = exportedLogger;\n","const DECIMAL_RESOLUTION_REGEX = /^(\\d+)x(\\d+)$/;\nconst ATTR_LIST_REGEX = /(.+?)=(\".*?\"|.*?)(?:,|$)/g;\n\n// adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\nexport class AttrList {\n  [key: string]: any;\n\n  constructor(attrs: string | Record<string, any>) {\n    if (typeof attrs === 'string') {\n      attrs = AttrList.parseAttrList(attrs);\n    }\n    Object.assign(this, attrs);\n  }\n\n  get clientAttrs(): string[] {\n    return Object.keys(this).filter((attr) => attr.substring(0, 2) === 'X-');\n  }\n\n  decimalInteger(attrName: string): number {\n    const intValue = parseInt(this[attrName], 10);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n\n    return intValue;\n  }\n\n  hexadecimalInteger(attrName: string) {\n    if (this[attrName]) {\n      let stringValue = (this[attrName] || '0x').slice(2);\n      stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\n\n      const value = new Uint8Array(stringValue.length / 2);\n      for (let i = 0; i < stringValue.length / 2; i++) {\n        value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\n      }\n\n      return value;\n    } else {\n      return null;\n    }\n  }\n\n  hexadecimalIntegerAsNumber(attrName: string): number {\n    const intValue = parseInt(this[attrName], 16);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n\n    return intValue;\n  }\n\n  decimalFloatingPoint(attrName: string): number {\n    return parseFloat(this[attrName]);\n  }\n\n  optionalFloat(attrName: string, defaultValue: number): number {\n    const value = this[attrName];\n    return value ? parseFloat(value) : defaultValue;\n  }\n\n  enumeratedString(attrName: string): string | undefined {\n    return this[attrName];\n  }\n\n  bool(attrName: string): boolean {\n    return this[attrName] === 'YES';\n  }\n\n  decimalResolution(attrName: string):\n    | {\n        width: number;\n        height: number;\n      }\n    | undefined {\n    const res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\n    if (res === null) {\n      return undefined;\n    }\n\n    return {\n      width: parseInt(res[1], 10),\n      height: parseInt(res[2], 10),\n    };\n  }\n\n  static parseAttrList(input: string): Record<string, any> {\n    let match;\n    const attrs = {};\n    const quote = '\"';\n    ATTR_LIST_REGEX.lastIndex = 0;\n    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\n      let value = match[2];\n\n      if (\n        value.indexOf(quote) === 0 &&\n        value.lastIndexOf(quote) === value.length - 1\n      ) {\n        value = value.slice(1, -1);\n      }\n      const name = match[1].trim();\n      attrs[name] = value;\n    }\n    return attrs;\n  }\n}\n","import { AttrList } from '../utils/attr-list';\nimport { logger } from '../utils/logger';\n\n// Avoid exporting const enum so that these values can be inlined\nconst enum DateRangeAttribute {\n  ID = 'ID',\n  CLASS = 'CLASS',\n  START_DATE = 'START-DATE',\n  DURATION = 'DURATION',\n  END_DATE = 'END-DATE',\n  END_ON_NEXT = 'END-ON-NEXT',\n  PLANNED_DURATION = 'PLANNED-DURATION',\n  SCTE35_OUT = 'SCTE35-OUT',\n  SCTE35_IN = 'SCTE35-IN',\n}\n\nexport function isDateRangeCueAttribute(attrName: string): boolean {\n  return (\n    attrName !== DateRangeAttribute.ID &&\n    attrName !== DateRangeAttribute.CLASS &&\n    attrName !== DateRangeAttribute.START_DATE &&\n    attrName !== DateRangeAttribute.DURATION &&\n    attrName !== DateRangeAttribute.END_DATE &&\n    attrName !== DateRangeAttribute.END_ON_NEXT\n  );\n}\n\nexport function isSCTE35Attribute(attrName: string): boolean {\n  return (\n    attrName === DateRangeAttribute.SCTE35_OUT ||\n    attrName === DateRangeAttribute.SCTE35_IN\n  );\n}\n\nexport class DateRange {\n  public attr: AttrList;\n  private _startDate: Date;\n  private _endDate?: Date;\n  private _badValueForSameId?: string;\n\n  constructor(dateRangeAttr: AttrList, dateRangeWithSameId?: DateRange) {\n    if (dateRangeWithSameId) {\n      const previousAttr = dateRangeWithSameId.attr;\n      for (const key in previousAttr) {\n        if (\n          Object.prototype.hasOwnProperty.call(dateRangeAttr, key) &&\n          dateRangeAttr[key] !== previousAttr[key]\n        ) {\n          logger.warn(\n            `DATERANGE tag attribute: \"${key}\" does not match for tags with ID: \"${dateRangeAttr.ID}\"`,\n          );\n          this._badValueForSameId = key;\n          break;\n        }\n      }\n      // Merge DateRange tags with the same ID\n      dateRangeAttr = Object.assign(\n        new AttrList({}),\n        previousAttr,\n        dateRangeAttr,\n      );\n    }\n    this.attr = dateRangeAttr;\n    this._startDate = new Date(dateRangeAttr[DateRangeAttribute.START_DATE]);\n    if (DateRangeAttribute.END_DATE in this.attr) {\n      const endDate = new Date(this.attr[DateRangeAttribute.END_DATE]);\n      if (Number.isFinite(endDate.getTime())) {\n        this._endDate = endDate;\n      }\n    }\n  }\n\n  get id(): string {\n    return this.attr.ID;\n  }\n\n  get class(): string {\n    return this.attr.CLASS;\n  }\n\n  get startDate(): Date {\n    return this._startDate;\n  }\n\n  get endDate(): Date | null {\n    if (this._endDate) {\n      return this._endDate;\n    }\n    const duration = this.duration;\n    if (duration !== null) {\n      return new Date(this._startDate.getTime() + duration * 1000);\n    }\n    return null;\n  }\n\n  get duration(): number | null {\n    if (DateRangeAttribute.DURATION in this.attr) {\n      const duration = this.attr.decimalFloatingPoint(\n        DateRangeAttribute.DURATION,\n      );\n      if (Number.isFinite(duration)) {\n        return duration;\n      }\n    } else if (this._endDate) {\n      return (this._endDate.getTime() - this._startDate.getTime()) / 1000;\n    }\n    return null;\n  }\n\n  get plannedDuration(): number | null {\n    if (DateRangeAttribute.PLANNED_DURATION in this.attr) {\n      return this.attr.decimalFloatingPoint(\n        DateRangeAttribute.PLANNED_DURATION,\n      );\n    }\n    return null;\n  }\n\n  get endOnNext(): boolean {\n    return this.attr.bool(DateRangeAttribute.END_ON_NEXT);\n  }\n\n  get isValid(): boolean {\n    return (\n      !!this.id &&\n      !this._badValueForSameId &&\n      Number.isFinite(this.startDate.getTime()) &&\n      (this.duration === null || this.duration >= 0) &&\n      (!this.endOnNext || !!this.class)\n    );\n  }\n}\n","import type {\n  HlsPerformanceTiming,\n  HlsProgressivePerformanceTiming,\n  LoaderStats,\n} from '../types/loader';\n\nexport class LoadStats implements LoaderStats {\n  aborted: boolean = false;\n  loaded: number = 0;\n  retry: number = 0;\n  total: number = 0;\n  chunkCount: number = 0;\n  bwEstimate: number = 0;\n  loading: HlsProgressivePerformanceTiming = { start: 0, first: 0, end: 0 };\n  parsing: HlsPerformanceTiming = { start: 0, end: 0 };\n  buffering: HlsProgressivePerformanceTiming = { start: 0, first: 0, end: 0 };\n}\n","import { buildAbsoluteURL } from 'url-toolkit';\nimport { LevelKey } from './level-key';\nimport { LoadStats } from './load-stats';\nimport { AttrList } from '../utils/attr-list';\nimport type {\n  FragmentLoaderContext,\n  KeyLoaderContext,\n  Loader,\n  PlaylistLevelType,\n} from '../types/loader';\nimport type { KeySystemFormats } from '../utils/mediakeys-helper';\n\nexport const enum ElementaryStreamTypes {\n  AUDIO = 'audio',\n  VIDEO = 'video',\n  AUDIOVIDEO = 'audiovideo',\n}\n\nexport interface ElementaryStreamInfo {\n  startPTS: number;\n  endPTS: number;\n  startDTS: number;\n  endDTS: number;\n  partial?: boolean;\n}\n\nexport type ElementaryStreams = Record<\n  ElementaryStreamTypes,\n  ElementaryStreamInfo | null\n>;\n\nexport class BaseSegment {\n  private _byteRange: [number, number] | null = null;\n  private _url: string | null = null;\n\n  // baseurl is the URL to the playlist\n  public readonly baseurl: string;\n  // relurl is the portion of the URL that comes from inside the playlist.\n  public relurl?: string;\n  // Holds the types of data this fragment supports\n  public elementaryStreams: ElementaryStreams = {\n    [ElementaryStreamTypes.AUDIO]: null,\n    [ElementaryStreamTypes.VIDEO]: null,\n    [ElementaryStreamTypes.AUDIOVIDEO]: null,\n  };\n\n  constructor(baseurl: string) {\n    this.baseurl = baseurl;\n  }\n\n  // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array\n  setByteRange(value: string, previous?: BaseSegment) {\n    const params = value.split('@', 2);\n    let start: number;\n    if (params.length === 1) {\n      start = previous?.byteRangeEndOffset || 0;\n    } else {\n      start = parseInt(params[1]);\n    }\n    this._byteRange = [start, parseInt(params[0]) + start];\n  }\n\n  get byteRange(): [number, number] | [] {\n    if (!this._byteRange) {\n      return [];\n    }\n\n    return this._byteRange;\n  }\n\n  get byteRangeStartOffset(): number | undefined {\n    return this.byteRange[0];\n  }\n\n  get byteRangeEndOffset(): number | undefined {\n    return this.byteRange[1];\n  }\n\n  get url(): string {\n    if (!this._url && this.baseurl && this.relurl) {\n      this._url = buildAbsoluteURL(this.baseurl, this.relurl, {\n        alwaysNormalize: true,\n      });\n    }\n    return this._url || '';\n  }\n\n  set url(value: string) {\n    this._url = value;\n  }\n}\n\n/**\n * Object representing parsed data from an HLS Segment. Found in {@link hls.js#LevelDetails.fragments}.\n */\nexport class Fragment extends BaseSegment {\n  private _decryptdata: LevelKey | null = null;\n\n  public rawProgramDateTime: string | null = null;\n  public programDateTime: number | null = null;\n  public tagList: Array<string[]> = [];\n\n  // EXTINF has to be present for a m3u8 to be considered valid\n  public duration: number = 0;\n  // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'\n  public sn: number | 'initSegment' = 0;\n  // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption\n  // core difference from the private field _decryptdata is the lack of the initialized IV\n  // _decryptdata will set the IV for this segment based on the segment number in the fragment\n  public levelkeys?: { [key: string]: LevelKey };\n  // A string representing the fragment type\n  public readonly type: PlaylistLevelType;\n  // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading\n  public loader: Loader<FragmentLoaderContext> | null = null;\n  // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading\n  public keyLoader: Loader<KeyLoaderContext> | null = null;\n  // The level/track index to which the fragment belongs\n  public level: number = -1;\n  // The continuity counter of the fragment\n  public cc: number = 0;\n  // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n  public startPTS?: number;\n  // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n  public endPTS?: number;\n  // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n  public startDTS!: number;\n  // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n  public endDTS!: number;\n  // The start time of the fragment, as listed in the manifest. Updated after transmux complete.\n  public start: number = 0;\n  // Set by `updateFragPTSDTS` in level-helper\n  public deltaPTS?: number;\n  // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n  public maxStartPTS?: number;\n  // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n  public minEndPTS?: number;\n  // Load/parse timing information\n  public stats: LoadStats = new LoadStats();\n  // Init Segment bytes (unset for media segments)\n  public data?: Uint8Array;\n  // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered\n  public bitrateTest: boolean = false;\n  // #EXTINF  segment title\n  public title: string | null = null;\n  // The Media Initialization Section for this segment\n  public initSegment: Fragment | null = null;\n  // Fragment is the last fragment in the media playlist\n  public endList?: boolean;\n  // Fragment is marked by an EXT-X-GAP tag indicating that it does not contain media data and should not be loaded\n  public gap?: boolean;\n  // Deprecated\n  public urlId: number = 0;\n\n  constructor(type: PlaylistLevelType, baseurl: string) {\n    super(baseurl);\n    this.type = type;\n  }\n\n  get decryptdata(): LevelKey | null {\n    const { levelkeys } = this;\n    if (!levelkeys && !this._decryptdata) {\n      return null;\n    }\n\n    if (!this._decryptdata && this.levelkeys && !this.levelkeys.NONE) {\n      const key = this.levelkeys.identity;\n      if (key) {\n        this._decryptdata = key.getDecryptData(this.sn);\n      } else {\n        const keyFormats = Object.keys(this.levelkeys);\n        if (keyFormats.length === 1) {\n          return (this._decryptdata = this.levelkeys[\n            keyFormats[0]\n          ].getDecryptData(this.sn));\n        } else {\n          // Multiple keys. key-loader to call Fragment.setKeyFormat based on selected key-system.\n        }\n      }\n    }\n\n    return this._decryptdata;\n  }\n\n  get end(): number {\n    return this.start + this.duration;\n  }\n\n  get endProgramDateTime() {\n    if (this.programDateTime === null) {\n      return null;\n    }\n\n    if (!Number.isFinite(this.programDateTime)) {\n      return null;\n    }\n\n    const duration = !Number.isFinite(this.duration) ? 0 : this.duration;\n\n    return this.programDateTime + duration * 1000;\n  }\n\n  get encrypted() {\n    // At the m3u8-parser level we need to add support for manifest signalled keyformats\n    // when we want the fragment to start reporting that it is encrypted.\n    // Currently, keyFormat will only be set for identity keys\n    if (this._decryptdata?.encrypted) {\n      return true;\n    } else if (this.levelkeys) {\n      const keyFormats = Object.keys(this.levelkeys);\n      const len = keyFormats.length;\n      if (len > 1 || (len === 1 && this.levelkeys[keyFormats[0]].encrypted)) {\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  setKeyFormat(keyFormat: KeySystemFormats) {\n    if (this.levelkeys) {\n      const key = this.levelkeys[keyFormat];\n      if (key && !this._decryptdata) {\n        this._decryptdata = key.getDecryptData(this.sn);\n      }\n    }\n  }\n\n  abortRequests(): void {\n    this.loader?.abort();\n    this.keyLoader?.abort();\n  }\n\n  setElementaryStreamInfo(\n    type: ElementaryStreamTypes,\n    startPTS: number,\n    endPTS: number,\n    startDTS: number,\n    endDTS: number,\n    partial: boolean = false,\n  ) {\n    const { elementaryStreams } = this;\n    const info = elementaryStreams[type];\n    if (!info) {\n      elementaryStreams[type] = {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS,\n        partial,\n      };\n      return;\n    }\n\n    info.startPTS = Math.min(info.startPTS, startPTS);\n    info.endPTS = Math.max(info.endPTS, endPTS);\n    info.startDTS = Math.min(info.startDTS, startDTS);\n    info.endDTS = Math.max(info.endDTS, endDTS);\n  }\n\n  clearElementaryStreamInfo() {\n    const { elementaryStreams } = this;\n    elementaryStreams[ElementaryStreamTypes.AUDIO] = null;\n    elementaryStreams[ElementaryStreamTypes.VIDEO] = null;\n    elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;\n  }\n}\n\n/**\n * Object representing parsed data from an HLS Partial Segment. Found in {@link hls.js#LevelDetails.partList}.\n */\nexport class Part extends BaseSegment {\n  public readonly fragOffset: number = 0;\n  public readonly duration: number = 0;\n  public readonly gap: boolean = false;\n  public readonly independent: boolean = false;\n  public readonly relurl: string;\n  public readonly fragment: Fragment;\n  public readonly index: number;\n  public stats: LoadStats = new LoadStats();\n\n  constructor(\n    partAttrs: AttrList,\n    frag: Fragment,\n    baseurl: string,\n    index: number,\n    previous?: Part,\n  ) {\n    super(baseurl);\n    this.duration = partAttrs.decimalFloatingPoint('DURATION');\n    this.gap = partAttrs.bool('GAP');\n    this.independent = partAttrs.bool('INDEPENDENT');\n    this.relurl = partAttrs.enumeratedString('URI') as string;\n    this.fragment = frag;\n    this.index = index;\n    const byteRange = partAttrs.enumeratedString('BYTERANGE');\n    if (byteRange) {\n      this.setByteRange(byteRange, previous);\n    }\n    if (previous) {\n      this.fragOffset = previous.fragOffset + previous.duration;\n    }\n  }\n\n  get start(): number {\n    return this.fragment.start + this.fragOffset;\n  }\n\n  get end(): number {\n    return this.start + this.duration;\n  }\n\n  get loaded(): boolean {\n    const { elementaryStreams } = this;\n    return !!(\n      elementaryStreams.audio ||\n      elementaryStreams.video ||\n      elementaryStreams.audiovideo\n    );\n  }\n}\n","import { Part } from './fragment';\nimport type { Fragment } from './fragment';\nimport type { AttrList } from '../utils/attr-list';\nimport type { DateRange } from './date-range';\nimport type { VariableMap } from '../types/level';\n\nconst DEFAULT_TARGET_DURATION = 10;\n\n/**\n * Object representing parsed data from an HLS Media Playlist. Found in {@link hls.js#Level.details}.\n */\nexport class LevelDetails {\n  public PTSKnown: boolean = false;\n  public alignedSliding: boolean = false;\n  public averagetargetduration?: number;\n  public endCC: number = 0;\n  public endSN: number = 0;\n  public fragments: Fragment[];\n  public fragmentHint?: Fragment;\n  public partList: Part[] | null = null;\n  public dateRanges: Record<string, DateRange>;\n  public live: boolean = true;\n  public ageHeader: number = 0;\n  public advancedDateTime?: number;\n  public updated: boolean = true;\n  public advanced: boolean = true;\n  public availabilityDelay?: number; // Manifest reload synchronization\n  public misses: number = 0;\n  public startCC: number = 0;\n  public startSN: number = 0;\n  public startTimeOffset: number | null = null;\n  public targetduration: number = 0;\n  public totalduration: number = 0;\n  public type: string | null = null;\n  public url: string;\n  public m3u8: string = '';\n  public version: number | null = null;\n  public canBlockReload: boolean = false;\n  public canSkipUntil: number = 0;\n  public canSkipDateRanges: boolean = false;\n  public skippedSegments: number = 0;\n  public recentlyRemovedDateranges?: string[];\n  public partHoldBack: number = 0;\n  public holdBack: number = 0;\n  public partTarget: number = 0;\n  public preloadHint?: AttrList;\n  public renditionReports?: AttrList[];\n  public tuneInGoal: number = 0;\n  public deltaUpdateFailed?: boolean;\n  public driftStartTime: number = 0;\n  public driftEndTime: number = 0;\n  public driftStart: number = 0;\n  public driftEnd: number = 0;\n  public encryptedFragments: Fragment[];\n  public playlistParsingError: Error | null = null;\n  public variableList: VariableMap | null = null;\n  public hasVariableRefs = false;\n\n  constructor(baseUrl: string) {\n    this.fragments = [];\n    this.encryptedFragments = [];\n    this.dateRanges = {};\n    this.url = baseUrl;\n  }\n\n  reloaded(previous: LevelDetails | undefined) {\n    if (!previous) {\n      this.advanced = true;\n      this.updated = true;\n      return;\n    }\n    const partSnDiff = this.lastPartSn - previous.lastPartSn;\n    const partIndexDiff = this.lastPartIndex - previous.lastPartIndex;\n    this.updated =\n      this.endSN !== previous.endSN ||\n      !!partIndexDiff ||\n      !!partSnDiff ||\n      !this.live;\n    this.advanced =\n      this.endSN > previous.endSN ||\n      partSnDiff > 0 ||\n      (partSnDiff === 0 && partIndexDiff > 0);\n    if (this.updated || this.advanced) {\n      this.misses = Math.floor(previous.misses * 0.6);\n    } else {\n      this.misses = previous.misses + 1;\n    }\n    this.availabilityDelay = previous.availabilityDelay;\n  }\n\n  get hasProgramDateTime(): boolean {\n    if (this.fragments.length) {\n      return Number.isFinite(\n        this.fragments[this.fragments.length - 1].programDateTime as number,\n      );\n    }\n    return false;\n  }\n\n  get levelTargetDuration(): number {\n    return (\n      this.averagetargetduration ||\n      this.targetduration ||\n      DEFAULT_TARGET_DURATION\n    );\n  }\n\n  get drift(): number {\n    const runTime = this.driftEndTime - this.driftStartTime;\n    if (runTime > 0) {\n      const runDuration = this.driftEnd - this.driftStart;\n      return (runDuration * 1000) / runTime;\n    }\n    return 1;\n  }\n\n  get edge(): number {\n    return this.partEnd || this.fragmentEnd;\n  }\n\n  get partEnd(): number {\n    if (this.partList?.length) {\n      return this.partList[this.partList.length - 1].end;\n    }\n    return this.fragmentEnd;\n  }\n\n  get fragmentEnd(): number {\n    if (this.fragments?.length) {\n      return this.fragments[this.fragments.length - 1].end;\n    }\n    return 0;\n  }\n\n  get age(): number {\n    if (this.advancedDateTime) {\n      return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;\n    }\n    return 0;\n  }\n\n  get lastPartIndex(): number {\n    if (this.partList?.length) {\n      return this.partList[this.partList.length - 1].index;\n    }\n    return -1;\n  }\n\n  get lastPartSn(): number {\n    if (this.partList?.length) {\n      return this.partList[this.partList.length - 1].fragment.sn as number;\n    }\n    return this.endSN;\n  }\n}\n","export function base64ToBase64Url(base64encodedStr: string): string {\n  return base64encodedStr\n    .replace(/\\+/g, '-')\n    .replace(/\\//g, '_')\n    .replace(/=+$/, '');\n}\n\nexport function strToBase64Encode(str: string): string {\n  return btoa(str);\n}\n\nexport function base64DecodeToStr(str: string): string {\n  return atob(str);\n}\n\nexport function base64Encode(input: Uint8Array): string {\n  return btoa(String.fromCharCode(...input));\n}\n\nexport function base64UrlEncode(input: Uint8Array): string {\n  return base64ToBase64Url(base64Encode(input));\n}\n\nexport function base64Decode(base64encodedStr: string): Uint8Array {\n  return Uint8Array.from(atob(base64encodedStr), (c) => c.charCodeAt(0));\n}\n","import { base64Decode } from './numeric-encoding-utils';\n\nfunction getKeyIdBytes(str: string): Uint8Array {\n  const keyIdbytes = strToUtf8array(str).subarray(0, 16);\n  const paddedkeyIdbytes = new Uint8Array(16);\n  paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);\n  return paddedkeyIdbytes;\n}\n\nexport function changeEndianness(keyId: Uint8Array) {\n  const swap = function (array: Uint8Array, from: number, to: number) {\n    const cur = array[from];\n    array[from] = array[to];\n    array[to] = cur;\n  };\n\n  swap(keyId, 0, 3);\n  swap(keyId, 1, 2);\n  swap(keyId, 4, 5);\n  swap(keyId, 6, 7);\n}\n\nexport function convertDataUriToArrayBytes(uri: string): Uint8Array | null {\n  // data:[<media type][;attribute=value][;base64],<data>\n  const colonsplit = uri.split(':');\n  let keydata: Uint8Array | null = null;\n  if (colonsplit[0] === 'data' && colonsplit.length === 2) {\n    const semicolonsplit = colonsplit[1].split(';');\n    const commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');\n    if (commasplit.length === 2) {\n      const isbase64 = commasplit[0] === 'base64';\n      const data = commasplit[1];\n      if (isbase64) {\n        semicolonsplit.splice(-1, 1); // remove from processing\n        keydata = base64Decode(data);\n      } else {\n        keydata = getKeyIdBytes(data);\n      }\n    }\n  }\n  return keydata;\n}\n\nexport function strToUtf8array(str: string): Uint8Array {\n  return Uint8Array.from(unescape(encodeURIComponent(str)), (c) =>\n    c.charCodeAt(0),\n  );\n}\n","/** returns `undefined` is `self` is missing, e.g. in node */\nexport const optionalSelf = typeof self !== 'undefined' ? self : undefined;\n","import { optionalSelf } from './global';\nimport { changeEndianness } from './keysystem-util';\nimport { base64Decode } from './numeric-encoding-utils';\nimport type { DRMSystemOptions, EMEControllerConfig } from '../config';\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\n */\nexport const enum KeySystems {\n  CLEARKEY = 'org.w3.clearkey',\n  FAIRPLAY = 'com.apple.fps',\n  PLAYREADY = 'com.microsoft.playready',\n  WIDEVINE = 'com.widevine.alpha',\n}\n\n// Playlist #EXT-X-KEY KEYFORMAT values\nexport const enum KeySystemFormats {\n  CLEARKEY = 'org.w3.clearkey',\n  FAIRPLAY = 'com.apple.streamingkeydelivery',\n  PLAYREADY = 'com.microsoft.playready',\n  WIDEVINE = 'urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed',\n}\n\nexport function keySystemFormatToKeySystemDomain(\n  format: KeySystemFormats,\n): KeySystems | undefined {\n  switch (format) {\n    case KeySystemFormats.FAIRPLAY:\n      return KeySystems.FAIRPLAY;\n    case KeySystemFormats.PLAYREADY:\n      return KeySystems.PLAYREADY;\n    case KeySystemFormats.WIDEVINE:\n      return KeySystems.WIDEVINE;\n    case KeySystemFormats.CLEARKEY:\n      return KeySystems.CLEARKEY;\n  }\n}\n\n// System IDs for which we can extract a key ID from \"encrypted\" event PSSH\nexport const enum KeySystemIds {\n  CENC = '1077efecc0b24d02ace33c1e52e2fb4b',\n  CLEARKEY = 'e2719d58a985b3c9781ab030af78d30e',\n  FAIRPLAY = '94ce86fb07ff4f43adb893d2fa968ca2',\n  PLAYREADY = '9a04f07998404286ab92e65be0885f95',\n  WIDEVINE = 'edef8ba979d64acea3c827dcd51d21ed',\n}\n\nexport function keySystemIdToKeySystemDomain(\n  systemId: KeySystemIds,\n): KeySystems | undefined {\n  if (systemId === KeySystemIds.WIDEVINE) {\n    return KeySystems.WIDEVINE;\n  } else if (systemId === KeySystemIds.PLAYREADY) {\n    return KeySystems.PLAYREADY;\n  } else if (\n    systemId === KeySystemIds.CENC ||\n    systemId === KeySystemIds.CLEARKEY\n  ) {\n    return KeySystems.CLEARKEY;\n  }\n}\n\nexport function keySystemDomainToKeySystemFormat(\n  keySystem: KeySystems,\n): KeySystemFormats | undefined {\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      return KeySystemFormats.FAIRPLAY;\n    case KeySystems.PLAYREADY:\n      return KeySystemFormats.PLAYREADY;\n    case KeySystems.WIDEVINE:\n      return KeySystemFormats.WIDEVINE;\n    case KeySystems.CLEARKEY:\n      return KeySystemFormats.CLEARKEY;\n  }\n}\n\nexport function getKeySystemsForConfig(\n  config: EMEControllerConfig,\n): KeySystems[] {\n  const { drmSystems, widevineLicenseUrl } = config;\n  const keySystemsToAttempt: KeySystems[] = drmSystems\n    ? [\n        KeySystems.FAIRPLAY,\n        KeySystems.WIDEVINE,\n        KeySystems.PLAYREADY,\n        KeySystems.CLEARKEY,\n      ].filter((keySystem) => !!drmSystems[keySystem])\n    : [];\n  if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {\n    keySystemsToAttempt.push(KeySystems.WIDEVINE);\n  }\n  return keySystemsToAttempt;\n}\n\nexport type MediaKeyFunc = (\n  keySystem: KeySystems,\n  supportedConfigurations: MediaKeySystemConfiguration[],\n) => Promise<MediaKeySystemAccess>;\n\nexport const requestMediaKeySystemAccess = (function (): MediaKeyFunc | null {\n  if (optionalSelf?.navigator?.requestMediaKeySystemAccess) {\n    return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);\n  } else {\n    return null;\n  }\n})();\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\n */\nexport function getSupportedMediaKeySystemConfigurations(\n  keySystem: KeySystems,\n  audioCodecs: string[],\n  videoCodecs: string[],\n  drmSystemOptions: DRMSystemOptions,\n): MediaKeySystemConfiguration[] {\n  let initDataTypes: string[];\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      initDataTypes = ['cenc', 'sinf'];\n      break;\n    case KeySystems.WIDEVINE:\n    case KeySystems.PLAYREADY:\n      initDataTypes = ['cenc'];\n      break;\n    case KeySystems.CLEARKEY:\n      initDataTypes = ['cenc', 'keyids'];\n      break;\n    default:\n      throw new Error(`Unknown key-system: ${keySystem}`);\n  }\n  return createMediaKeySystemConfigurations(\n    initDataTypes,\n    audioCodecs,\n    videoCodecs,\n    drmSystemOptions,\n  );\n}\n\nfunction createMediaKeySystemConfigurations(\n  initDataTypes: string[],\n  audioCodecs: string[],\n  videoCodecs: string[],\n  drmSystemOptions: DRMSystemOptions,\n): MediaKeySystemConfiguration[] {\n  const baseConfig: MediaKeySystemConfiguration = {\n    initDataTypes: initDataTypes,\n    persistentState: drmSystemOptions.persistentState || 'optional',\n    distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'optional',\n    sessionTypes: drmSystemOptions.sessionTypes || [\n      drmSystemOptions.sessionType || 'temporary',\n    ],\n    audioCapabilities: audioCodecs.map((codec) => ({\n      contentType: `audio/mp4; codecs=\"${codec}\"`,\n      robustness: drmSystemOptions.audioRobustness || '',\n      encryptionScheme: drmSystemOptions.audioEncryptionScheme || null,\n    })),\n    videoCapabilities: videoCodecs.map((codec) => ({\n      contentType: `video/mp4; codecs=\"${codec}\"`,\n      robustness: drmSystemOptions.videoRobustness || '',\n      encryptionScheme: drmSystemOptions.videoEncryptionScheme || null,\n    })),\n  };\n\n  return [baseConfig];\n}\n\nexport function parsePlayReadyWRM(keyBytes: Uint8Array): Uint8Array | null {\n  const keyBytesUtf16 = new Uint16Array(\n    keyBytes.buffer,\n    keyBytes.byteOffset,\n    keyBytes.byteLength / 2,\n  );\n  const keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));\n\n  // Parse Playready WRMHeader XML\n  const xmlKeyBytes = keyByteStr.substring(\n    keyByteStr.indexOf('<'),\n    keyByteStr.length,\n  );\n  const parser = new DOMParser();\n  const xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');\n  const keyData = xmlDoc.getElementsByTagName('KID')[0];\n  if (keyData) {\n    const keyId = keyData.childNodes[0]\n      ? keyData.childNodes[0].nodeValue\n      : keyData.getAttribute('VALUE');\n    if (keyId) {\n      const keyIdArray = base64Decode(keyId).subarray(0, 16);\n      // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID\n      // KID value in ‘tenc’ is a big endian UUID GUID interpretation of UUID\n      changeEndianness(keyIdArray);\n      return keyIdArray;\n    }\n  }\n  return null;\n}\n","export function sliceUint8(\n  array: Uint8Array,\n  start?: number,\n  end?: number,\n): Uint8Array {\n  // @ts-expect-error This polyfills IE11 usage of Uint8Array slice.\n  // It always exists in the TypeScript definition so fails, but it fails at runtime on IE11.\n  return Uint8Array.prototype.slice\n    ? array.slice(start, end)\n    : new Uint8Array(Array.prototype.slice.call(array, start, end));\n}\n","type RawFrame = { type: string; size: number; data: Uint8Array };\n\n// breaking up those two types in order to clarify what is happening in the decoding path.\ntype DecodedFrame<T> = { key: string; data: T; info?: any };\nexport type Frame = DecodedFrame<ArrayBuffer | string>;\n\n/**\n * Returns true if an ID3 header can be found at offset in data\n * @param data - The data to search\n * @param offset - The offset at which to start searching\n */\nexport const isHeader = (data: Uint8Array, offset: number): boolean => {\n  /*\n   * http://id3.org/id3v2.3.0\n   * [0]     = 'I'\n   * [1]     = 'D'\n   * [2]     = '3'\n   * [3,4]   = {Version}\n   * [5]     = {Flags}\n   * [6-9]   = {ID3 Size}\n   *\n   * An ID3v2 tag can be detected with the following pattern:\n   *  $49 44 33 yy yy xx zz zz zz zz\n   * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\n   */\n  if (offset + 10 <= data.length) {\n    // look for 'ID3' identifier\n    if (\n      data[offset] === 0x49 &&\n      data[offset + 1] === 0x44 &&\n      data[offset + 2] === 0x33\n    ) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (\n          data[offset + 6] < 0x80 &&\n          data[offset + 7] < 0x80 &&\n          data[offset + 8] < 0x80 &&\n          data[offset + 9] < 0x80\n        ) {\n          return true;\n        }\n      }\n    }\n  }\n\n  return false;\n};\n\n/**\n * Returns true if an ID3 footer can be found at offset in data\n * @param data - The data to search\n * @param offset - The offset at which to start searching\n */\nexport const isFooter = (data: Uint8Array, offset: number): boolean => {\n  /*\n   * The footer is a copy of the header, but with a different identifier\n   */\n  if (offset + 10 <= data.length) {\n    // look for '3DI' identifier\n    if (\n      data[offset] === 0x33 &&\n      data[offset + 1] === 0x44 &&\n      data[offset + 2] === 0x49\n    ) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (\n          data[offset + 6] < 0x80 &&\n          data[offset + 7] < 0x80 &&\n          data[offset + 8] < 0x80 &&\n          data[offset + 9] < 0x80\n        ) {\n          return true;\n        }\n      }\n    }\n  }\n\n  return false;\n};\n\n/**\n * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\n * @param data - The data to search in\n * @param offset - The offset at which to start searching\n * @returns the block of data containing any ID3 tags found\n * or *undefined* if no header is found at the starting offset\n */\nexport const getID3Data = (\n  data: Uint8Array,\n  offset: number,\n): Uint8Array | undefined => {\n  const front = offset;\n  let length = 0;\n\n  while (isHeader(data, offset)) {\n    // ID3 header is 10 bytes\n    length += 10;\n\n    const size = readSize(data, offset + 6);\n    length += size;\n\n    if (isFooter(data, offset + 10)) {\n      // ID3 footer is 10 bytes\n      length += 10;\n    }\n\n    offset += length;\n  }\n\n  if (length > 0) {\n    return data.subarray(front, front + length);\n  }\n\n  return undefined;\n};\n\nconst readSize = (data: Uint8Array, offset: number): number => {\n  let size = 0;\n  size = (data[offset] & 0x7f) << 21;\n  size |= (data[offset + 1] & 0x7f) << 14;\n  size |= (data[offset + 2] & 0x7f) << 7;\n  size |= data[offset + 3] & 0x7f;\n  return size;\n};\n\nexport const canParse = (data: Uint8Array, offset: number): boolean => {\n  return (\n    isHeader(data, offset) &&\n    readSize(data, offset + 6) + 10 <= data.length - offset\n  );\n};\n\n/**\n * Searches for the Elementary Stream timestamp found in the ID3 data chunk\n * @param data - Block of data containing one or more ID3 tags\n */\nexport const getTimeStamp = (data: Uint8Array): number | undefined => {\n  const frames: Frame[] = getID3Frames(data);\n\n  for (let i = 0; i < frames.length; i++) {\n    const frame = frames[i];\n\n    if (isTimeStampFrame(frame)) {\n      return readTimeStamp(frame as DecodedFrame<ArrayBuffer>);\n    }\n  }\n\n  return undefined;\n};\n\n/**\n * Returns true if the ID3 frame is an Elementary Stream timestamp frame\n */\nexport const isTimeStampFrame = (frame: Frame): boolean => {\n  return (\n    frame &&\n    frame.key === 'PRIV' &&\n    frame.info === 'com.apple.streaming.transportStreamTimestamp'\n  );\n};\n\nconst getFrameData = (data: Uint8Array): RawFrame => {\n  /*\n  Frame ID       $xx xx xx xx (four characters)\n  Size           $xx xx xx xx\n  Flags          $xx xx\n  */\n  const type: string = String.fromCharCode(data[0], data[1], data[2], data[3]);\n  const size: number = readSize(data, 4);\n\n  // skip frame id, size, and flags\n  const offset = 10;\n\n  return { type, size, data: data.subarray(offset, offset + size) };\n};\n\n/**\n * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\n * @param id3Data - The ID3 data containing one or more ID3 tags\n */\nexport const getID3Frames = (id3Data: Uint8Array): Frame[] => {\n  let offset = 0;\n  const frames: Frame[] = [];\n\n  while (isHeader(id3Data, offset)) {\n    const size = readSize(id3Data, offset + 6);\n    // skip past ID3 header\n    offset += 10;\n    const end = offset + size;\n    // loop through frames in the ID3 tag\n    while (offset + 8 < end) {\n      const frameData: RawFrame = getFrameData(id3Data.subarray(offset));\n      const frame: Frame | undefined = decodeFrame(frameData);\n      if (frame) {\n        frames.push(frame);\n      }\n\n      // skip frame header and frame data\n      offset += frameData.size + 10;\n    }\n\n    if (isFooter(id3Data, offset)) {\n      offset += 10;\n    }\n  }\n\n  return frames;\n};\n\nexport const decodeFrame = (frame: RawFrame): Frame | undefined => {\n  if (frame.type === 'PRIV') {\n    return decodePrivFrame(frame);\n  } else if (frame.type[0] === 'W') {\n    return decodeURLFrame(frame);\n  }\n\n  return decodeTextFrame(frame);\n};\n\nconst decodePrivFrame = (\n  frame: RawFrame,\n): DecodedFrame<ArrayBuffer> | undefined => {\n  /*\n  Format: <text string>\\0<binary data>\n  */\n  if (frame.size < 2) {\n    return undefined;\n  }\n\n  const owner = utf8ArrayToStr(frame.data, true);\n  const privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\n\n  return { key: frame.type, info: owner, data: privateData.buffer };\n};\n\nconst decodeTextFrame = (frame: RawFrame): DecodedFrame<string> | undefined => {\n  if (frame.size < 2) {\n    return undefined;\n  }\n\n  if (frame.type === 'TXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{Value}\n    */\n    let index = 1;\n    const description = utf8ArrayToStr(frame.data.subarray(index), true);\n\n    index += description.length + 1;\n    const value = utf8ArrayToStr(frame.data.subarray(index));\n\n    return { key: frame.type, info: description, data: value };\n  }\n  /*\n  Format:\n  [0]   = {Text Encoding}\n  [1-?] = {Value}\n  */\n  const text = utf8ArrayToStr(frame.data.subarray(1));\n  return { key: frame.type, data: text };\n};\n\nconst decodeURLFrame = (frame: RawFrame): DecodedFrame<string> | undefined => {\n  if (frame.type === 'WXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{URL}\n    */\n    if (frame.size < 2) {\n      return undefined;\n    }\n\n    let index = 1;\n    const description: string = utf8ArrayToStr(\n      frame.data.subarray(index),\n      true,\n    );\n\n    index += description.length + 1;\n    const value: string = utf8ArrayToStr(frame.data.subarray(index));\n\n    return { key: frame.type, info: description, data: value };\n  }\n  /*\n  Format:\n  [0-?] = {URL}\n  */\n  const url: string = utf8ArrayToStr(frame.data);\n  return { key: frame.type, data: url };\n};\n\nconst readTimeStamp = (\n  timeStampFrame: DecodedFrame<ArrayBuffer>,\n): number | undefined => {\n  if (timeStampFrame.data.byteLength === 8) {\n    const data = new Uint8Array(timeStampFrame.data);\n    // timestamp is 33 bit expressed as a big-endian eight-octet number,\n    // with the upper 31 bits set to zero.\n    const pts33Bit = data[3] & 0x1;\n    let timestamp =\n      (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\n    timestamp /= 45;\n\n    if (pts33Bit) {\n      timestamp += 47721858.84;\n    } // 2^32 / 90\n\n    return Math.round(timestamp);\n  }\n\n  return undefined;\n};\n\n// http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n/* utf.js - UTF-8 <=> UTF-16 convertion\n *\n * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0\n * LastModified: Dec 25 1999\n * This library is free.  You can redistribute it and/or modify it.\n */\nexport const utf8ArrayToStr = (\n  array: Uint8Array,\n  exitOnNull: boolean = false,\n): string => {\n  const decoder = getTextDecoder();\n  if (decoder) {\n    const decoded = decoder.decode(array);\n\n    if (exitOnNull) {\n      // grab up to the first null\n      const idx = decoded.indexOf('\\0');\n      return idx !== -1 ? decoded.substring(0, idx) : decoded;\n    }\n\n    // remove any null characters\n    return decoded.replace(/\\0/g, '');\n  }\n\n  const len = array.length;\n  let c;\n  let char2;\n  let char3;\n  let out = '';\n  let i = 0;\n  while (i < len) {\n    c = array[i++];\n    if (c === 0x00 && exitOnNull) {\n      return out;\n    } else if (c === 0x00 || c === 0x03) {\n      // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\n      continue;\n    }\n    switch (c >> 4) {\n      case 0:\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n      case 5:\n      case 6:\n      case 7:\n        // 0xxxxxxx\n        out += String.fromCharCode(c);\n        break;\n      case 12:\n      case 13:\n        // 110x xxxx   10xx xxxx\n        char2 = array[i++];\n        out += String.fromCharCode(((c & 0x1f) << 6) | (char2 & 0x3f));\n        break;\n      case 14:\n        // 1110 xxxx  10xx xxxx  10xx xxxx\n        char2 = array[i++];\n        char3 = array[i++];\n        out += String.fromCharCode(\n          ((c & 0x0f) << 12) | ((char2 & 0x3f) << 6) | ((char3 & 0x3f) << 0),\n        );\n        break;\n      default:\n    }\n  }\n  return out;\n};\n\nexport const testables = {\n  decodeTextFrame: decodeTextFrame,\n};\n\nlet decoder: TextDecoder;\n\nfunction getTextDecoder() {\n  // On Play Station 4, TextDecoder is defined but partially implemented.\n  // Manual decoding option is preferable\n  if (navigator.userAgent.includes('PlayStation 4')) {\n    return;\n  }\n\n  if (!decoder && typeof self.TextDecoder !== 'undefined') {\n    decoder = new self.TextDecoder('utf-8');\n  }\n\n  return decoder;\n}\n","/**\n *  hex dump helper class\n */\n\nconst Hex = {\n  hexDump: function (array: Uint8Array) {\n    let str = '';\n    for (let i = 0; i < array.length; i++) {\n      let h = array[i].toString(16);\n      if (h.length < 2) {\n        h = '0' + h;\n      }\n\n      str += h;\n    }\n    return str;\n  },\n};\n\nexport default Hex;\n","import { ElementaryStreamTypes } from '../loader/fragment';\nimport { sliceUint8 } from './typed-array';\nimport { utf8ArrayToStr } from '../demux/id3';\nimport { logger } from '../utils/logger';\nimport Hex from './hex';\nimport type { KeySystemIds } from './mediakeys-helper';\nimport type { PassthroughTrack, UserdataSample } from '../types/demuxer';\nimport type { DecryptData } from '../loader/level-key';\n\nconst UINT32_MAX = Math.pow(2, 32) - 1;\nconst push = [].push;\n\n// We are using fixed track IDs for driving the MP4 remuxer\n// instead of following the TS PIDs.\n// There is no reason not to do this and some browsers/SourceBuffer-demuxers\n// may not like if there are TrackID \"switches\"\n// See https://github.com/video-dev/hls.js/issues/1331\n// Here we are mapping our internal track types to constant MP4 track IDs\n// With MSE currently one can only have one track of each, and we are muxing\n// whatever video/audio rendition in them.\nexport const RemuxerTrackIdConfig = {\n  video: 1,\n  audio: 2,\n  id3: 3,\n  text: 4,\n};\n\nexport function bin2str(data: Uint8Array): string {\n  return String.fromCharCode.apply(null, data);\n}\n\nexport function readUint16(buffer: Uint8Array, offset: number): number {\n  const val = (buffer[offset] << 8) | buffer[offset + 1];\n  return val < 0 ? 65536 + val : val;\n}\n\nexport function readUint32(buffer: Uint8Array, offset: number): number {\n  const val = readSint32(buffer, offset);\n  return val < 0 ? 4294967296 + val : val;\n}\n\nexport function readUint64(buffer: Uint8Array, offset: number) {\n  let result = readUint32(buffer, offset);\n  result *= Math.pow(2, 32);\n  result += readUint32(buffer, offset + 4);\n  return result;\n}\n\nexport function readSint32(buffer: Uint8Array, offset: number): number {\n  return (\n    (buffer[offset] << 24) |\n    (buffer[offset + 1] << 16) |\n    (buffer[offset + 2] << 8) |\n    buffer[offset + 3]\n  );\n}\n\nexport function writeUint32(buffer: Uint8Array, offset: number, value: number) {\n  buffer[offset] = value >> 24;\n  buffer[offset + 1] = (value >> 16) & 0xff;\n  buffer[offset + 2] = (value >> 8) & 0xff;\n  buffer[offset + 3] = value & 0xff;\n}\n\n// Find \"moof\" box\nexport function hasMoofData(data: Uint8Array): boolean {\n  const end = data.byteLength;\n  for (let i = 0; i < end; ) {\n    const size = readUint32(data, i);\n    if (\n      size > 8 &&\n      data[i + 4] === 0x6d &&\n      data[i + 5] === 0x6f &&\n      data[i + 6] === 0x6f &&\n      data[i + 7] === 0x66\n    ) {\n      return true;\n    }\n    i = size > 1 ? i + size : end;\n  }\n  return false;\n}\n\n// Find the data for a box specified by its path\nexport function findBox(data: Uint8Array, path: string[]): Uint8Array[] {\n  const results = [] as Uint8Array[];\n  if (!path.length) {\n    // short-circuit the search for empty paths\n    return results;\n  }\n  const end = data.byteLength;\n\n  for (let i = 0; i < end; ) {\n    const size = readUint32(data, i);\n    const type = bin2str(data.subarray(i + 4, i + 8));\n    const endbox = size > 1 ? i + size : end;\n    if (type === path[0]) {\n      if (path.length === 1) {\n        // this is the end of the path and we've found the box we were\n        // looking for\n        results.push(data.subarray(i + 8, endbox));\n      } else {\n        // recursively search for the next box along the path\n        const subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));\n        if (subresults.length) {\n          push.apply(results, subresults);\n        }\n      }\n    }\n    i = endbox;\n  }\n\n  // we've finished searching all of data\n  return results;\n}\n\ntype SidxInfo = {\n  earliestPresentationTime: number;\n  timescale: number;\n  version: number;\n  referencesCount: number;\n  references: any[];\n};\n\nexport function parseSegmentIndex(sidx: Uint8Array): SidxInfo | null {\n  const references: any[] = [];\n\n  const version = sidx[0];\n\n  // set initial offset, we skip the reference ID (not needed)\n  let index = 8;\n\n  const timescale = readUint32(sidx, index);\n  index += 4;\n\n  let earliestPresentationTime = 0;\n  let firstOffset = 0;\n\n  if (version === 0) {\n    earliestPresentationTime = readUint32(sidx, index);\n    firstOffset = readUint32(sidx, index + 4);\n    index += 8;\n  } else {\n    earliestPresentationTime = readUint64(sidx, index);\n    firstOffset = readUint64(sidx, index + 8);\n    index += 16;\n  }\n\n  // skip reserved\n  index += 2;\n\n  let startByte = sidx.length + firstOffset;\n\n  const referencesCount = readUint16(sidx, index);\n  index += 2;\n\n  for (let i = 0; i < referencesCount; i++) {\n    let referenceIndex = index;\n\n    const referenceInfo = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n\n    const referenceSize = referenceInfo & 0x7fffffff;\n    const referenceType = (referenceInfo & 0x80000000) >>> 31;\n\n    if (referenceType === 1) {\n      logger.warn('SIDX has hierarchical references (not supported)');\n      return null;\n    }\n\n    const subsegmentDuration = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n\n    references.push({\n      referenceSize,\n      subsegmentDuration, // unscaled\n      info: {\n        duration: subsegmentDuration / timescale,\n        start: startByte,\n        end: startByte + referenceSize - 1,\n      },\n    });\n\n    startByte += referenceSize;\n\n    // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\n    // for |sapDelta|.\n    referenceIndex += 4;\n\n    // skip to next ref\n    index = referenceIndex;\n  }\n\n  return {\n    earliestPresentationTime,\n    timescale,\n    version,\n    referencesCount,\n    references,\n  };\n}\n\n/**\n * Parses an MP4 initialization segment and extracts stream type and\n * timescale values for any declared tracks. Timescale values indicate the\n * number of clock ticks per second to assume for time-based values\n * elsewhere in the MP4.\n *\n * To determine the start time of an MP4, you need two pieces of\n * information: the timescale unit and the earliest base media decode\n * time. Multiple timescales can be specified within an MP4 but the\n * base media decode time is always expressed in the timescale from\n * the media header box for the track:\n * ```\n * moov > trak > mdia > mdhd.timescale\n * moov > trak > mdia > hdlr\n * ```\n * @param initSegment the bytes of the init segment\n * @returns a hash of track type to timescale values or null if\n * the init segment is malformed.\n */\n\nexport interface InitDataTrack {\n  timescale: number;\n  id: number;\n  codec: string;\n}\n\ntype HdlrType = ElementaryStreamTypes.AUDIO | ElementaryStreamTypes.VIDEO;\n\nexport interface InitData extends Array<any> {\n  [index: number]:\n    | {\n        timescale: number;\n        type: HdlrType;\n        default?: {\n          duration: number;\n          flags: number;\n        };\n      }\n    | undefined;\n  audio?: InitDataTrack;\n  video?: InitDataTrack;\n  caption?: InitDataTrack;\n}\n\nexport function parseInitSegment(initSegment: Uint8Array): InitData {\n  const result: InitData = [];\n  const traks = findBox(initSegment, ['moov', 'trak']);\n  for (let i = 0; i < traks.length; i++) {\n    const trak = traks[i];\n    const tkhd = findBox(trak, ['tkhd'])[0];\n    if (tkhd) {\n      let version = tkhd[0];\n      const trackId = readUint32(tkhd, version === 0 ? 12 : 20);\n      const mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n      if (mdhd) {\n        version = mdhd[0];\n        const timescale = readUint32(mdhd, version === 0 ? 12 : 20);\n        const hdlr = findBox(trak, ['mdia', 'hdlr'])[0];\n        if (hdlr) {\n          const hdlrType = bin2str(hdlr.subarray(8, 12));\n          const type: HdlrType | undefined = {\n            soun: ElementaryStreamTypes.AUDIO as const,\n            vide: ElementaryStreamTypes.VIDEO as const,\n          }[hdlrType];\n          if (type) {\n            // Parse codec details\n            const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n            const stsdData = parseStsd(stsd);\n            result[trackId] = { timescale, type };\n            result[type] = { timescale, id: trackId, ...stsdData };\n          }\n        }\n      }\n    }\n  }\n\n  const trex = findBox(initSegment, ['moov', 'mvex', 'trex']);\n  trex.forEach((trex) => {\n    const trackId = readUint32(trex, 4);\n    const track = result[trackId];\n    if (track) {\n      track.default = {\n        duration: readUint32(trex, 12),\n        flags: readUint32(trex, 20),\n      };\n    }\n  });\n\n  return result;\n}\n\nfunction parseStsd(stsd: Uint8Array): { codec: string; encrypted: boolean } {\n  const sampleEntries = stsd.subarray(8);\n  const sampleEntriesEnd = sampleEntries.subarray(8 + 78);\n  const fourCC = bin2str(sampleEntries.subarray(4, 8));\n  let codec = fourCC;\n  const encrypted = fourCC === 'enca' || fourCC === 'encv';\n  if (encrypted) {\n    const encBox = findBox(sampleEntries, [fourCC])[0];\n    const encBoxChildren = encBox.subarray(fourCC === 'enca' ? 28 : 78);\n    const sinfs = findBox(encBoxChildren, ['sinf']);\n    sinfs.forEach((sinf) => {\n      const schm = findBox(sinf, ['schm'])[0];\n      if (schm) {\n        const scheme = bin2str(schm.subarray(4, 8));\n        if (scheme === 'cbcs' || scheme === 'cenc') {\n          const frma = findBox(sinf, ['frma'])[0];\n          if (frma) {\n            // for encrypted content codec fourCC will be in frma\n            codec = bin2str(frma);\n          }\n        }\n      }\n    });\n  }\n  switch (codec) {\n    case 'avc1':\n    case 'avc2':\n    case 'avc3':\n    case 'avc4': {\n      // extract profile + compatibility + level out of avcC box\n      const avcCBox = findBox(sampleEntriesEnd, ['avcC'])[0];\n      codec += '.' + toHex(avcCBox[1]) + toHex(avcCBox[2]) + toHex(avcCBox[3]);\n      break;\n    }\n    case 'mp4a': {\n      const codecBox = findBox(sampleEntries, [fourCC])[0];\n      const esdsBox = findBox(codecBox.subarray(28), ['esds'])[0];\n      if (esdsBox && esdsBox.length > 12) {\n        let i = 4;\n        // ES Descriptor tag\n        if (esdsBox[i++] !== 0x03) {\n          break;\n        }\n        i = skipBERInteger(esdsBox, i);\n        i += 2; // skip es_id;\n        const flags = esdsBox[i++];\n        if (flags & 0x80) {\n          i += 2; // skip dependency es_id\n        }\n        if (flags & 0x40) {\n          i += esdsBox[i++]; // skip URL\n        }\n        // Decoder config descriptor\n        if (esdsBox[i++] !== 0x04) {\n          break;\n        }\n        i = skipBERInteger(esdsBox, i);\n        const objectType = esdsBox[i++];\n        if (objectType === 0x40) {\n          codec += '.' + toHex(objectType);\n        } else {\n          break;\n        }\n        i += 12;\n        // Decoder specific info\n        if (esdsBox[i++] !== 0x05) {\n          break;\n        }\n        i = skipBERInteger(esdsBox, i);\n        const firstByte = esdsBox[i++];\n        let audioObjectType = (firstByte & 0xf8) >> 3;\n        if (audioObjectType === 31) {\n          audioObjectType +=\n            1 + ((firstByte & 0x7) << 3) + ((esdsBox[i] & 0xe0) >> 5);\n        }\n        codec += '.' + audioObjectType;\n      }\n      break;\n    }\n    case 'hvc1':\n    case 'hev1': {\n      const hvcCBox = findBox(sampleEntriesEnd, ['hvcC'])[0];\n      const profileByte = hvcCBox[1];\n      const profileSpace = ['', 'A', 'B', 'C'][profileByte >> 6];\n      const generalProfileIdc = profileByte & 0x1f;\n      const profileCompat = readUint32(hvcCBox, 2);\n      const tierFlag = (profileByte & 0x20) >> 5 ? 'H' : 'L';\n      const levelIDC = hvcCBox[12];\n      const constraintIndicator = hvcCBox.subarray(6, 12);\n      codec += '.' + profileSpace + generalProfileIdc;\n      codec += '.' + profileCompat.toString(16).toUpperCase();\n      codec += '.' + tierFlag + levelIDC;\n      let constraintString = '';\n      for (let i = constraintIndicator.length; i--; ) {\n        const byte = constraintIndicator[i];\n        if (byte || constraintString) {\n          const encodedByte = byte.toString(16).toUpperCase();\n          constraintString = '.' + encodedByte + constraintString;\n        }\n      }\n      codec += constraintString;\n      break;\n    }\n    case 'dvh1':\n    case 'dvhe': {\n      const dvcCBox = findBox(sampleEntriesEnd, ['dvcC'])[0];\n      const profile = (dvcCBox[2] >> 1) & 0x7f;\n      const level = ((dvcCBox[2] << 5) & 0x20) | ((dvcCBox[3] >> 3) & 0x1f);\n      codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level);\n      break;\n    }\n    case 'vp09': {\n      const vpcCBox = findBox(sampleEntriesEnd, ['vpcC'])[0];\n      const profile = vpcCBox[4];\n      const level = vpcCBox[5];\n      const bitDepth = (vpcCBox[6] >> 4) & 0x0f;\n      codec +=\n        '.' +\n        addLeadingZero(profile) +\n        '.' +\n        addLeadingZero(level) +\n        '.' +\n        addLeadingZero(bitDepth);\n      break;\n    }\n    case 'av01': {\n      const av1CBox = findBox(sampleEntriesEnd, ['av1C'])[0];\n      const profile = av1CBox[1] >>> 5;\n      const level = av1CBox[1] & 0x1f;\n      const tierFlag = av1CBox[2] >>> 7 ? 'H' : 'M';\n      const highBitDepth = (av1CBox[2] & 0x40) >> 6;\n      const twelveBit = (av1CBox[2] & 0x20) >> 5;\n      const bitDepth =\n        profile === 2 && highBitDepth\n          ? twelveBit\n            ? 12\n            : 10\n          : highBitDepth\n            ? 10\n            : 8;\n      const monochrome = (av1CBox[2] & 0x10) >> 4;\n      const chromaSubsamplingX = (av1CBox[2] & 0x08) >> 3;\n      const chromaSubsamplingY = (av1CBox[2] & 0x04) >> 2;\n      const chromaSamplePosition = av1CBox[2] & 0x03;\n      // TODO: parse color_description_present_flag\n      // default it to BT.709/limited range for now\n      // more info https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox-syntax\n      const colorPrimaries = 1;\n      const transferCharacteristics = 1;\n      const matrixCoefficients = 1;\n      const videoFullRangeFlag = 0;\n      codec +=\n        '.' +\n        profile +\n        '.' +\n        addLeadingZero(level) +\n        tierFlag +\n        '.' +\n        addLeadingZero(bitDepth) +\n        '.' +\n        monochrome +\n        '.' +\n        chromaSubsamplingX +\n        chromaSubsamplingY +\n        chromaSamplePosition +\n        '.' +\n        addLeadingZero(colorPrimaries) +\n        '.' +\n        addLeadingZero(transferCharacteristics) +\n        '.' +\n        addLeadingZero(matrixCoefficients) +\n        '.' +\n        videoFullRangeFlag;\n      break;\n    }\n    case 'ac-3':\n    case 'ec-3':\n    case 'alac':\n    case 'fLaC':\n    case 'Opus':\n    default:\n      break;\n  }\n  return { codec, encrypted };\n}\n\nfunction skipBERInteger(bytes: Uint8Array, i: number): number {\n  const limit = i + 5;\n  while (bytes[i++] & 0x80 && i < limit) {}\n  return i;\n}\n\nfunction toHex(x: number): string {\n  return ('0' + x.toString(16).toUpperCase()).slice(-2);\n}\n\nfunction addLeadingZero(num: number): string {\n  return (num < 10 ? '0' : '') + num;\n}\n\nexport function patchEncyptionData(\n  initSegment: Uint8Array | undefined,\n  decryptdata: DecryptData | null,\n): Uint8Array | undefined {\n  if (!initSegment || !decryptdata) {\n    return initSegment;\n  }\n  const keyId = decryptdata.keyId;\n  if (keyId && decryptdata.isCommonEncryption) {\n    const traks = findBox(initSegment, ['moov', 'trak']);\n    traks.forEach((trak) => {\n      const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n\n      // skip the sample entry count\n      const sampleEntries = stsd.subarray(8);\n      let encBoxes = findBox(sampleEntries, ['enca']);\n      const isAudio = encBoxes.length > 0;\n      if (!isAudio) {\n        encBoxes = findBox(sampleEntries, ['encv']);\n      }\n      encBoxes.forEach((enc) => {\n        const encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);\n        const sinfBoxes = findBox(encBoxChildren, ['sinf']);\n        sinfBoxes.forEach((sinf) => {\n          const tenc = parseSinf(sinf);\n          if (tenc) {\n            // Look for default key id (keyID offset is always 8 within the tenc box):\n            const tencKeyId = tenc.subarray(8, 24);\n            if (!tencKeyId.some((b) => b !== 0)) {\n              logger.log(\n                `[eme] Patching keyId in 'enc${\n                  isAudio ? 'a' : 'v'\n                }>sinf>>tenc' box: ${Hex.hexDump(tencKeyId)} -> ${Hex.hexDump(\n                  keyId,\n                )}`,\n              );\n              tenc.set(keyId, 8);\n            }\n          }\n        });\n      });\n    });\n  }\n\n  return initSegment;\n}\n\nexport function parseSinf(sinf: Uint8Array): Uint8Array | null {\n  const schm = findBox(sinf, ['schm'])[0];\n  if (schm) {\n    const scheme = bin2str(schm.subarray(4, 8));\n    if (scheme === 'cbcs' || scheme === 'cenc') {\n      return findBox(sinf, ['schi', 'tenc'])[0];\n    }\n  }\n  return null;\n}\n\n/**\n * Determine the base media decode start time, in seconds, for an MP4\n * fragment. If multiple fragments are specified, the earliest time is\n * returned.\n *\n * The base media decode time can be parsed from track fragment\n * metadata:\n * ```\n * moof > traf > tfdt.baseMediaDecodeTime\n * ```\n * It requires the timescale value from the mdhd to interpret.\n *\n * @param initData - a hash of track type to timescale values\n * @param fmp4 - the bytes of the mp4 fragment\n * @returns the earliest base media decode start time for the\n * fragment, in seconds\n */\nexport function getStartDTS(\n  initData: InitData,\n  fmp4: Uint8Array,\n): number | null {\n  // we need info from two children of each track fragment box\n  return findBox(fmp4, ['moof', 'traf']).reduce(\n    (result: number | null, traf) => {\n      const tfdt = findBox(traf, ['tfdt'])[0];\n      const version = tfdt[0];\n      const start = findBox(traf, ['tfhd']).reduce(\n        (result: number | null, tfhd) => {\n          // get the track id from the tfhd\n          const id = readUint32(tfhd, 4);\n          const track = initData[id];\n          if (track) {\n            let baseTime = readUint32(tfdt, 4);\n            if (version === 1) {\n              // If value is too large, assume signed 64-bit. Negative track fragment decode times are invalid, but they exist in the wild.\n              // This prevents large values from being used for initPTS, which can cause playlist sync issues.\n              // https://github.com/video-dev/hls.js/issues/5303\n              if (baseTime === UINT32_MAX) {\n                logger.warn(\n                  `[mp4-demuxer]: Ignoring assumed invalid signed 64-bit track fragment decode time`,\n                );\n                return result;\n              }\n              baseTime *= UINT32_MAX + 1;\n              baseTime += readUint32(tfdt, 8);\n            }\n            // assume a 90kHz clock if no timescale was specified\n            const scale = track.timescale || 90e3;\n            // convert base time to seconds\n            const startTime = baseTime / scale;\n            if (\n              Number.isFinite(startTime) &&\n              (result === null || startTime < result)\n            ) {\n              return startTime;\n            }\n          }\n          return result;\n        },\n        null,\n      );\n      if (\n        start !== null &&\n        Number.isFinite(start) &&\n        (result === null || start < result)\n      ) {\n        return start;\n      }\n      return result;\n    },\n    null,\n  );\n}\n\n/*\n  For Reference:\n  aligned(8) class TrackFragmentHeaderBox\n           extends FullBox(‘tfhd’, 0, tf_flags){\n     unsigned int(32)  track_ID;\n     // all the following are optional fields\n     unsigned int(64)  base_data_offset;\n     unsigned int(32)  sample_description_index;\n     unsigned int(32)  default_sample_duration;\n     unsigned int(32)  default_sample_size;\n     unsigned int(32)  default_sample_flags\n  }\n */\nexport function getDuration(data: Uint8Array, initData: InitData) {\n  let rawDuration = 0;\n  let videoDuration = 0;\n  let audioDuration = 0;\n  const trafs = findBox(data, ['moof', 'traf']);\n  for (let i = 0; i < trafs.length; i++) {\n    const traf = trafs[i];\n    // There is only one tfhd & trun per traf\n    // This is true for CMAF style content, and we should perhaps check the ftyp\n    // and only look for a single trun then, but for ISOBMFF we should check\n    // for multiple track runs.\n    const tfhd = findBox(traf, ['tfhd'])[0];\n    // get the track id from the tfhd\n    const id = readUint32(tfhd, 4);\n    const track = initData[id];\n    if (!track) {\n      continue;\n    }\n    const trackDefault = track.default;\n    const tfhdFlags = readUint32(tfhd, 0) | trackDefault?.flags!;\n    let sampleDuration: number | undefined = trackDefault?.duration;\n    if (tfhdFlags & 0x000008) {\n      // 0x000008 indicates the presence of the default_sample_duration field\n      if (tfhdFlags & 0x000002) {\n        // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration\n        // If present, the default_sample_duration exists at byte offset 12\n        sampleDuration = readUint32(tfhd, 12);\n      } else {\n        // Otherwise, the duration is at byte offset 8\n        sampleDuration = readUint32(tfhd, 8);\n      }\n    }\n    // assume a 90kHz clock if no timescale was specified\n    const timescale = track.timescale || 90e3;\n    const truns = findBox(traf, ['trun']);\n    for (let j = 0; j < truns.length; j++) {\n      rawDuration = computeRawDurationFromSamples(truns[j]);\n      if (!rawDuration && sampleDuration) {\n        const sampleCount = readUint32(truns[j], 4);\n        rawDuration = sampleDuration * sampleCount;\n      }\n      if (track.type === ElementaryStreamTypes.VIDEO) {\n        videoDuration += rawDuration / timescale;\n      } else if (track.type === ElementaryStreamTypes.AUDIO) {\n        audioDuration += rawDuration / timescale;\n      }\n    }\n  }\n  if (videoDuration === 0 && audioDuration === 0) {\n    // If duration samples are not available in the traf use sidx subsegment_duration\n    let sidxMinStart = Infinity;\n    let sidxMaxEnd = 0;\n    let sidxDuration = 0;\n    const sidxs = findBox(data, ['sidx']);\n    for (let i = 0; i < sidxs.length; i++) {\n      const sidx = parseSegmentIndex(sidxs[i]);\n      if (sidx?.references) {\n        sidxMinStart = Math.min(\n          sidxMinStart,\n          sidx.earliestPresentationTime / sidx.timescale,\n        );\n        const subSegmentDuration = sidx.references.reduce(\n          (dur, ref) => dur + ref.info.duration || 0,\n          0,\n        );\n        sidxMaxEnd = Math.max(\n          sidxMaxEnd,\n          subSegmentDuration + sidx.earliestPresentationTime / sidx.timescale,\n        );\n        sidxDuration = sidxMaxEnd - sidxMinStart;\n      }\n    }\n    if (sidxDuration && Number.isFinite(sidxDuration)) {\n      return sidxDuration;\n    }\n  }\n  if (videoDuration) {\n    return videoDuration;\n  }\n  return audioDuration;\n}\n\n/*\n  For Reference:\n  aligned(8) class TrackRunBox\n           extends FullBox(‘trun’, version, tr_flags) {\n     unsigned int(32)  sample_count;\n     // the following are optional fields\n     signed int(32) data_offset;\n     unsigned int(32)  first_sample_flags;\n     // all fields in the following array are optional\n     {\n        unsigned int(32)  sample_duration;\n        unsigned int(32)  sample_size;\n        unsigned int(32)  sample_flags\n        if (version == 0)\n           { unsigned int(32)\n        else\n           { signed int(32)\n     }[ sample_count ]\n  }\n */\nexport function computeRawDurationFromSamples(trun): number {\n  const flags = readUint32(trun, 0);\n  // Flags are at offset 0, non-optional sample_count is at offset 4. Therefore we start 8 bytes in.\n  // Each field is an int32, which is 4 bytes\n  let offset = 8;\n  // data-offset-present flag\n  if (flags & 0x000001) {\n    offset += 4;\n  }\n  // first-sample-flags-present flag\n  if (flags & 0x000004) {\n    offset += 4;\n  }\n\n  let duration = 0;\n  const sampleCount = readUint32(trun, 4);\n  for (let i = 0; i < sampleCount; i++) {\n    // sample-duration-present flag\n    if (flags & 0x000100) {\n      const sampleDuration = readUint32(trun, offset);\n      duration += sampleDuration;\n      offset += 4;\n    }\n    // sample-size-present flag\n    if (flags & 0x000200) {\n      offset += 4;\n    }\n    // sample-flags-present flag\n    if (flags & 0x000400) {\n      offset += 4;\n    }\n    // sample-composition-time-offsets-present flag\n    if (flags & 0x000800) {\n      offset += 4;\n    }\n  }\n  return duration;\n}\n\nexport function offsetStartDTS(\n  initData: InitData,\n  fmp4: Uint8Array,\n  timeOffset: number,\n) {\n  findBox(fmp4, ['moof', 'traf']).forEach((traf) => {\n    findBox(traf, ['tfhd']).forEach((tfhd) => {\n      // get the track id from the tfhd\n      const id = readUint32(tfhd, 4);\n      const track = initData[id];\n      if (!track) {\n        return;\n      }\n      // assume a 90kHz clock if no timescale was specified\n      const timescale = track.timescale || 90e3;\n      // get the base media decode time from the tfdt\n      findBox(traf, ['tfdt']).forEach((tfdt) => {\n        const version = tfdt[0];\n        const offset = timeOffset * timescale;\n        if (offset) {\n          let baseMediaDecodeTime = readUint32(tfdt, 4);\n          if (version === 0) {\n            baseMediaDecodeTime -= offset;\n            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n            writeUint32(tfdt, 4, baseMediaDecodeTime);\n          } else {\n            baseMediaDecodeTime *= Math.pow(2, 32);\n            baseMediaDecodeTime += readUint32(tfdt, 8);\n            baseMediaDecodeTime -= offset;\n            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n            const upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\n            const lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n            writeUint32(tfdt, 4, upper);\n            writeUint32(tfdt, 8, lower);\n          }\n        }\n      });\n    });\n  });\n}\n\n// TODO: Check if the last moof+mdat pair is part of the valid range\nexport function segmentValidRange(data: Uint8Array): SegmentedRange {\n  const segmentedRange: SegmentedRange = {\n    valid: null,\n    remainder: null,\n  };\n\n  const moofs = findBox(data, ['moof']);\n  if (moofs.length < 2) {\n    segmentedRange.remainder = data;\n    return segmentedRange;\n  }\n  const last = moofs[moofs.length - 1];\n  // Offset by 8 bytes; findBox offsets the start by as much\n  segmentedRange.valid = sliceUint8(data, 0, last.byteOffset - 8);\n  segmentedRange.remainder = sliceUint8(data, last.byteOffset - 8);\n  return segmentedRange;\n}\n\nexport interface SegmentedRange {\n  valid: Uint8Array | null;\n  remainder: Uint8Array | null;\n}\n\nexport function appendUint8Array(\n  data1: Uint8Array,\n  data2: Uint8Array,\n): Uint8Array {\n  const temp = new Uint8Array(data1.length + data2.length);\n  temp.set(data1);\n  temp.set(data2, data1.length);\n\n  return temp;\n}\n\nexport interface IEmsgParsingData {\n  schemeIdUri: string;\n  value: string;\n  timeScale: number;\n  presentationTimeDelta?: number;\n  presentationTime?: number;\n  eventDuration: number;\n  id: number;\n  payload: Uint8Array;\n}\n\nexport function parseSamples(\n  timeOffset: number,\n  track: PassthroughTrack,\n): UserdataSample[] {\n  const seiSamples = [] as UserdataSample[];\n  const videoData = track.samples;\n  const timescale = track.timescale;\n  const trackId = track.id;\n  let isHEVCFlavor = false;\n\n  const moofs = findBox(videoData, ['moof']);\n  moofs.map((moof) => {\n    const moofOffset = moof.byteOffset - 8;\n    const trafs = findBox(moof, ['traf']);\n    trafs.map((traf) => {\n      // get the base media decode time from the tfdt\n      const baseTime = findBox(traf, ['tfdt']).map((tfdt) => {\n        const version = tfdt[0];\n        let result = readUint32(tfdt, 4);\n        if (version === 1) {\n          result *= Math.pow(2, 32);\n          result += readUint32(tfdt, 8);\n        }\n        return result / timescale;\n      })[0];\n\n      if (baseTime !== undefined) {\n        timeOffset = baseTime;\n      }\n\n      return findBox(traf, ['tfhd']).map((tfhd) => {\n        const id = readUint32(tfhd, 4);\n        const tfhdFlags = readUint32(tfhd, 0) & 0xffffff;\n        const baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;\n        const sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;\n        const defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;\n        let defaultSampleDuration = 0;\n        const defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;\n        let defaultSampleSize = 0;\n        const defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;\n        let tfhdOffset = 8;\n\n        if (id === trackId) {\n          if (baseDataOffsetPresent) {\n            tfhdOffset += 8;\n          }\n          if (sampleDescriptionIndexPresent) {\n            tfhdOffset += 4;\n          }\n          if (defaultSampleDurationPresent) {\n            defaultSampleDuration = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleSizePresent) {\n            defaultSampleSize = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleFlagsPresent) {\n            tfhdOffset += 4;\n          }\n          if (track.type === 'video') {\n            isHEVCFlavor = isHEVC(track.codec);\n          }\n\n          findBox(traf, ['trun']).map((trun) => {\n            const version = trun[0];\n            const flags = readUint32(trun, 0) & 0xffffff;\n            const dataOffsetPresent = (flags & 0x000001) !== 0;\n            let dataOffset = 0;\n            const firstSampleFlagsPresent = (flags & 0x000004) !== 0;\n            const sampleDurationPresent = (flags & 0x000100) !== 0;\n            let sampleDuration = 0;\n            const sampleSizePresent = (flags & 0x000200) !== 0;\n            let sampleSize = 0;\n            const sampleFlagsPresent = (flags & 0x000400) !== 0;\n            const sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;\n            let compositionOffset = 0;\n            const sampleCount = readUint32(trun, 4);\n            let trunOffset = 8; // past version, flags, and sample count\n\n            if (dataOffsetPresent) {\n              dataOffset = readUint32(trun, trunOffset);\n              trunOffset += 4;\n            }\n            if (firstSampleFlagsPresent) {\n              trunOffset += 4;\n            }\n\n            let sampleOffset = dataOffset + moofOffset;\n\n            for (let ix = 0; ix < sampleCount; ix++) {\n              if (sampleDurationPresent) {\n                sampleDuration = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleDuration = defaultSampleDuration;\n              }\n              if (sampleSizePresent) {\n                sampleSize = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleSize = defaultSampleSize;\n              }\n              if (sampleFlagsPresent) {\n                trunOffset += 4;\n              }\n              if (sampleCompositionOffsetsPresent) {\n                if (version === 0) {\n                  compositionOffset = readUint32(trun, trunOffset);\n                } else {\n                  compositionOffset = readSint32(trun, trunOffset);\n                }\n                trunOffset += 4;\n              }\n              if (track.type === ElementaryStreamTypes.VIDEO) {\n                let naluTotalSize = 0;\n                while (naluTotalSize < sampleSize) {\n                  const naluSize = readUint32(videoData, sampleOffset);\n                  sampleOffset += 4;\n                  if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {\n                    const data = videoData.subarray(\n                      sampleOffset,\n                      sampleOffset + naluSize,\n                    );\n                    parseSEIMessageFromNALu(\n                      data,\n                      isHEVCFlavor ? 2 : 1,\n                      timeOffset + compositionOffset / timescale,\n                      seiSamples,\n                    );\n                  }\n                  sampleOffset += naluSize;\n                  naluTotalSize += naluSize + 4;\n                }\n              }\n\n              timeOffset += sampleDuration / timescale;\n            }\n          });\n        }\n      });\n    });\n  });\n  return seiSamples;\n}\n\nfunction isHEVC(codec: string) {\n  if (!codec) {\n    return false;\n  }\n  const delimit = codec.indexOf('.');\n  const baseCodec = delimit < 0 ? codec : codec.substring(0, delimit);\n  return (\n    baseCodec === 'hvc1' ||\n    baseCodec === 'hev1' ||\n    // Dolby Vision\n    baseCodec === 'dvh1' ||\n    baseCodec === 'dvhe'\n  );\n}\n\nfunction isSEIMessage(isHEVCFlavor: boolean, naluHeader: number) {\n  if (isHEVCFlavor) {\n    const naluType = (naluHeader >> 1) & 0x3f;\n    return naluType === 39 || naluType === 40;\n  } else {\n    const naluType = naluHeader & 0x1f;\n    return naluType === 6;\n  }\n}\n\nexport function parseSEIMessageFromNALu(\n  unescapedData: Uint8Array,\n  headerSize: number,\n  pts: number,\n  samples: UserdataSample[],\n) {\n  const data = discardEPB(unescapedData);\n  let seiPtr = 0;\n  // skip nal header\n  seiPtr += headerSize;\n  let payloadType = 0;\n  let payloadSize = 0;\n  let b = 0;\n\n  while (seiPtr < data.length) {\n    payloadType = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadType += b;\n    } while (b === 0xff);\n\n    // Parse payload size.\n    payloadSize = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadSize += b;\n    } while (b === 0xff);\n\n    const leftOver = data.length - seiPtr;\n    // Create a variable to process the payload\n    let payPtr = seiPtr;\n\n    // Increment the seiPtr to the end of the payload\n    if (payloadSize < leftOver) {\n      seiPtr += payloadSize;\n    } else if (payloadSize > leftOver) {\n      // Some type of corruption has happened?\n      logger.error(\n        `Malformed SEI payload. ${payloadSize} is too small, only ${leftOver} bytes left to parse.`,\n      );\n      // We might be able to parse some data, but let's be safe and ignore it.\n      break;\n    }\n\n    if (payloadType === 4) {\n      const countryCode = data[payPtr++];\n      if (countryCode === 181) {\n        const providerCode = readUint16(data, payPtr);\n        payPtr += 2;\n\n        if (providerCode === 49) {\n          const userStructure = readUint32(data, payPtr);\n          payPtr += 4;\n\n          if (userStructure === 0x47413934) {\n            const userDataType = data[payPtr++];\n\n            // Raw CEA-608 bytes wrapped in CEA-708 packet\n            if (userDataType === 3) {\n              const firstByte = data[payPtr++];\n              const totalCCs = 0x1f & firstByte;\n              const enabled = 0x40 & firstByte;\n              const totalBytes = enabled ? 2 + totalCCs * 3 : 0;\n              const byteArray = new Uint8Array(totalBytes);\n              if (enabled) {\n                byteArray[0] = firstByte;\n                for (let i = 1; i < totalBytes; i++) {\n                  byteArray[i] = data[payPtr++];\n                }\n              }\n\n              samples.push({\n                type: userDataType,\n                payloadType,\n                pts,\n                bytes: byteArray,\n              });\n            }\n          }\n        }\n      }\n    } else if (payloadType === 5) {\n      if (payloadSize > 16) {\n        const uuidStrArray: Array<string> = [];\n        for (let i = 0; i < 16; i++) {\n          const b = data[payPtr++].toString(16);\n          uuidStrArray.push(b.length == 1 ? '0' + b : b);\n\n          if (i === 3 || i === 5 || i === 7 || i === 9) {\n            uuidStrArray.push('-');\n          }\n        }\n        const length = payloadSize - 16;\n        const userDataBytes = new Uint8Array(length);\n        for (let i = 0; i < length; i++) {\n          userDataBytes[i] = data[payPtr++];\n        }\n\n        samples.push({\n          payloadType,\n          pts,\n          uuid: uuidStrArray.join(''),\n          userData: utf8ArrayToStr(userDataBytes),\n          userDataBytes,\n        });\n      }\n    }\n  }\n}\n\n/**\n * remove Emulation Prevention bytes from a RBSP\n */\nexport function discardEPB(data: Uint8Array): Uint8Array {\n  const length = data.byteLength;\n  const EPBPositions = [] as Array<number>;\n  let i = 1;\n\n  // Find all `Emulation Prevention Bytes`\n  while (i < length - 2) {\n    if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n      EPBPositions.push(i + 2);\n      i += 2;\n    } else {\n      i++;\n    }\n  }\n\n  // If no Emulation Prevention Bytes were found just return the original\n  // array\n  if (EPBPositions.length === 0) {\n    return data;\n  }\n\n  // Create a new array to hold the NAL unit data\n  const newLength = length - EPBPositions.length;\n  const newData = new Uint8Array(newLength);\n  let sourceIndex = 0;\n\n  for (i = 0; i < newLength; sourceIndex++, i++) {\n    if (sourceIndex === EPBPositions[0]) {\n      // Skip this byte\n      sourceIndex++;\n      // Remove this position index\n      EPBPositions.shift();\n    }\n    newData[i] = data[sourceIndex];\n  }\n  return newData;\n}\n\nexport function parseEmsg(data: Uint8Array): IEmsgParsingData {\n  const version = data[0];\n  let schemeIdUri: string = '';\n  let value: string = '';\n  let timeScale: number = 0;\n  let presentationTimeDelta: number = 0;\n  let presentationTime: number = 0;\n  let eventDuration: number = 0;\n  let id: number = 0;\n  let offset: number = 0;\n\n  if (version === 0) {\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n\n    timeScale = readUint32(data, 12);\n    presentationTimeDelta = readUint32(data, 16);\n    eventDuration = readUint32(data, 20);\n    id = readUint32(data, 24);\n    offset = 28;\n  } else if (version === 1) {\n    offset += 4;\n    timeScale = readUint32(data, offset);\n    offset += 4;\n    const leftPresentationTime = readUint32(data, offset);\n    offset += 4;\n    const rightPresentationTime = readUint32(data, offset);\n    offset += 4;\n    presentationTime = 2 ** 32 * leftPresentationTime + rightPresentationTime;\n    if (!Number.isSafeInteger(presentationTime)) {\n      presentationTime = Number.MAX_SAFE_INTEGER;\n      logger.warn(\n        'Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box',\n      );\n    }\n\n    eventDuration = readUint32(data, offset);\n    offset += 4;\n    id = readUint32(data, offset);\n    offset += 4;\n\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n  }\n  const payload = data.subarray(offset, data.byteLength);\n\n  return {\n    schemeIdUri,\n    value,\n    timeScale,\n    presentationTime,\n    presentationTimeDelta,\n    eventDuration,\n    id,\n    payload,\n  };\n}\n\nexport function mp4Box(type: ArrayLike<number>, ...payload: Uint8Array[]) {\n  const len = payload.length;\n  let size = 8;\n  let i = len;\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n  const result = new Uint8Array(size);\n  result[0] = (size >> 24) & 0xff;\n  result[1] = (size >> 16) & 0xff;\n  result[2] = (size >> 8) & 0xff;\n  result[3] = size & 0xff;\n  result.set(type, 4);\n  for (i = 0, size = 8; i < len; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n  return result;\n}\n\nexport function mp4pssh(\n  systemId: Uint8Array,\n  keyids: Array<Uint8Array> | null,\n  data: Uint8Array,\n) {\n  if (systemId.byteLength !== 16) {\n    throw new RangeError('Invalid system id');\n  }\n  let version;\n  let kids;\n  if (keyids) {\n    version = 1;\n    kids = new Uint8Array(keyids.length * 16);\n    for (let ix = 0; ix < keyids.length; ix++) {\n      const k = keyids[ix]; // uint8array\n      if (k.byteLength !== 16) {\n        throw new RangeError('Invalid key');\n      }\n      kids.set(k, ix * 16);\n    }\n  } else {\n    version = 0;\n    kids = new Uint8Array();\n  }\n  let kidCount;\n  if (version > 0) {\n    kidCount = new Uint8Array(4);\n    if (keyids!.length > 0) {\n      new DataView(kidCount.buffer).setUint32(0, keyids!.length, false);\n    }\n  } else {\n    kidCount = new Uint8Array();\n  }\n  const dataSize = new Uint8Array(4);\n  if (data && data.byteLength > 0) {\n    new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);\n  }\n  return mp4Box(\n    [112, 115, 115, 104],\n    new Uint8Array([\n      version,\n      0x00,\n      0x00,\n      0x00, // Flags\n    ]),\n    systemId, // 16 bytes\n    kidCount,\n    kids,\n    dataSize,\n    data || new Uint8Array(),\n  );\n}\n\nexport type PsshData = {\n  version: 0 | 1;\n  systemId: KeySystemIds;\n  kids: null | Uint8Array[];\n  data: null | Uint8Array;\n  offset: number;\n  size: number;\n};\n\nexport type PsshInvalidResult = {\n  systemId?: undefined;\n  offset: number;\n  size: number;\n};\n\nexport function parseMultiPssh(\n  initData: ArrayBuffer,\n): (PsshData | PsshInvalidResult)[] {\n  const results: (PsshData | PsshInvalidResult)[] = [];\n  if (initData instanceof ArrayBuffer) {\n    const length = initData.byteLength;\n    let offset = 0;\n    while (offset + 32 < length) {\n      const view = new DataView(initData, offset);\n      const pssh = parsePssh(view);\n      results.push(pssh);\n      offset += pssh.size;\n    }\n  }\n  return results;\n}\n\nfunction parsePssh(view: DataView): PsshData | PsshInvalidResult {\n  const size = view.getUint32(0);\n  const offset = view.byteOffset;\n  const length = view.byteLength;\n  if (length < size) {\n    return {\n      offset,\n      size: length,\n    };\n  }\n  const type = view.getUint32(4);\n  if (type !== 0x70737368) {\n    return { offset, size };\n  }\n  const version = view.getUint32(8) >>> 24;\n  if (version !== 0 && version !== 1) {\n    return { offset, size };\n  }\n  const buffer = view.buffer;\n  const systemId = Hex.hexDump(\n    new Uint8Array(buffer, offset + 12, 16),\n  ) as KeySystemIds;\n  const dataSizeOrKidCount = view.getUint32(28);\n  let kids: null | Uint8Array[] = null;\n  let data: null | Uint8Array = null;\n  if (version === 0) {\n    if (size - 32 < dataSizeOrKidCount || dataSizeOrKidCount < 22) {\n      return { offset, size };\n    }\n    data = new Uint8Array(buffer, offset + 32, dataSizeOrKidCount);\n  } else if (version === 1) {\n    if (\n      !dataSizeOrKidCount ||\n      length < offset + 32 + dataSizeOrKidCount * 16 + 16\n    ) {\n      return { offset, size };\n    }\n    kids = [];\n    for (let i = 0; i < dataSizeOrKidCount; i++) {\n      kids.push(new Uint8Array(buffer, offset + 32 + i * 16, 16));\n    }\n  }\n  return {\n    version,\n    systemId,\n    kids,\n    data,\n    offset,\n    size,\n  };\n}\n","import {\n  changeEndianness,\n  convertDataUriToArrayBytes,\n} from '../utils/keysystem-util';\nimport { KeySystemFormats, parsePlayReadyWRM } from '../utils/mediakeys-helper';\nimport { mp4pssh } from '../utils/mp4-tools';\nimport { logger } from '../utils/logger';\nimport { base64Decode } from '../utils/numeric-encoding-utils';\n\nlet keyUriToKeyIdMap: { [uri: string]: Uint8Array } = {};\n\nexport interface DecryptData {\n  uri: string;\n  method: string;\n  keyFormat: string;\n  keyFormatVersions: number[];\n  iv: Uint8Array | null;\n  key: Uint8Array | null;\n  keyId: Uint8Array | null;\n  pssh: Uint8Array | null;\n  encrypted: boolean;\n  isCommonEncryption: boolean;\n}\n\nexport class LevelKey implements DecryptData {\n  public readonly uri: string;\n  public readonly method: string;\n  public readonly keyFormat: string;\n  public readonly keyFormatVersions: number[];\n  public readonly encrypted: boolean;\n  public readonly isCommonEncryption: boolean;\n  public iv: Uint8Array | null = null;\n  public key: Uint8Array | null = null;\n  public keyId: Uint8Array | null = null;\n  public pssh: Uint8Array | null = null;\n\n  static clearKeyUriToKeyIdMap() {\n    keyUriToKeyIdMap = {};\n  }\n\n  constructor(\n    method: string,\n    uri: string,\n    format: string,\n    formatversions: number[] = [1],\n    iv: Uint8Array | null = null,\n  ) {\n    this.method = method;\n    this.uri = uri;\n    this.keyFormat = format;\n    this.keyFormatVersions = formatversions;\n    this.iv = iv;\n    this.encrypted = method ? method !== 'NONE' : false;\n    this.isCommonEncryption = this.encrypted && method !== 'AES-128';\n  }\n\n  public isSupported(): boolean {\n    // If it's Segment encryption or No encryption, just select that key system\n    if (this.method) {\n      if (this.method === 'AES-128' || this.method === 'NONE') {\n        return true;\n      }\n      if (this.keyFormat === 'identity') {\n        // Maintain support for clear SAMPLE-AES with MPEG-3 TS\n        return this.method === 'SAMPLE-AES';\n      } else if (__USE_EME_DRM__) {\n        switch (this.keyFormat) {\n          case KeySystemFormats.FAIRPLAY:\n          case KeySystemFormats.WIDEVINE:\n          case KeySystemFormats.PLAYREADY:\n          case KeySystemFormats.CLEARKEY:\n            return (\n              [\n                'ISO-23001-7',\n                'SAMPLE-AES',\n                'SAMPLE-AES-CENC',\n                'SAMPLE-AES-CTR',\n              ].indexOf(this.method) !== -1\n            );\n        }\n      }\n    }\n    return false;\n  }\n\n  public getDecryptData(sn: number | 'initSegment'): LevelKey | null {\n    if (!this.encrypted || !this.uri) {\n      return null;\n    }\n\n    if (this.method === 'AES-128' && this.uri && !this.iv) {\n      if (typeof sn !== 'number') {\n        // We are fetching decryption data for a initialization segment\n        // If the segment was encrypted with AES-128\n        // It must have an IV defined. We cannot substitute the Segment Number in.\n        if (this.method === 'AES-128' && !this.iv) {\n          logger.warn(\n            `missing IV for initialization segment with method=\"${this.method}\" - compliance issue`,\n          );\n        }\n        // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.\n        sn = 0;\n      }\n      const iv = createInitializationVector(sn);\n      const decryptdata = new LevelKey(\n        this.method,\n        this.uri,\n        'identity',\n        this.keyFormatVersions,\n        iv,\n      );\n      return decryptdata;\n    }\n\n    if (!__USE_EME_DRM__) {\n      return this;\n    }\n\n    // Initialize keyId if possible\n    const keyBytes = convertDataUriToArrayBytes(this.uri);\n    if (keyBytes) {\n      switch (this.keyFormat) {\n        case KeySystemFormats.WIDEVINE:\n          // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using\n          // the playlist-key before the \"encrypted\" event. (Comment out to only use \"encrypted\" path.)\n          this.pssh = keyBytes;\n          // In case of widevine keyID is embedded in PSSH box. Read Key ID.\n          if (keyBytes.length >= 22) {\n            this.keyId = keyBytes.subarray(\n              keyBytes.length - 22,\n              keyBytes.length - 6,\n            );\n          }\n          break;\n        case KeySystemFormats.PLAYREADY: {\n          const PlayReadyKeySystemUUID = new Uint8Array([\n            0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6,\n            0x5b, 0xe0, 0x88, 0x5f, 0x95,\n          ]);\n\n          // Setting `pssh` on this LevelKey/DecryptData allows HLS.js to generate a session using\n          // the playlist-key before the \"encrypted\" event. (Comment out to only use \"encrypted\" path.)\n          this.pssh = mp4pssh(PlayReadyKeySystemUUID, null, keyBytes);\n\n          this.keyId = parsePlayReadyWRM(keyBytes);\n\n          break;\n        }\n        default: {\n          let keydata = keyBytes.subarray(0, 16);\n          if (keydata.length !== 16) {\n            const padded = new Uint8Array(16);\n            padded.set(keydata, 16 - keydata.length);\n            keydata = padded;\n          }\n          this.keyId = keydata;\n          break;\n        }\n      }\n    }\n\n    // Default behavior: assign a new keyId for each uri\n    if (!this.keyId || this.keyId.byteLength !== 16) {\n      let keyId = keyUriToKeyIdMap[this.uri];\n      if (!keyId) {\n        const val =\n          Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;\n        keyId = new Uint8Array(16);\n        const dv = new DataView(keyId.buffer, 12, 4); // Just set the last 4 bytes\n        dv.setUint32(0, val);\n        keyUriToKeyIdMap[this.uri] = keyId;\n      }\n      this.keyId = keyId;\n    }\n\n    return this;\n  }\n}\n\nfunction createInitializationVector(segmentNumber: number): Uint8Array {\n  const uint8View = new Uint8Array(16);\n  for (let i = 12; i < 16; i++) {\n    uint8View[i] = (segmentNumber >> (8 * (15 - i))) & 0xff;\n  }\n  return uint8View;\n}\n","import type { AttrList } from './attr-list';\nimport type { ParsedMultivariantPlaylist } from '../loader/m3u8-parser';\nimport type { LevelDetails } from '../loader/level-details';\nimport type { VariableMap } from '../types/level';\n\nconst VARIABLE_REPLACEMENT_REGEX = /\\{\\$([a-zA-Z0-9-_]+)\\}/g;\n\nexport function hasVariableReferences(str: string): boolean {\n  return VARIABLE_REPLACEMENT_REGEX.test(str);\n}\n\nexport function substituteVariablesInAttributes(\n  parsed: Pick<\n    ParsedMultivariantPlaylist | LevelDetails,\n    'variableList' | 'hasVariableRefs' | 'playlistParsingError'\n  >,\n  attr: AttrList,\n  attributeNames: string[],\n) {\n  if (parsed.variableList !== null || parsed.hasVariableRefs) {\n    for (let i = attributeNames.length; i--; ) {\n      const name = attributeNames[i];\n      const value = attr[name];\n      if (value) {\n        attr[name] = substituteVariables(parsed, value);\n      }\n    }\n  }\n}\n\nexport function substituteVariables(\n  parsed: Pick<\n    ParsedMultivariantPlaylist | LevelDetails,\n    'variableList' | 'hasVariableRefs' | 'playlistParsingError'\n  >,\n  value: string,\n): string {\n  if (parsed.variableList !== null || parsed.hasVariableRefs) {\n    const variableList = parsed.variableList;\n    return value.replace(\n      VARIABLE_REPLACEMENT_REGEX,\n      (variableReference: string) => {\n        const variableName = variableReference.substring(\n          2,\n          variableReference.length - 1,\n        );\n        const variableValue = variableList?.[variableName];\n        if (variableValue === undefined) {\n          parsed.playlistParsingError ||= new Error(\n            `Missing preceding EXT-X-DEFINE tag for Variable Reference: \"${variableName}\"`,\n          );\n          return variableReference;\n        }\n        return variableValue;\n      },\n    );\n  }\n  return value;\n}\n\nexport function addVariableDefinition(\n  parsed: Pick<\n    ParsedMultivariantPlaylist | LevelDetails,\n    'variableList' | 'playlistParsingError'\n  >,\n  attr: AttrList,\n  parentUrl: string,\n) {\n  let variableList = parsed.variableList;\n  if (!variableList) {\n    parsed.variableList = variableList = {};\n  }\n  let NAME: string;\n  let VALUE;\n  if ('QUERYPARAM' in attr) {\n    NAME = attr.QUERYPARAM;\n    try {\n      const searchParams = new self.URL(parentUrl).searchParams;\n      if (searchParams.has(NAME)) {\n        VALUE = searchParams.get(NAME);\n      } else {\n        throw new Error(\n          `\"${NAME}\" does not match any query parameter in URI: \"${parentUrl}\"`,\n        );\n      }\n    } catch (error) {\n      parsed.playlistParsingError ||= new Error(\n        `EXT-X-DEFINE QUERYPARAM: ${error.message}`,\n      );\n    }\n  } else {\n    NAME = attr.NAME;\n    VALUE = attr.VALUE;\n  }\n  if (NAME in variableList) {\n    parsed.playlistParsingError ||= new Error(\n      `EXT-X-DEFINE duplicate Variable Name declarations: \"${NAME}\"`,\n    );\n  } else {\n    variableList[NAME] = VALUE || '';\n  }\n}\n\nexport function importVariableDefinition(\n  parsed: Pick<\n    ParsedMultivariantPlaylist | LevelDetails,\n    'variableList' | 'playlistParsingError'\n  >,\n  attr: AttrList,\n  sourceVariableList: VariableMap | null,\n) {\n  const IMPORT = attr.IMPORT;\n  if (sourceVariableList && IMPORT in sourceVariableList) {\n    let variableList = parsed.variableList;\n    if (!variableList) {\n      parsed.variableList = variableList = {};\n    }\n    variableList[IMPORT] = sourceVariableList[IMPORT];\n  } else {\n    parsed.playlistParsingError ||= new Error(\n      `EXT-X-DEFINE IMPORT attribute not found in Multivariant Playlist: \"${IMPORT}\"`,\n    );\n  }\n}\n","/**\n * MediaSource helper\n */\n\nexport function getMediaSource(\n  preferManagedMediaSource = true,\n): typeof MediaSource | undefined {\n  if (typeof self === 'undefined') return undefined;\n  const mms =\n    (preferManagedMediaSource || !self.MediaSource) &&\n    ((self as any).ManagedMediaSource as undefined | typeof MediaSource);\n  return (\n    mms ||\n    self.MediaSource ||\n    ((self as any).WebKitMediaSource as typeof MediaSource)\n  );\n}\n\nexport function isManagedMediaSource(source: typeof MediaSource | undefined) {\n  return (\n    typeof self !== 'undefined' && source === (self as any).ManagedMediaSource\n  );\n}\n","import { getMediaSource } from './mediasource-helper';\n\n// from http://mp4ra.org/codecs.html\n// values indicate codec selection preference (lower is higher priority)\nconst sampleEntryCodesISO = {\n  audio: {\n    a3ds: 1,\n    'ac-3': 0.95,\n    'ac-4': 1,\n    alac: 0.9,\n    alaw: 1,\n    dra1: 1,\n    'dts+': 1,\n    'dts-': 1,\n    dtsc: 1,\n    dtse: 1,\n    dtsh: 1,\n    'ec-3': 0.9,\n    enca: 1,\n    fLaC: 0.9, // MP4-RA listed codec entry for FLAC\n    flac: 0.9, // legacy browser codec name for FLAC\n    FLAC: 0.9, // some manifests may list \"FLAC\" with Apple's tools\n    g719: 1,\n    g726: 1,\n    m4ae: 1,\n    mha1: 1,\n    mha2: 1,\n    mhm1: 1,\n    mhm2: 1,\n    mlpa: 1,\n    mp4a: 1,\n    'raw ': 1,\n    Opus: 1,\n    opus: 1, // browsers expect this to be lowercase despite MP4RA says 'Opus'\n    samr: 1,\n    sawb: 1,\n    sawp: 1,\n    sevc: 1,\n    sqcp: 1,\n    ssmv: 1,\n    twos: 1,\n    ulaw: 1,\n  },\n  video: {\n    avc1: 1,\n    avc2: 1,\n    avc3: 1,\n    avc4: 1,\n    avcp: 1,\n    av01: 0.8,\n    drac: 1,\n    dva1: 1,\n    dvav: 1,\n    dvh1: 0.7,\n    dvhe: 0.7,\n    encv: 1,\n    hev1: 0.75,\n    hvc1: 0.75,\n    mjp2: 1,\n    mp4v: 1,\n    mvc1: 1,\n    mvc2: 1,\n    mvc3: 1,\n    mvc4: 1,\n    resv: 1,\n    rv60: 1,\n    s263: 1,\n    svc1: 1,\n    svc2: 1,\n    'vc-1': 1,\n    vp08: 1,\n    vp09: 0.9,\n  },\n  text: {\n    stpp: 1,\n    wvtt: 1,\n  },\n} as const;\n\nexport type CodecType = 'audio' | 'video';\n\nexport function isCodecType(codec: string, type: CodecType): boolean {\n  const typeCodes = sampleEntryCodesISO[type];\n  return !!typeCodes && !!typeCodes[codec.slice(0, 4)];\n}\n\nexport function areCodecsMediaSourceSupported(\n  codecs: string,\n  type: CodecType,\n  preferManagedMediaSource = true,\n): boolean {\n  return !codecs\n    .split(',')\n    .some(\n      (codec) =>\n        !isCodecMediaSourceSupported(codec, type, preferManagedMediaSource),\n    );\n}\n\nfunction isCodecMediaSourceSupported(\n  codec: string,\n  type: CodecType,\n  preferManagedMediaSource = true,\n): boolean {\n  const MediaSource = getMediaSource(preferManagedMediaSource);\n  return MediaSource?.isTypeSupported(mimeTypeForCodec(codec, type)) ?? false;\n}\n\nexport function mimeTypeForCodec(codec: string, type: CodecType): string {\n  return `${type}/mp4;codecs=\"${codec}\"`;\n}\n\nexport function videoCodecPreferenceValue(\n  videoCodec: string | undefined,\n): number {\n  if (videoCodec) {\n    const fourCC = videoCodec.substring(0, 4);\n    return sampleEntryCodesISO.video[fourCC];\n  }\n  return 2;\n}\n\nexport function codecsSetSelectionPreferenceValue(codecSet: string): number {\n  return codecSet.split(',').reduce((num, fourCC) => {\n    const preferenceValue = sampleEntryCodesISO.video[fourCC];\n    if (preferenceValue) {\n      return (preferenceValue * 2 + num) / (num ? 3 : 2);\n    }\n    return (sampleEntryCodesISO.audio[fourCC] + num) / (num ? 2 : 1);\n  }, 0);\n}\n\ninterface CodecNameCache {\n  flac?: string;\n  opus?: string;\n}\n\nconst CODEC_COMPATIBLE_NAMES: CodecNameCache = {};\n\ntype LowerCaseCodecType = 'flac' | 'opus';\n\nfunction getCodecCompatibleNameLower(\n  lowerCaseCodec: LowerCaseCodecType,\n  preferManagedMediaSource = true,\n): string {\n  if (CODEC_COMPATIBLE_NAMES[lowerCaseCodec]) {\n    return CODEC_COMPATIBLE_NAMES[lowerCaseCodec]!;\n  }\n\n  // Idealy fLaC and Opus would be first (spec-compliant) but\n  // some browsers will report that fLaC is supported then fail.\n  // see: https://bugs.chromium.org/p/chromium/issues/detail?id=1422728\n  const codecsToCheck = {\n    flac: ['flac', 'fLaC', 'FLAC'],\n    opus: ['opus', 'Opus'],\n  }[lowerCaseCodec];\n\n  for (let i = 0; i < codecsToCheck.length; i++) {\n    if (\n      isCodecMediaSourceSupported(\n        codecsToCheck[i],\n        'audio',\n        preferManagedMediaSource,\n      )\n    ) {\n      CODEC_COMPATIBLE_NAMES[lowerCaseCodec] = codecsToCheck[i];\n      return codecsToCheck[i];\n    }\n  }\n\n  return lowerCaseCodec;\n}\n\nconst AUDIO_CODEC_REGEXP = /flac|opus/i;\nexport function getCodecCompatibleName(\n  codec: string,\n  preferManagedMediaSource = true,\n): string {\n  return codec.replace(AUDIO_CODEC_REGEXP, (m) =>\n    getCodecCompatibleNameLower(\n      m.toLowerCase() as LowerCaseCodecType,\n      preferManagedMediaSource,\n    ),\n  );\n}\n\nexport function pickMostCompleteCodecName(\n  parsedCodec: string,\n  levelCodec: string | undefined,\n): string | undefined {\n  // Parsing of mp4a codecs strings in mp4-tools from media is incomplete as of d8c6c7a\n  // so use level codec is parsed codec is unavailable or incomplete\n  if (parsedCodec && parsedCodec !== 'mp4a') {\n    return parsedCodec;\n  }\n  return levelCodec ? levelCodec.split(',')[0] : levelCodec;\n}\n\nexport function convertAVC1ToAVCOTI(codec: string) {\n  // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported\n  // Examples: avc1.66.30 to avc1.42001e and avc1.77.30,avc1.66.30 to avc1.4d001e,avc1.42001e.\n  const codecs = codec.split(',');\n  for (let i = 0; i < codecs.length; i++) {\n    const avcdata = codecs[i].split('.');\n    if (avcdata.length > 2) {\n      let result = avcdata.shift() + '.';\n      result += parseInt(avcdata.shift() as string).toString(16);\n      result += (\n        '000' + parseInt(avcdata.shift() as string).toString(16)\n      ).slice(-4);\n      codecs[i] = result;\n    }\n  }\n  return codecs.join(',');\n}\n","import { buildAbsoluteURL } from 'url-toolkit';\nimport { DateRange } from './date-range';\nimport { Fragment, Part } from './fragment';\nimport { LevelDetails } from './level-details';\nimport { LevelKey } from './level-key';\nimport { AttrList } from '../utils/attr-list';\nimport { logger } from '../utils/logger';\nimport {\n  addVariableDefinition,\n  hasVariableReferences,\n  importVariableDefinition,\n  substituteVariables,\n  substituteVariablesInAttributes,\n} from '../utils/variable-substitution';\nimport { isCodecType } from '../utils/codecs';\nimport type { CodecType } from '../utils/codecs';\nimport type { MediaPlaylist, MediaAttributes } from '../types/media-playlist';\nimport type { PlaylistLevelType } from '../types/loader';\nimport type { LevelAttributes, LevelParsed, VariableMap } from '../types/level';\nimport type { ContentSteeringOptions } from '../types/events';\n\ntype M3U8ParserFragments = Array<Fragment | null>;\n\nexport type ParsedMultivariantPlaylist = {\n  contentSteering: ContentSteeringOptions | null;\n  levels: LevelParsed[];\n  playlistParsingError: Error | null;\n  sessionData: Record<string, AttrList> | null;\n  sessionKeys: LevelKey[] | null;\n  startTimeOffset: number | null;\n  variableList: VariableMap | null;\n  hasVariableRefs: boolean;\n};\n\ntype ParsedMultivariantMediaOptions = {\n  AUDIO?: MediaPlaylist[];\n  SUBTITLES?: MediaPlaylist[];\n  'CLOSED-CAPTIONS'?: MediaPlaylist[];\n};\n\nconst MASTER_PLAYLIST_REGEX =\n  /#EXT-X-STREAM-INF:([^\\r\\n]*)(?:[\\r\\n](?:#[^\\r\\n]*)?)*([^\\r\\n]+)|#EXT-X-(SESSION-DATA|SESSION-KEY|DEFINE|CONTENT-STEERING|START):([^\\r\\n]*)[\\r\\n]+/g;\nconst MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\n\nconst IS_MEDIA_PLAYLIST = /^#EXT(?:INF|-X-TARGETDURATION):/m; // Handle empty Media Playlist (first EXTINF not signaled, but TARGETDURATION present)\n\nconst LEVEL_PLAYLIST_REGEX_FAST = new RegExp(\n  [\n    /#EXTINF:\\s*(\\d*(?:\\.\\d+)?)(?:,(.*)\\s+)?/.source, // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\n    /(?!#) *(\\S[^\\r\\n]*)/.source, // segment URI, group 3 => the URI (note newline is not eaten)\n    /#EXT-X-BYTERANGE:*(.+)/.source, // next segment's byterange, group 4 => range spec (x@y)\n    /#EXT-X-PROGRAM-DATE-TIME:(.+)/.source, // next segment's program date/time group 5 => the datetime spec\n    /#.*/.source, // All other non-segment oriented tags will match with all groups empty\n  ].join('|'),\n  'g',\n);\n\nconst LEVEL_PLAYLIST_REGEX_SLOW = new RegExp(\n  [\n    /#(EXTM3U)/.source,\n    /#EXT-X-(DATERANGE|DEFINE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/\n      .source,\n    /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\\d+)/\n      .source,\n    /#EXT-X-(DISCONTINUITY|ENDLIST|GAP|INDEPENDENT-SEGMENTS)/.source,\n    /(#)([^:]*):(.*)/.source,\n    /(#)(.*)(?:.*)\\r?\\n?/.source,\n  ].join('|'),\n);\n\nexport default class M3U8Parser {\n  static findGroup(\n    groups: (\n      | { id?: string; audioCodec?: string }\n      | { id?: string; textCodec?: string }\n    )[],\n    mediaGroupId: string,\n  ):\n    | { id?: string; audioCodec?: string }\n    | { id?: string; textCodec?: string }\n    | undefined {\n    for (let i = 0; i < groups.length; i++) {\n      const group = groups[i];\n      if (group.id === mediaGroupId) {\n        return group;\n      }\n    }\n  }\n\n  static resolve(url, baseUrl) {\n    return buildAbsoluteURL(baseUrl, url, { alwaysNormalize: true });\n  }\n\n  static isMediaPlaylist(str: string): boolean {\n    return IS_MEDIA_PLAYLIST.test(str);\n  }\n\n  static parseMasterPlaylist(\n    string: string,\n    baseurl: string,\n  ): ParsedMultivariantPlaylist {\n    const hasVariableRefs = __USE_VARIABLE_SUBSTITUTION__\n      ? hasVariableReferences(string)\n      : false;\n    const parsed: ParsedMultivariantPlaylist = {\n      contentSteering: null,\n      levels: [],\n      playlistParsingError: null,\n      sessionData: null,\n      sessionKeys: null,\n      startTimeOffset: null,\n      variableList: null,\n      hasVariableRefs,\n    };\n    const levelsWithKnownCodecs: LevelParsed[] = [];\n\n    MASTER_PLAYLIST_REGEX.lastIndex = 0;\n\n    let result: RegExpExecArray | null;\n    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\n      if (result[1]) {\n        // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1\n        const attrs = new AttrList(result[1]) as LevelAttributes;\n        if (__USE_VARIABLE_SUBSTITUTION__) {\n          substituteVariablesInAttributes(parsed, attrs, [\n            'CODECS',\n            'SUPPLEMENTAL-CODECS',\n            'ALLOWED-CPC',\n            'PATHWAY-ID',\n            'STABLE-VARIANT-ID',\n            'AUDIO',\n            'VIDEO',\n            'SUBTITLES',\n            'CLOSED-CAPTIONS',\n            'NAME',\n          ]);\n        }\n        const uri = __USE_VARIABLE_SUBSTITUTION__\n          ? substituteVariables(parsed, result[2])\n          : result[2];\n        const level: LevelParsed = {\n          attrs,\n          bitrate:\n            attrs.decimalInteger('BANDWIDTH') ||\n            attrs.decimalInteger('AVERAGE-BANDWIDTH'),\n          name: attrs.NAME,\n          url: M3U8Parser.resolve(uri, baseurl),\n        };\n\n        const resolution = attrs.decimalResolution('RESOLUTION');\n        if (resolution) {\n          level.width = resolution.width;\n          level.height = resolution.height;\n        }\n\n        setCodecs(attrs.CODECS, level);\n\n        if (!level.unknownCodecs?.length) {\n          levelsWithKnownCodecs.push(level);\n        }\n\n        parsed.levels.push(level);\n      } else if (result[3]) {\n        const tag = result[3];\n        const attributes = result[4];\n        switch (tag) {\n          case 'SESSION-DATA': {\n            // #EXT-X-SESSION-DATA\n            const sessionAttrs = new AttrList(attributes);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(parsed, sessionAttrs, [\n                'DATA-ID',\n                'LANGUAGE',\n                'VALUE',\n                'URI',\n              ]);\n            }\n            const dataId = sessionAttrs['DATA-ID'];\n            if (dataId) {\n              if (parsed.sessionData === null) {\n                parsed.sessionData = {};\n              }\n              parsed.sessionData[dataId] = sessionAttrs;\n            }\n            break;\n          }\n          case 'SESSION-KEY': {\n            // #EXT-X-SESSION-KEY\n            const sessionKey = parseKey(attributes, baseurl, parsed);\n            if (sessionKey.encrypted && sessionKey.isSupported()) {\n              if (parsed.sessionKeys === null) {\n                parsed.sessionKeys = [];\n              }\n              parsed.sessionKeys.push(sessionKey);\n            } else {\n              logger.warn(\n                `[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: \"${attributes}\"`,\n              );\n            }\n            break;\n          }\n          case 'DEFINE': {\n            // #EXT-X-DEFINE\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              const variableAttributes = new AttrList(attributes);\n              substituteVariablesInAttributes(parsed, variableAttributes, [\n                'NAME',\n                'VALUE',\n                'QUERYPARAM',\n              ]);\n              addVariableDefinition(parsed, variableAttributes, baseurl);\n            }\n            break;\n          }\n          case 'CONTENT-STEERING': {\n            // #EXT-X-CONTENT-STEERING\n            const contentSteeringAttributes = new AttrList(attributes);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(\n                parsed,\n                contentSteeringAttributes,\n                ['SERVER-URI', 'PATHWAY-ID'],\n              );\n            }\n            parsed.contentSteering = {\n              uri: M3U8Parser.resolve(\n                contentSteeringAttributes['SERVER-URI'],\n                baseurl,\n              ),\n              pathwayId: contentSteeringAttributes['PATHWAY-ID'] || '.',\n            };\n            break;\n          }\n          case 'START': {\n            // #EXT-X-START\n            parsed.startTimeOffset = parseStartTimeOffset(attributes);\n            break;\n          }\n          default:\n            break;\n        }\n      }\n    }\n    // Filter out levels with unknown codecs if it does not remove all levels\n    const stripUnknownCodecLevels =\n      levelsWithKnownCodecs.length > 0 &&\n      levelsWithKnownCodecs.length < parsed.levels.length;\n\n    parsed.levels = stripUnknownCodecLevels\n      ? levelsWithKnownCodecs\n      : parsed.levels;\n    if (parsed.levels.length === 0) {\n      parsed.playlistParsingError = new Error('no levels found in manifest');\n    }\n\n    return parsed;\n  }\n\n  static parseMasterPlaylistMedia(\n    string: string,\n    baseurl: string,\n    parsed: ParsedMultivariantPlaylist,\n  ): ParsedMultivariantMediaOptions {\n    let result: RegExpExecArray | null;\n    const results: ParsedMultivariantMediaOptions = {};\n    const levels = parsed.levels;\n    const groupsByType = {\n      AUDIO: levels.map((level: LevelParsed) => ({\n        id: level.attrs.AUDIO,\n        audioCodec: level.audioCodec,\n      })),\n      SUBTITLES: levels.map((level: LevelParsed) => ({\n        id: level.attrs.SUBTITLES,\n        textCodec: level.textCodec,\n      })),\n      'CLOSED-CAPTIONS': [],\n    };\n    let id = 0;\n    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\n    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\n      const attrs = new AttrList(result[1]) as MediaAttributes;\n      const type = attrs.TYPE;\n      if (type) {\n        const groups: (typeof groupsByType)[keyof typeof groupsByType] =\n          groupsByType[type];\n        const medias: MediaPlaylist[] = results[type] || [];\n        results[type] = medias;\n        if (__USE_VARIABLE_SUBSTITUTION__) {\n          substituteVariablesInAttributes(parsed, attrs, [\n            'URI',\n            'GROUP-ID',\n            'LANGUAGE',\n            'ASSOC-LANGUAGE',\n            'STABLE-RENDITION-ID',\n            'NAME',\n            'INSTREAM-ID',\n            'CHARACTERISTICS',\n            'CHANNELS',\n          ]);\n        }\n        const lang = attrs.LANGUAGE;\n        const assocLang = attrs['ASSOC-LANGUAGE'];\n        const channels = attrs.CHANNELS;\n        const characteristics = attrs.CHARACTERISTICS;\n        const instreamId = attrs['INSTREAM-ID'];\n        const media: MediaPlaylist = {\n          attrs,\n          bitrate: 0,\n          id: id++,\n          groupId: attrs['GROUP-ID'] || '',\n          name: attrs.NAME || lang || '',\n          type,\n          default: attrs.bool('DEFAULT'),\n          autoselect: attrs.bool('AUTOSELECT'),\n          forced: attrs.bool('FORCED'),\n          lang,\n          url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : '',\n        };\n        if (assocLang) {\n          media.assocLang = assocLang;\n        }\n        if (channels) {\n          media.channels = channels;\n        }\n        if (characteristics) {\n          media.characteristics = characteristics;\n        }\n        if (instreamId) {\n          media.instreamId = instreamId;\n        }\n\n        if (groups?.length) {\n          // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track\n          // If we don't find the track signalled, lets use the first audio groups codec we have\n          // Acting as a best guess\n          const groupCodec =\n            M3U8Parser.findGroup(groups, media.groupId as string) || groups[0];\n          assignCodec(media, groupCodec, 'audioCodec');\n          assignCodec(media, groupCodec, 'textCodec');\n        }\n\n        medias.push(media);\n      }\n    }\n    return results;\n  }\n\n  static parseLevelPlaylist(\n    string: string,\n    baseurl: string,\n    id: number,\n    type: PlaylistLevelType,\n    levelUrlId: number,\n    multivariantVariableList: VariableMap | null,\n  ): LevelDetails {\n    const level = new LevelDetails(baseurl);\n    const fragments: M3U8ParserFragments = level.fragments;\n    // The most recent init segment seen (applies to all subsequent segments)\n    let currentInitSegment: Fragment | null = null;\n    let currentSN = 0;\n    let currentPart = 0;\n    let totalduration = 0;\n    let discontinuityCounter = 0;\n    let prevFrag: Fragment | null = null;\n    let frag: Fragment = new Fragment(type, baseurl);\n    let result: RegExpExecArray | RegExpMatchArray | null;\n    let i: number;\n    let levelkeys: { [key: string]: LevelKey } | undefined;\n    let firstPdtIndex = -1;\n    let createNextFrag = false;\n    let nextByteRange: string | null = null;\n\n    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\n    level.m3u8 = string;\n    level.hasVariableRefs = __USE_VARIABLE_SUBSTITUTION__\n      ? hasVariableReferences(string)\n      : false;\n\n    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\n      if (createNextFrag) {\n        createNextFrag = false;\n        frag = new Fragment(type, baseurl);\n        // setup the next fragment for part loading\n        frag.start = totalduration;\n        frag.sn = currentSN;\n        frag.cc = discontinuityCounter;\n        frag.level = id;\n        if (currentInitSegment) {\n          frag.initSegment = currentInitSegment;\n          frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n          currentInitSegment.rawProgramDateTime = null;\n          if (nextByteRange) {\n            frag.setByteRange(nextByteRange);\n            nextByteRange = null;\n          }\n        }\n      }\n\n      const duration = result[1];\n      if (duration) {\n        // INF\n        frag.duration = parseFloat(duration);\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const title = (' ' + result[2]).slice(1);\n        frag.title = title || null;\n        frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\n      } else if (result[3]) {\n        // url\n        if (Number.isFinite(frag.duration)) {\n          frag.start = totalduration;\n          if (levelkeys) {\n            setFragLevelKeys(frag, levelkeys, level);\n          }\n          frag.sn = currentSN;\n          frag.level = id;\n          frag.cc = discontinuityCounter;\n          fragments.push(frag);\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          const uri = (' ' + result[3]).slice(1);\n          frag.relurl = __USE_VARIABLE_SUBSTITUTION__\n            ? substituteVariables(level, uri)\n            : uri;\n          assignProgramDateTime(frag, prevFrag);\n          prevFrag = frag;\n          totalduration += frag.duration;\n          currentSN++;\n          currentPart = 0;\n          createNextFrag = true;\n        }\n      } else if (result[4]) {\n        // X-BYTERANGE\n        const data = (' ' + result[4]).slice(1);\n        if (prevFrag) {\n          frag.setByteRange(data, prevFrag);\n        } else {\n          frag.setByteRange(data);\n        }\n      } else if (result[5]) {\n        // PROGRAM-DATE-TIME\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        frag.rawProgramDateTime = (' ' + result[5]).slice(1);\n        frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);\n        if (firstPdtIndex === -1) {\n          firstPdtIndex = fragments.length;\n        }\n      } else {\n        result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\n        if (!result) {\n          logger.warn('No matches on slow regex match for level playlist!');\n          continue;\n        }\n        for (i = 1; i < result.length; i++) {\n          if (typeof result[i] !== 'undefined') {\n            break;\n          }\n        }\n\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const tag = (' ' + result[i]).slice(1);\n        const value1 = (' ' + result[i + 1]).slice(1);\n        const value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : '';\n\n        switch (tag) {\n          case 'PLAYLIST-TYPE':\n            level.type = value1.toUpperCase();\n            break;\n          case 'MEDIA-SEQUENCE':\n            currentSN = level.startSN = parseInt(value1);\n            break;\n          case 'SKIP': {\n            const skipAttrs = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, skipAttrs, [\n                'RECENTLY-REMOVED-DATERANGES',\n              ]);\n            }\n            const skippedSegments =\n              skipAttrs.decimalInteger('SKIPPED-SEGMENTS');\n            if (Number.isFinite(skippedSegments)) {\n              level.skippedSegments = skippedSegments;\n              // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`\n              for (let i = skippedSegments; i--; ) {\n                fragments.unshift(null);\n              }\n              currentSN += skippedSegments;\n            }\n            const recentlyRemovedDateranges = skipAttrs.enumeratedString(\n              'RECENTLY-REMOVED-DATERANGES',\n            );\n            if (recentlyRemovedDateranges) {\n              level.recentlyRemovedDateranges =\n                recentlyRemovedDateranges.split('\\t');\n            }\n            break;\n          }\n          case 'TARGETDURATION':\n            level.targetduration = Math.max(parseInt(value1), 1);\n            break;\n          case 'VERSION':\n            level.version = parseInt(value1);\n            break;\n          case 'INDEPENDENT-SEGMENTS':\n          case 'EXTM3U':\n            break;\n          case 'ENDLIST':\n            level.live = false;\n            break;\n          case '#':\n            if (value1 || value2) {\n              frag.tagList.push(value2 ? [value1, value2] : [value1]);\n            }\n            break;\n          case 'DISCONTINUITY':\n            discontinuityCounter++;\n            frag.tagList.push(['DIS']);\n            break;\n          case 'GAP':\n            frag.gap = true;\n            frag.tagList.push([tag]);\n            break;\n          case 'BITRATE':\n            frag.tagList.push([tag, value1]);\n            break;\n          case 'DATERANGE': {\n            const dateRangeAttr = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, dateRangeAttr, [\n                'ID',\n                'CLASS',\n                'START-DATE',\n                'END-DATE',\n                'SCTE35-CMD',\n                'SCTE35-OUT',\n                'SCTE35-IN',\n              ]);\n              substituteVariablesInAttributes(\n                level,\n                dateRangeAttr,\n                dateRangeAttr.clientAttrs,\n              );\n            }\n            const dateRange = new DateRange(\n              dateRangeAttr,\n              level.dateRanges[dateRangeAttr.ID],\n            );\n            if (dateRange.isValid || level.skippedSegments) {\n              level.dateRanges[dateRange.id] = dateRange;\n            } else {\n              logger.warn(`Ignoring invalid DATERANGE tag: \"${value1}\"`);\n            }\n            // Add to fragment tag list for backwards compatibility (< v1.2.0)\n            frag.tagList.push(['EXT-X-DATERANGE', value1]);\n            break;\n          }\n          case 'DEFINE': {\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              const variableAttributes = new AttrList(value1);\n              substituteVariablesInAttributes(level, variableAttributes, [\n                'NAME',\n                'VALUE',\n                'IMPORT',\n                'QUERYPARAM',\n              ]);\n              if ('IMPORT' in variableAttributes) {\n                importVariableDefinition(\n                  level,\n                  variableAttributes,\n                  multivariantVariableList,\n                );\n              } else {\n                addVariableDefinition(level, variableAttributes, baseurl);\n              }\n            }\n            break;\n          }\n\n          case 'DISCONTINUITY-SEQUENCE':\n            discontinuityCounter = parseInt(value1);\n            break;\n          case 'KEY': {\n            const levelKey = parseKey(value1, baseurl, level);\n            if (levelKey.isSupported()) {\n              if (levelKey.method === 'NONE') {\n                levelkeys = undefined;\n                break;\n              }\n              if (!levelkeys) {\n                levelkeys = {};\n              }\n              if (levelkeys[levelKey.keyFormat]) {\n                levelkeys = Object.assign({}, levelkeys);\n              }\n              levelkeys[levelKey.keyFormat] = levelKey;\n            } else {\n              logger.warn(`[Keys] Ignoring invalid EXT-X-KEY tag: \"${value1}\"`);\n            }\n            break;\n          }\n          case 'START':\n            level.startTimeOffset = parseStartTimeOffset(value1);\n            break;\n          case 'MAP': {\n            const mapAttrs = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, mapAttrs, [\n                'BYTERANGE',\n                'URI',\n              ]);\n            }\n            if (frag.duration) {\n              // Initial segment tag is after segment duration tag.\n              //   #EXTINF: 6.0\n              //   #EXT-X-MAP:URI=\"init.mp4\n              const init = new Fragment(type, baseurl);\n              setInitSegment(init, mapAttrs, id, levelkeys);\n              currentInitSegment = init;\n              frag.initSegment = currentInitSegment;\n              if (\n                currentInitSegment.rawProgramDateTime &&\n                !frag.rawProgramDateTime\n              ) {\n                frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n              }\n            } else {\n              // Initial segment tag is before segment duration tag\n              // Handle case where EXT-X-MAP is declared after EXT-X-BYTERANGE\n              const end = frag.byteRangeEndOffset;\n              if (end) {\n                const start = frag.byteRangeStartOffset as number;\n                nextByteRange = `${end - start}@${start}`;\n              } else {\n                nextByteRange = null;\n              }\n              setInitSegment(frag, mapAttrs, id, levelkeys);\n              currentInitSegment = frag;\n              createNextFrag = true;\n            }\n            break;\n          }\n          case 'SERVER-CONTROL': {\n            const serverControlAttrs = new AttrList(value1);\n            level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');\n            level.canSkipUntil = serverControlAttrs.optionalFloat(\n              'CAN-SKIP-UNTIL',\n              0,\n            );\n            level.canSkipDateRanges =\n              level.canSkipUntil > 0 &&\n              serverControlAttrs.bool('CAN-SKIP-DATERANGES');\n            level.partHoldBack = serverControlAttrs.optionalFloat(\n              'PART-HOLD-BACK',\n              0,\n            );\n            level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);\n            break;\n          }\n          case 'PART-INF': {\n            const partInfAttrs = new AttrList(value1);\n            level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');\n            break;\n          }\n          case 'PART': {\n            let partList = level.partList;\n            if (!partList) {\n              partList = level.partList = [];\n            }\n            const previousFragmentPart =\n              currentPart > 0 ? partList[partList.length - 1] : undefined;\n            const index = currentPart++;\n            const partAttrs = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, partAttrs, [\n                'BYTERANGE',\n                'URI',\n              ]);\n            }\n            const part = new Part(\n              partAttrs,\n              frag,\n              baseurl,\n              index,\n              previousFragmentPart,\n            );\n            partList.push(part);\n            frag.duration += part.duration;\n            break;\n          }\n          case 'PRELOAD-HINT': {\n            const preloadHintAttrs = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, preloadHintAttrs, ['URI']);\n            }\n            level.preloadHint = preloadHintAttrs;\n            break;\n          }\n          case 'RENDITION-REPORT': {\n            const renditionReportAttrs = new AttrList(value1);\n            if (__USE_VARIABLE_SUBSTITUTION__) {\n              substituteVariablesInAttributes(level, renditionReportAttrs, [\n                'URI',\n              ]);\n            }\n            level.renditionReports = level.renditionReports || [];\n            level.renditionReports.push(renditionReportAttrs);\n            break;\n          }\n          default:\n            logger.warn(`line parsed but not handled: ${result}`);\n            break;\n        }\n      }\n    }\n    if (prevFrag && !prevFrag.relurl) {\n      fragments.pop();\n      totalduration -= prevFrag.duration;\n      if (level.partList) {\n        level.fragmentHint = prevFrag;\n      }\n    } else if (level.partList) {\n      assignProgramDateTime(frag, prevFrag);\n      frag.cc = discontinuityCounter;\n      level.fragmentHint = frag;\n      if (levelkeys) {\n        setFragLevelKeys(frag, levelkeys, level);\n      }\n    }\n    const fragmentLength = fragments.length;\n    const firstFragment = fragments[0];\n    const lastFragment = fragments[fragmentLength - 1];\n    totalduration += level.skippedSegments * level.targetduration;\n    if (totalduration > 0 && fragmentLength && lastFragment) {\n      level.averagetargetduration = totalduration / fragmentLength;\n      const lastSn = lastFragment.sn;\n      level.endSN = lastSn !== 'initSegment' ? lastSn : 0;\n      if (!level.live) {\n        lastFragment.endList = true;\n      }\n      if (firstFragment) {\n        level.startCC = firstFragment.cc;\n      }\n    } else {\n      level.endSN = 0;\n      level.startCC = 0;\n    }\n    if (level.fragmentHint) {\n      totalduration += level.fragmentHint.duration;\n    }\n    level.totalduration = totalduration;\n    level.endCC = discontinuityCounter;\n\n    /**\n     * Backfill any missing PDT values\n     * \"If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after\n     * one or more Media Segment URIs, the client SHOULD extrapolate\n     * backward from that tag (using EXTINF durations and/or media\n     * timestamps) to associate dates with those segments.\"\n     * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs\n     * computed.\n     */\n    if (firstPdtIndex > 0) {\n      backfillProgramDateTimes(fragments, firstPdtIndex);\n    }\n\n    return level;\n  }\n}\n\nfunction parseKey(\n  keyTagAttributes: string,\n  baseurl: string,\n  parsed: ParsedMultivariantPlaylist | LevelDetails,\n): LevelKey {\n  // https://tools.ietf.org/html/rfc8216#section-4.3.2.4\n  const keyAttrs = new AttrList(keyTagAttributes);\n  if (__USE_VARIABLE_SUBSTITUTION__) {\n    substituteVariablesInAttributes(parsed, keyAttrs, [\n      'KEYFORMAT',\n      'KEYFORMATVERSIONS',\n      'URI',\n      'IV',\n      'URI',\n    ]);\n  }\n  const decryptmethod = keyAttrs.METHOD ?? '';\n  const decrypturi = keyAttrs.URI;\n  const decryptiv = keyAttrs.hexadecimalInteger('IV');\n  const decryptkeyformatversions = keyAttrs.KEYFORMATVERSIONS;\n  // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of \"identity\".\n  const decryptkeyformat = keyAttrs.KEYFORMAT ?? 'identity';\n\n  if (decrypturi && keyAttrs.IV && !decryptiv) {\n    logger.error(`Invalid IV: ${keyAttrs.IV}`);\n  }\n  // If decrypturi is a URI with a scheme, then baseurl will be ignored\n  // No uri is allowed when METHOD is NONE\n  const resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';\n  const keyFormatVersions = (\n    decryptkeyformatversions ? decryptkeyformatversions : '1'\n  )\n    .split('/')\n    .map(Number)\n    .filter(Number.isFinite);\n\n  return new LevelKey(\n    decryptmethod,\n    resolvedUri,\n    decryptkeyformat,\n    keyFormatVersions,\n    decryptiv,\n  );\n}\n\nfunction parseStartTimeOffset(startAttributes: string): number | null {\n  const startAttrs = new AttrList(startAttributes);\n  const startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');\n  if (Number.isFinite(startTimeOffset)) {\n    return startTimeOffset;\n  }\n  return null;\n}\n\nfunction setCodecs(\n  codecsAttributeValue: string | undefined,\n  level: LevelParsed,\n) {\n  let codecs = (codecsAttributeValue || '').split(/[ ,]+/).filter((c) => c);\n  ['video', 'audio', 'text'].forEach((type: CodecType) => {\n    const filtered = codecs.filter((codec) => isCodecType(codec, type));\n    if (filtered.length) {\n      // Comma separated list of all codecs for type\n      level[`${type}Codec`] = filtered.join(',');\n      // Remove known codecs so that only unknownCodecs are left after iterating through each type\n      codecs = codecs.filter((codec) => filtered.indexOf(codec) === -1);\n    }\n  });\n  level.unknownCodecs = codecs;\n}\n\nfunction assignCodec(\n  media: MediaPlaylist,\n  groupItem: { audioCodec?: string; textCodec?: string },\n  codecProperty: 'audioCodec' | 'textCodec',\n) {\n  const codecValue = groupItem[codecProperty];\n  if (codecValue) {\n    media[codecProperty] = codecValue;\n  }\n}\n\nfunction backfillProgramDateTimes(\n  fragments: M3U8ParserFragments,\n  firstPdtIndex: number,\n) {\n  let fragPrev = fragments[firstPdtIndex] as Fragment;\n  for (let i = firstPdtIndex; i--; ) {\n    const frag = fragments[i];\n    // Exit on delta-playlist skipped segments\n    if (!frag) {\n      return;\n    }\n    frag.programDateTime =\n      (fragPrev.programDateTime as number) - frag.duration * 1000;\n    fragPrev = frag;\n  }\n}\n\nfunction assignProgramDateTime(frag, prevFrag) {\n  if (frag.rawProgramDateTime) {\n    frag.programDateTime = Date.parse(frag.rawProgramDateTime);\n  } else if (prevFrag?.programDateTime) {\n    frag.programDateTime = prevFrag.endProgramDateTime;\n  }\n\n  if (!Number.isFinite(frag.programDateTime)) {\n    frag.programDateTime = null;\n    frag.rawProgramDateTime = null;\n  }\n}\n\nfunction setInitSegment(\n  frag: Fragment,\n  mapAttrs: AttrList,\n  id: number,\n  levelkeys: { [key: string]: LevelKey } | undefined,\n) {\n  frag.relurl = mapAttrs.URI;\n  if (mapAttrs.BYTERANGE) {\n    frag.setByteRange(mapAttrs.BYTERANGE);\n  }\n  frag.level = id;\n  frag.sn = 'initSegment';\n  if (levelkeys) {\n    frag.levelkeys = levelkeys;\n  }\n  frag.initSegment = null;\n}\n\nfunction setFragLevelKeys(\n  frag: Fragment,\n  levelkeys: { [key: string]: LevelKey },\n  level: LevelDetails,\n) {\n  frag.levelkeys = levelkeys;\n  const { encryptedFragments } = level;\n  if (\n    (!encryptedFragments.length ||\n      encryptedFragments[encryptedFragments.length - 1].levelkeys !==\n        levelkeys) &&\n    Object.keys(levelkeys).some(\n      (format) => levelkeys![format].isCommonEncryption,\n    )\n  ) {\n    encryptedFragments.push(frag);\n  }\n}\n","import type { LoaderConfig } from '../config';\nimport type { Fragment } from '../loader/fragment';\nimport type { Part } from '../loader/fragment';\nimport type { KeyLoaderInfo } from '../loader/key-loader';\nimport type { LevelDetails } from '../loader/level-details';\nimport type { HlsUrlParameters } from './level';\n\nexport interface LoaderContext {\n  // target URL\n  url: string;\n  // loader response type (arraybuffer or default response type for playlist)\n  responseType: string;\n  // headers\n  headers?: Record<string, string>;\n  // start byte range offset\n  rangeStart?: number;\n  // end byte range offset\n  rangeEnd?: number;\n  // true if onProgress should report partial chunk of loaded content\n  progressData?: boolean;\n}\n\nexport interface FragmentLoaderContext extends LoaderContext {\n  frag: Fragment;\n  part: Part | null;\n  resetIV?: boolean;\n}\n\nexport interface KeyLoaderContext extends LoaderContext {\n  keyInfo: KeyLoaderInfo;\n  frag: Fragment;\n}\n\nexport interface LoaderConfiguration {\n  // LoaderConfig policy that overrides required settings\n  loadPolicy: LoaderConfig;\n  /**\n   * @deprecated use LoaderConfig timeoutRetry and errorRetry maxNumRetry\n   */\n  // Max number of load retries\n  maxRetry: number;\n  /**\n   * @deprecated use LoaderConfig maxTimeToFirstByteMs and maxLoadTimeMs\n   */\n  // Timeout after which `onTimeOut` callback will be triggered\n  //  when loading has not finished after that delay\n  timeout: number;\n  /**\n   * @deprecated use LoaderConfig timeoutRetry and errorRetry retryDelayMs\n   */\n  // Delay between an I/O error and following connection retry (ms).\n  // This to avoid spamming the server\n  retryDelay: number;\n  /**\n   * @deprecated use LoaderConfig timeoutRetry and errorRetry maxRetryDelayMs\n   */\n  // max connection retry delay (ms)\n  maxRetryDelay: number;\n  // When streaming progressively, this is the minimum chunk size required to emit a PROGRESS event\n  highWaterMark?: number;\n}\n\nexport interface LoaderResponse {\n  url: string;\n  data?: string | ArrayBuffer | Object;\n  // Errors can include HTTP status code and error message\n  // Successful responses should include status code 200\n  code?: number;\n  text?: string;\n}\n\nexport interface LoaderStats {\n  aborted: boolean;\n  loaded: number;\n  retry: number;\n  total: number;\n  chunkCount: number;\n  bwEstimate: number;\n  loading: HlsProgressivePerformanceTiming;\n  parsing: HlsPerformanceTiming;\n  buffering: HlsProgressivePerformanceTiming;\n}\n\nexport interface HlsPerformanceTiming {\n  start: number;\n  end: number;\n}\n\nexport interface HlsChunkPerformanceTiming extends HlsPerformanceTiming {\n  executeStart: number;\n  executeEnd: number;\n}\n\nexport interface HlsProgressivePerformanceTiming extends HlsPerformanceTiming {\n  first: number;\n}\n\nexport type LoaderOnSuccess<T extends LoaderContext> = (\n  response: LoaderResponse,\n  stats: LoaderStats,\n  context: T,\n  networkDetails: any,\n) => void;\n\nexport type LoaderOnProgress<T extends LoaderContext> = (\n  stats: LoaderStats,\n  context: T,\n  data: string | ArrayBuffer,\n  networkDetails: any,\n) => void;\n\nexport type LoaderOnError<T extends LoaderContext> = (\n  error: {\n    // error status code\n    code: number;\n    // error description\n    text: string;\n  },\n  context: T,\n  networkDetails: any,\n  stats: LoaderStats,\n) => void;\n\nexport type LoaderOnTimeout<T extends LoaderContext> = (\n  stats: LoaderStats,\n  context: T,\n  networkDetails: any,\n) => void;\n\nexport type LoaderOnAbort<T extends LoaderContext> = (\n  stats: LoaderStats,\n  context: T,\n  networkDetails: any,\n) => void;\n\nexport interface LoaderCallbacks<T extends LoaderContext> {\n  onSuccess: LoaderOnSuccess<T>;\n  onError: LoaderOnError<T>;\n  onTimeout: LoaderOnTimeout<T>;\n  onAbort?: LoaderOnAbort<T>;\n  onProgress?: LoaderOnProgress<T>;\n}\n\nexport interface Loader<T extends LoaderContext> {\n  destroy(): void;\n  abort(): void;\n  load(\n    context: T,\n    config: LoaderConfiguration,\n    callbacks: LoaderCallbacks<T>,\n  ): void;\n  /**\n   * `getCacheAge()` is called by hls.js to get the duration that a given object\n   * has been sitting in a cache proxy when playing live.  If implemented,\n   * this should return a value in seconds.\n   *\n   * For HTTP based loaders, this should return the contents of the \"age\" header.\n   *\n   * @returns time object being lodaded\n   */\n  getCacheAge?: () => number | null;\n  getResponseHeader?: (name: string) => string | null;\n  context: T | null;\n  stats: LoaderStats;\n}\n\nexport const enum PlaylistContextType {\n  MANIFEST = 'manifest',\n  LEVEL = 'level',\n  AUDIO_TRACK = 'audioTrack',\n  SUBTITLE_TRACK = 'subtitleTrack',\n}\n\nexport const enum PlaylistLevelType {\n  MAIN = 'main',\n  AUDIO = 'audio',\n  SUBTITLE = 'subtitle',\n}\n\nexport interface PlaylistLoaderContext extends LoaderContext {\n  type: PlaylistContextType;\n  // the level index to load\n  level: number | null;\n  // level or track id from LevelLoadingData / TrackLoadingData\n  id: number | null;\n  // Media Playlist Group ID\n  groupId?: string;\n  // Content Steering Pathway ID (or undefined for default Pathway \".\")\n  pathwayId?: string;\n  // internal representation of a parsed m3u8 level playlist\n  levelDetails?: LevelDetails;\n  // Blocking playlist request delivery directives (or null id none were added to playlist url\n  deliveryDirectives: HlsUrlParameters | null;\n}\n","/**\n * PlaylistLoader - delegate for media manifest/playlist loading tasks. Takes care of parsing media to internal data-models.\n *\n * Once loaded, dispatches events with parsed data-models of manifest/levels/audio/subtitle tracks.\n *\n * Uses loader(s) set in config to do actual internal loading of resource tasks.\n */\n\nimport { Events } from '../events';\nimport { ErrorDetails, ErrorTypes } from '../errors';\nimport { logger } from '../utils/logger';\nimport M3U8Parser from './m3u8-parser';\nimport type { LevelParsed, VariableMap } from '../types/level';\nimport type {\n  Loader,\n  LoaderCallbacks,\n  LoaderConfiguration,\n  LoaderContext,\n  LoaderResponse,\n  LoaderStats,\n  PlaylistLoaderContext,\n} from '../types/loader';\nimport { PlaylistContextType, PlaylistLevelType } from '../types/loader';\nimport { LevelDetails } from './level-details';\nimport { AttrList } from '../utils/attr-list';\nimport type Hls from '../hls';\nimport type {\n  ErrorData,\n  LevelLoadingData,\n  ManifestLoadingData,\n  TrackLoadingData,\n} from '../types/events';\nimport type { NetworkComponentAPI } from '../types/component-api';\nimport type { MediaAttributes } from '../types/media-playlist';\nimport type { LoaderConfig, RetryConfig } from '../config';\n\nfunction mapContextToLevelType(\n  context: PlaylistLoaderContext,\n): PlaylistLevelType {\n  const { type } = context;\n\n  switch (type) {\n    case PlaylistContextType.AUDIO_TRACK:\n      return PlaylistLevelType.AUDIO;\n    case PlaylistContextType.SUBTITLE_TRACK:\n      return PlaylistLevelType.SUBTITLE;\n    default:\n      return PlaylistLevelType.MAIN;\n  }\n}\n\nfunction getResponseUrl(\n  response: LoaderResponse,\n  context: PlaylistLoaderContext,\n): string {\n  let url = response.url;\n  // responseURL not supported on some browsers (it is used to detect URL redirection)\n  // data-uri mode also not supported (but no need to detect redirection)\n  if (url === undefined || url.indexOf('data:') === 0) {\n    // fallback to initial URL\n    url = context.url;\n  }\n  return url;\n}\n\nclass PlaylistLoader implements NetworkComponentAPI {\n  private readonly hls: Hls;\n  private readonly loaders: {\n    [key: string]: Loader<LoaderContext>;\n  } = Object.create(null);\n  private variableList: VariableMap | null = null;\n\n  constructor(hls: Hls) {\n    this.hls = hls;\n    this.registerListeners();\n  }\n\n  public startLoad(startPosition: number): void {}\n\n  public stopLoad(): void {\n    this.destroyInternalLoaders();\n  }\n\n  private registerListeners() {\n    const { hls } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n  }\n\n  private unregisterListeners() {\n    const { hls } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n  }\n\n  /**\n   * Returns defaults or configured loader-type overloads (pLoader and loader config params)\n   */\n  private createInternalLoader(\n    context: PlaylistLoaderContext,\n  ): Loader<LoaderContext> {\n    const config = this.hls.config;\n    const PLoader = config.pLoader;\n    const Loader = config.loader;\n    const InternalLoader = PLoader || Loader;\n    const loader = new InternalLoader(config) as Loader<PlaylistLoaderContext>;\n\n    this.loaders[context.type] = loader;\n    return loader;\n  }\n\n  private getInternalLoader(\n    context: PlaylistLoaderContext,\n  ): Loader<LoaderContext> | undefined {\n    return this.loaders[context.type];\n  }\n\n  private resetInternalLoader(contextType): void {\n    if (this.loaders[contextType]) {\n      delete this.loaders[contextType];\n    }\n  }\n\n  /**\n   * Call `destroy` on all internal loader instances mapped (one per context type)\n   */\n  private destroyInternalLoaders(): void {\n    for (const contextType in this.loaders) {\n      const loader = this.loaders[contextType];\n      if (loader) {\n        loader.destroy();\n      }\n\n      this.resetInternalLoader(contextType);\n    }\n  }\n\n  public destroy(): void {\n    this.variableList = null;\n    this.unregisterListeners();\n    this.destroyInternalLoaders();\n  }\n\n  private onManifestLoading(\n    event: Events.MANIFEST_LOADING,\n    data: ManifestLoadingData,\n  ) {\n    const { url } = data;\n    this.variableList = null;\n    this.load({\n      id: null,\n      level: 0,\n      responseType: 'text',\n      type: PlaylistContextType.MANIFEST,\n      url,\n      deliveryDirectives: null,\n    });\n  }\n\n  private onLevelLoading(event: Events.LEVEL_LOADING, data: LevelLoadingData) {\n    const { id, level, pathwayId, url, deliveryDirectives } = data;\n    this.load({\n      id,\n      level,\n      pathwayId,\n      responseType: 'text',\n      type: PlaylistContextType.LEVEL,\n      url,\n      deliveryDirectives,\n    });\n  }\n\n  private onAudioTrackLoading(\n    event: Events.AUDIO_TRACK_LOADING,\n    data: TrackLoadingData,\n  ) {\n    const { id, groupId, url, deliveryDirectives } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.AUDIO_TRACK,\n      url,\n      deliveryDirectives,\n    });\n  }\n\n  private onSubtitleTrackLoading(\n    event: Events.SUBTITLE_TRACK_LOADING,\n    data: TrackLoadingData,\n  ) {\n    const { id, groupId, url, deliveryDirectives } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.SUBTITLE_TRACK,\n      url,\n      deliveryDirectives,\n    });\n  }\n\n  private load(context: PlaylistLoaderContext): void {\n    const config = this.hls.config;\n\n    // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);\n\n    // Check if a loader for this context already exists\n    let loader = this.getInternalLoader(context);\n    if (loader) {\n      const loaderContext = loader.context as PlaylistLoaderContext;\n      if (\n        loaderContext &&\n        loaderContext.url === context.url &&\n        loaderContext.level === context.level\n      ) {\n        // same URL can't overlap\n        logger.trace('[playlist-loader]: playlist request ongoing');\n        return;\n      }\n      logger.log(\n        `[playlist-loader]: aborting previous loader for type: ${context.type}`,\n      );\n      loader.abort();\n    }\n\n    // apply different configs for retries depending on\n    // context (manifest, level, audio/subs playlist)\n    let loadPolicy: LoaderConfig;\n    if (context.type === PlaylistContextType.MANIFEST) {\n      loadPolicy = config.manifestLoadPolicy.default;\n    } else {\n      loadPolicy = Object.assign({}, config.playlistLoadPolicy.default, {\n        timeoutRetry: null,\n        errorRetry: null,\n      });\n    }\n    loader = this.createInternalLoader(context);\n\n    // Override level/track timeout for LL-HLS requests\n    // (the default of 10000ms is counter productive to blocking playlist reload requests)\n    if (Number.isFinite(context.deliveryDirectives?.part)) {\n      let levelDetails: LevelDetails | undefined;\n      if (\n        context.type === PlaylistContextType.LEVEL &&\n        context.level !== null\n      ) {\n        levelDetails = this.hls.levels[context.level].details;\n      } else if (\n        context.type === PlaylistContextType.AUDIO_TRACK &&\n        context.id !== null\n      ) {\n        levelDetails = this.hls.audioTracks[context.id].details;\n      } else if (\n        context.type === PlaylistContextType.SUBTITLE_TRACK &&\n        context.id !== null\n      ) {\n        levelDetails = this.hls.subtitleTracks[context.id].details;\n      }\n      if (levelDetails) {\n        const partTarget = levelDetails.partTarget;\n        const targetDuration = levelDetails.targetduration;\n        if (partTarget && targetDuration) {\n          const maxLowLatencyPlaylistRefresh =\n            Math.max(partTarget * 3, targetDuration * 0.8) * 1000;\n          loadPolicy = Object.assign({}, loadPolicy, {\n            maxTimeToFirstByteMs: Math.min(\n              maxLowLatencyPlaylistRefresh,\n              loadPolicy.maxTimeToFirstByteMs,\n            ),\n            maxLoadTimeMs: Math.min(\n              maxLowLatencyPlaylistRefresh,\n              loadPolicy.maxTimeToFirstByteMs,\n            ),\n          });\n        }\n      }\n    }\n\n    const legacyRetryCompatibility: RetryConfig | Record<string, void> =\n      loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n    const loaderConfig: LoaderConfiguration = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n      retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n      maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0,\n    };\n\n    const loaderCallbacks: LoaderCallbacks<PlaylistLoaderContext> = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        const loader = this.getInternalLoader(context) as\n          | Loader<PlaylistLoaderContext>\n          | undefined;\n        this.resetInternalLoader(context.type);\n\n        const string = response.data as string;\n\n        // Validate if it is an M3U8 at all\n        if (string.indexOf('#EXTM3U') !== 0) {\n          this.handleManifestParsingError(\n            response,\n            context,\n            new Error('no EXTM3U delimiter'),\n            networkDetails || null,\n            stats,\n          );\n          return;\n        }\n\n        stats.parsing.start = performance.now();\n        if (M3U8Parser.isMediaPlaylist(string)) {\n          this.handleTrackOrLevelPlaylist(\n            response,\n            stats,\n            context,\n            networkDetails || null,\n            loader,\n          );\n        } else {\n          this.handleMasterPlaylist(response, stats, context, networkDetails);\n        }\n      },\n      onError: (response, context, networkDetails, stats) => {\n        this.handleNetworkError(\n          context,\n          networkDetails,\n          false,\n          response,\n          stats,\n        );\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        this.handleNetworkError(\n          context,\n          networkDetails,\n          true,\n          undefined,\n          stats,\n        );\n      },\n    };\n\n    // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);\n\n    loader.load(context, loaderConfig, loaderCallbacks);\n  }\n\n  private handleMasterPlaylist(\n    response: LoaderResponse,\n    stats: LoaderStats,\n    context: PlaylistLoaderContext,\n    networkDetails: any,\n  ): void {\n    const hls = this.hls;\n    const string = response.data as string;\n\n    const url = getResponseUrl(response, context);\n\n    const parsedResult = M3U8Parser.parseMasterPlaylist(string, url);\n\n    if (parsedResult.playlistParsingError) {\n      this.handleManifestParsingError(\n        response,\n        context,\n        parsedResult.playlistParsingError,\n        networkDetails,\n        stats,\n      );\n      return;\n    }\n\n    const {\n      contentSteering,\n      levels,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList,\n    } = parsedResult;\n\n    this.variableList = variableList;\n\n    const {\n      AUDIO: audioTracks = [],\n      SUBTITLES: subtitles,\n      'CLOSED-CAPTIONS': captions,\n    } = M3U8Parser.parseMasterPlaylistMedia(string, url, parsedResult);\n\n    if (audioTracks.length) {\n      // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\n      const embeddedAudioFound: boolean = audioTracks.some(\n        (audioTrack) => !audioTrack.url,\n      );\n\n      // if no embedded audio track defined, but audio codec signaled in quality level,\n      // we need to signal this main audio track this could happen with playlists with\n      // alt audio rendition in which quality levels (main)\n      // contains both audio+video. but with mixed audio track not signaled\n      if (\n        !embeddedAudioFound &&\n        levels[0].audioCodec &&\n        !levels[0].attrs.AUDIO\n      ) {\n        logger.log(\n          '[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one',\n        );\n        audioTracks.unshift({\n          type: 'main',\n          name: 'main',\n          groupId: 'main',\n          default: false,\n          autoselect: false,\n          forced: false,\n          id: -1,\n          attrs: new AttrList({}) as MediaAttributes,\n          bitrate: 0,\n          url: '',\n        });\n      }\n    }\n\n    hls.trigger(Events.MANIFEST_LOADED, {\n      levels,\n      audioTracks,\n      subtitles,\n      captions,\n      contentSteering,\n      url,\n      stats,\n      networkDetails,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList,\n    });\n  }\n\n  private handleTrackOrLevelPlaylist(\n    response: LoaderResponse,\n    stats: LoaderStats,\n    context: PlaylistLoaderContext,\n    networkDetails: any,\n    loader: Loader<PlaylistLoaderContext> | undefined,\n  ): void {\n    const hls = this.hls;\n    const { id, level, type } = context;\n\n    const url = getResponseUrl(response, context);\n    const levelUrlId = 0;\n    const levelId = Number.isFinite(level as number)\n      ? (level as number)\n      : Number.isFinite(id as number)\n        ? (id as number)\n        : 0;\n    const levelType = mapContextToLevelType(context);\n    const levelDetails: LevelDetails = M3U8Parser.parseLevelPlaylist(\n      response.data as string,\n      url,\n      levelId,\n      levelType,\n      levelUrlId,\n      this.variableList,\n    );\n\n    // We have done our first request (Manifest-type) and receive\n    // not a master playlist but a chunk-list (track/level)\n    // We fire the manifest-loaded event anyway with the parsed level-details\n    // by creating a single-level structure for it.\n    if (type === PlaylistContextType.MANIFEST) {\n      const singleLevel: LevelParsed = {\n        attrs: new AttrList({}),\n        bitrate: 0,\n        details: levelDetails,\n        name: '',\n        url,\n      };\n\n      hls.trigger(Events.MANIFEST_LOADED, {\n        levels: [singleLevel],\n        audioTracks: [],\n        url,\n        stats,\n        networkDetails,\n        sessionData: null,\n        sessionKeys: null,\n        contentSteering: null,\n        startTimeOffset: null,\n        variableList: null,\n      });\n    }\n\n    // save parsing time\n    stats.parsing.end = performance.now();\n\n    // extend the context with the new levelDetails property\n    context.levelDetails = levelDetails;\n\n    this.handlePlaylistLoaded(\n      levelDetails,\n      response,\n      stats,\n      context,\n      networkDetails,\n      loader,\n    );\n  }\n\n  private handleManifestParsingError(\n    response: LoaderResponse,\n    context: PlaylistLoaderContext,\n    error: Error,\n    networkDetails: any,\n    stats: LoaderStats,\n  ): void {\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.NETWORK_ERROR,\n      details: ErrorDetails.MANIFEST_PARSING_ERROR,\n      fatal: context.type === PlaylistContextType.MANIFEST,\n      url: response.url,\n      err: error,\n      error,\n      reason: error.message,\n      response,\n      context,\n      networkDetails,\n      stats,\n    });\n  }\n\n  private handleNetworkError(\n    context: PlaylistLoaderContext,\n    networkDetails: any,\n    timeout = false,\n    response: { code: number; text: string } | undefined,\n    stats: LoaderStats,\n  ): void {\n    let message = `A network ${\n      timeout\n        ? 'timeout'\n        : 'error' + (response ? ' (status ' + response.code + ')' : '')\n    } occurred while loading ${context.type}`;\n    if (context.type === PlaylistContextType.LEVEL) {\n      message += `: ${context.level} id: ${context.id}`;\n    } else if (\n      context.type === PlaylistContextType.AUDIO_TRACK ||\n      context.type === PlaylistContextType.SUBTITLE_TRACK\n    ) {\n      message += ` id: ${context.id} group-id: \"${context.groupId}\"`;\n    }\n    const error = new Error(message);\n    logger.warn(`[playlist-loader]: ${message}`);\n    let details = ErrorDetails.UNKNOWN;\n    let fatal = false;\n\n    const loader = this.getInternalLoader(context);\n\n    switch (context.type) {\n      case PlaylistContextType.MANIFEST:\n        details = timeout\n          ? ErrorDetails.MANIFEST_LOAD_TIMEOUT\n          : ErrorDetails.MANIFEST_LOAD_ERROR;\n        fatal = true;\n        break;\n      case PlaylistContextType.LEVEL:\n        details = timeout\n          ? ErrorDetails.LEVEL_LOAD_TIMEOUT\n          : ErrorDetails.LEVEL_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        details = timeout\n          ? ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT\n          : ErrorDetails.AUDIO_TRACK_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        details = timeout\n          ? ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT\n          : ErrorDetails.SUBTITLE_LOAD_ERROR;\n        fatal = false;\n        break;\n    }\n\n    if (loader) {\n      this.resetInternalLoader(context.type);\n    }\n\n    const errorData: ErrorData = {\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal,\n      url: context.url,\n      loader,\n      context,\n      error,\n      networkDetails,\n      stats,\n    };\n\n    if (response) {\n      const url = networkDetails?.url || context.url;\n      errorData.response = { url, data: undefined as any, ...response };\n    }\n\n    this.hls.trigger(Events.ERROR, errorData);\n  }\n\n  private handlePlaylistLoaded(\n    levelDetails: LevelDetails,\n    response: LoaderResponse,\n    stats: LoaderStats,\n    context: PlaylistLoaderContext,\n    networkDetails: any,\n    loader: Loader<PlaylistLoaderContext> | undefined,\n  ): void {\n    const hls = this.hls;\n    const { type, level, id, groupId, deliveryDirectives } = context;\n    const url = getResponseUrl(response, context);\n    const parent = mapContextToLevelType(context);\n    const levelIndex =\n      typeof context.level === 'number' && parent === PlaylistLevelType.MAIN\n        ? (level as number)\n        : undefined;\n    if (!levelDetails.fragments.length) {\n      const error = new Error('No Segments found in Playlist');\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.LEVEL_EMPTY_ERROR,\n        fatal: false,\n        url,\n        error,\n        reason: error.message,\n        response,\n        context,\n        level: levelIndex,\n        parent,\n        networkDetails,\n        stats,\n      });\n      return;\n    }\n    if (!levelDetails.targetduration) {\n      levelDetails.playlistParsingError = new Error('Missing Target Duration');\n    }\n    const error = levelDetails.playlistParsingError;\n    if (error) {\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.LEVEL_PARSING_ERROR,\n        fatal: false,\n        url,\n        error,\n        reason: error.message,\n        response,\n        context,\n        level: levelIndex,\n        parent,\n        networkDetails,\n        stats,\n      });\n      return;\n    }\n\n    if (levelDetails.live && loader) {\n      if (loader.getCacheAge) {\n        levelDetails.ageHeader = loader.getCacheAge() || 0;\n      }\n      if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {\n        levelDetails.ageHeader = 0;\n      }\n    }\n\n    switch (type) {\n      case PlaylistContextType.MANIFEST:\n      case PlaylistContextType.LEVEL:\n        hls.trigger(Events.LEVEL_LOADED, {\n          details: levelDetails,\n          level: levelIndex || 0,\n          id: id || 0,\n          stats,\n          networkDetails,\n          deliveryDirectives,\n        });\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        hls.trigger(Events.AUDIO_TRACK_LOADED, {\n          details: levelDetails,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives,\n        });\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        hls.trigger(Events.SUBTITLE_TRACK_LOADED, {\n          details: levelDetails,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives,\n        });\n        break;\n    }\n  }\n}\n\nexport default PlaylistLoader;\n","import { logger } from './logger';\n\nexport function sendAddTrackEvent(track: TextTrack, videoEl: HTMLMediaElement) {\n  let event: Event;\n  try {\n    event = new Event('addtrack');\n  } catch (err) {\n    // for IE11\n    event = document.createEvent('Event');\n    event.initEvent('addtrack', false, false);\n  }\n  (event as any).track = track;\n  videoEl.dispatchEvent(event);\n}\n\nexport function addCueToTrack(track: TextTrack, cue: VTTCue) {\n  // Sometimes there are cue overlaps on segmented vtts so the same\n  // cue can appear more than once in different vtt files.\n  // This avoid showing duplicated cues with same timecode and text.\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues && !track.cues.getCueById(cue.id)) {\n    try {\n      track.addCue(cue);\n      if (!track.cues.getCueById(cue.id)) {\n        throw new Error(`addCue is failed for: ${cue}`);\n      }\n    } catch (err) {\n      logger.debug(`[texttrack-utils]: ${err}`);\n      try {\n        const textTrackCue = new (self.TextTrackCue as any)(\n          cue.startTime,\n          cue.endTime,\n          cue.text,\n        );\n        textTrackCue.id = cue.id;\n        track.addCue(textTrackCue);\n      } catch (err2) {\n        logger.debug(\n          `[texttrack-utils]: Legacy TextTrackCue fallback failed: ${err2}`,\n        );\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\n\nexport function clearCurrentCues(track: TextTrack) {\n  // When track.mode is disabled, track.cues will be null.\n  // To guarantee the removal of cues, we need to temporarily\n  // change the mode to hidden\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues) {\n    for (let i = track.cues.length; i--; ) {\n      track.removeCue(track.cues[i]);\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\n\nexport function removeCuesInRange(\n  track: TextTrack,\n  start: number,\n  end: number,\n  predicate?: (cue: TextTrackCue) => boolean,\n) {\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n\n  if (track.cues && track.cues.length > 0) {\n    const cues = getCuesInRange(track.cues, start, end);\n    for (let i = 0; i < cues.length; i++) {\n      if (!predicate || predicate(cues[i])) {\n        track.removeCue(cues[i]);\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\n\n// Find first cue starting after given time.\n// Modified version of binary search O(log(n)).\nfunction getFirstCueIndexAfterTime(\n  cues: TextTrackCueList | TextTrackCue[],\n  time: number,\n): number {\n  // If first cue starts after time, start there\n  if (time < cues[0].startTime) {\n    return 0;\n  }\n  // If the last cue ends before time there is no overlap\n  const len = cues.length - 1;\n  if (time > cues[len].endTime) {\n    return -1;\n  }\n\n  let left = 0;\n  let right = len;\n\n  while (left <= right) {\n    const mid = Math.floor((right + left) / 2);\n\n    if (time < cues[mid].startTime) {\n      right = mid - 1;\n    } else if (time > cues[mid].startTime && left < len) {\n      left = mid + 1;\n    } else {\n      // If it's not lower or higher, it must be equal.\n      return mid;\n    }\n  }\n  // At this point, left and right have swapped.\n  // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.\n  return cues[left].startTime - time < time - cues[right].startTime\n    ? left\n    : right;\n}\n\nexport function getCuesInRange(\n  cues: TextTrackCueList | TextTrackCue[],\n  start: number,\n  end: number,\n): TextTrackCue[] {\n  const cuesFound: TextTrackCue[] = [];\n  const firstCueInRange = getFirstCueIndexAfterTime(cues, start);\n  if (firstCueInRange > -1) {\n    for (let i = firstCueInRange, len = cues.length; i < len; i++) {\n      const cue = cues[i];\n      if (cue.startTime >= start && cue.endTime <= end) {\n        cuesFound.push(cue);\n      } else if (cue.startTime > end) {\n        return cuesFound;\n      }\n    }\n  }\n  return cuesFound;\n}\n\nexport function filterSubtitleTracks(\n  textTrackList: TextTrackList,\n): TextTrack[] {\n  const tracks: TextTrack[] = [];\n  for (let i = 0; i < textTrackList.length; i++) {\n    const track = textTrackList[i];\n    // Edge adds a track without a label; we don't want to use it\n    if (\n      (track.kind === 'subtitles' || track.kind === 'captions') &&\n      track.label\n    ) {\n      tracks.push(textTrackList[i]);\n    }\n  }\n  return tracks;\n}\n","import type { RationalTimestamp } from '../utils/timescale-conversion';\n\nexport interface Demuxer {\n  demux(\n    data: Uint8Array,\n    timeOffset: number,\n    isSampleAes?: boolean,\n    flush?: boolean,\n  ): DemuxerResult;\n  demuxSampleAes(\n    data: Uint8Array,\n    keyData: KeyData,\n    timeOffset: number,\n  ): Promise<DemuxerResult>;\n  flush(timeOffset?: number): DemuxerResult | Promise<DemuxerResult>;\n  destroy(): void;\n  resetInitSegment(\n    initSegment: Uint8Array | undefined,\n    audioCodec: string | undefined,\n    videoCodec: string | undefined,\n    trackDuration: number,\n  );\n  resetTimeStamp(defaultInitPTS?: RationalTimestamp | null): void;\n  resetContiguity(): void;\n}\n\nexport interface DemuxerResult {\n  audioTrack: DemuxedAudioTrack;\n  videoTrack: DemuxedVideoTrackBase;\n  id3Track: DemuxedMetadataTrack;\n  textTrack: DemuxedUserdataTrack;\n}\n\nexport interface DemuxedTrack {\n  type: string;\n  id: number;\n  pid: number;\n  inputTimeScale: number;\n  sequenceNumber: number;\n  samples:\n    | AudioSample[]\n    | VideoSample[]\n    | MetadataSample[]\n    | UserdataSample[]\n    | Uint8Array;\n  timescale?: number;\n  container?: string;\n  dropped: number;\n  duration?: number;\n  pesData?: ElementaryStreamData | null;\n  codec?: string;\n}\n\nexport interface PassthroughTrack extends DemuxedTrack {\n  sampleDuration: number;\n  samples: Uint8Array;\n  timescale: number;\n  duration: number;\n  codec: string;\n}\nexport interface DemuxedAudioTrack extends DemuxedTrack {\n  config?: number[] | Uint8Array;\n  samplerate?: number;\n  segmentCodec?: string;\n  channelCount?: number;\n  manifestCodec?: string;\n  samples: AudioSample[];\n}\n\nexport interface DemuxedVideoTrackBase extends DemuxedTrack {\n  width?: number;\n  height?: number;\n  pixelRatio?: [number, number];\n  audFound?: boolean;\n  pps?: Uint8Array[];\n  sps?: Uint8Array[];\n  naluState?: number;\n  segmentCodec?: string;\n  manifestCodec?: string;\n  samples: VideoSample[] | Uint8Array;\n}\n\nexport interface DemuxedVideoTrack extends DemuxedVideoTrackBase {\n  samples: VideoSample[];\n}\n\nexport interface DemuxedMetadataTrack extends DemuxedTrack {\n  samples: MetadataSample[];\n}\n\nexport interface DemuxedUserdataTrack extends DemuxedTrack {\n  samples: UserdataSample[];\n}\n\nexport const enum MetadataSchema {\n  audioId3 = 'org.id3',\n  dateRange = 'com.apple.quicktime.HLS',\n  emsg = 'https://aomedia.org/emsg/ID3',\n}\nexport interface MetadataSample {\n  pts: number;\n  dts: number;\n  duration: number;\n  len?: number;\n  data: Uint8Array;\n  type: MetadataSchema;\n}\n\nexport interface UserdataSample {\n  pts: number;\n  bytes?: Uint8Array;\n  type?: number;\n  payloadType?: number;\n  uuid?: string;\n  userData?: string;\n  userDataBytes?: Uint8Array;\n}\n\nexport interface VideoSample {\n  dts: number;\n  pts: number;\n  key: boolean;\n  frame: boolean;\n  units: VideoSampleUnit[];\n  debug: string;\n  length: number;\n}\n\nexport interface VideoSampleUnit {\n  data: Uint8Array;\n  type: number;\n  state?: number;\n}\n\nexport type AudioSample = {\n  unit: Uint8Array;\n  pts: number;\n};\n\nexport type AudioFrame = {\n  sample: AudioSample;\n  length: number;\n  missing: number;\n};\n\nexport interface ElementaryStreamData {\n  data: Uint8Array[];\n  size: number;\n}\n\nexport interface KeyData {\n  method: string;\n  key: Uint8Array;\n  iv: Uint8Array;\n}\n","import { Events } from '../events';\nimport {\n  sendAddTrackEvent,\n  clearCurrentCues,\n  removeCuesInRange,\n} from '../utils/texttrack-utils';\nimport * as ID3 from '../demux/id3';\nimport {\n  DateRange,\n  isDateRangeCueAttribute,\n  isSCTE35Attribute,\n} from '../loader/date-range';\nimport { MetadataSchema } from '../types/demuxer';\nimport type {\n  BufferFlushingData,\n  FragParsingMetadataData,\n  LevelUpdatedData,\n  MediaAttachedData,\n} from '../types/events';\nimport type { ComponentAPI } from '../types/component-api';\nimport type Hls from '../hls';\n\ndeclare global {\n  interface Window {\n    WebKitDataCue: VTTCue | void;\n  }\n}\n\nconst MIN_CUE_DURATION = 0.25;\n\nfunction getCueClass(): typeof VTTCue | typeof TextTrackCue | undefined {\n  if (typeof self === 'undefined') return undefined;\n  return self.VTTCue || self.TextTrackCue;\n}\n\nfunction createCueWithDataFields(\n  Cue: typeof VTTCue | typeof TextTrackCue,\n  startTime: number,\n  endTime: number,\n  data: Object,\n  type?: string,\n): VTTCue | TextTrackCue | undefined {\n  let cue = new Cue(startTime, endTime, '');\n  try {\n    (cue as any).value = data;\n    if (type) {\n      (cue as any).type = type;\n    }\n  } catch (e) {\n    cue = new Cue(\n      startTime,\n      endTime,\n      JSON.stringify(type ? { type, ...data } : data),\n    );\n  }\n  return cue;\n}\n\n// VTTCue latest draft allows an infinite duration, fallback\n// to MAX_VALUE if necessary\nconst MAX_CUE_ENDTIME = (() => {\n  const Cue = getCueClass();\n  try {\n    Cue && new Cue(0, Number.POSITIVE_INFINITY, '');\n  } catch (e) {\n    return Number.MAX_VALUE;\n  }\n  return Number.POSITIVE_INFINITY;\n})();\n\nfunction dateRangeDateToTimelineSeconds(date: Date, offset: number): number {\n  return date.getTime() / 1000 - offset;\n}\n\nfunction hexToArrayBuffer(str): ArrayBuffer {\n  return Uint8Array.from(\n    str\n      .replace(/^0x/, '')\n      .replace(/([\\da-fA-F]{2}) ?/g, '0x$1 ')\n      .replace(/ +$/, '')\n      .split(' '),\n  ).buffer;\n}\nclass ID3TrackController implements ComponentAPI {\n  private hls: Hls;\n  private id3Track: TextTrack | null = null;\n  private media: HTMLMediaElement | null = null;\n  private dateRangeCuesAppended: Record<\n    string,\n    {\n      cues: Record<string, VTTCue | TextTrackCue>;\n      dateRange: DateRange;\n      durationKnown: boolean;\n    }\n  > = {};\n\n  constructor(hls) {\n    this.hls = hls;\n    this._registerListeners();\n  }\n\n  destroy() {\n    this._unregisterListeners();\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n    // @ts-ignore\n    this.hls = null;\n  }\n\n  private _registerListeners() {\n    const { hls } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n\n  private _unregisterListeners() {\n    const { hls } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n\n  // Add ID3 metatadata text track.\n  protected onMediaAttached(\n    event: Events.MEDIA_ATTACHED,\n    data: MediaAttachedData,\n  ): void {\n    this.media = data.media;\n  }\n\n  protected onMediaDetaching(): void {\n    if (!this.id3Track) {\n      return;\n    }\n    clearCurrentCues(this.id3Track);\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n  }\n\n  private onManifestLoading() {\n    this.dateRangeCuesAppended = {};\n  }\n\n  createTrack(media: HTMLMediaElement): TextTrack {\n    const track = this.getID3Track(media.textTracks) as TextTrack;\n    track.mode = 'hidden';\n    return track;\n  }\n\n  getID3Track(textTracks: TextTrackList): TextTrack | void {\n    if (!this.media) {\n      return;\n    }\n    for (let i = 0; i < textTracks.length; i++) {\n      const textTrack: TextTrack = textTracks[i];\n      if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\n        // send 'addtrack' when reusing the textTrack for metadata,\n        // same as what we do for captions\n        sendAddTrackEvent(textTrack, this.media);\n\n        return textTrack;\n      }\n    }\n    return this.media.addTextTrack('metadata', 'id3');\n  }\n\n  onFragParsingMetadata(\n    event: Events.FRAG_PARSING_METADATA,\n    data: FragParsingMetadataData,\n  ) {\n    if (!this.media) {\n      return;\n    }\n\n    const {\n      hls: {\n        config: { enableEmsgMetadataCues, enableID3MetadataCues },\n      },\n    } = this;\n    if (!enableEmsgMetadataCues && !enableID3MetadataCues) {\n      return;\n    }\n\n    const { samples } = data;\n\n    // create track dynamically\n    if (!this.id3Track) {\n      this.id3Track = this.createTrack(this.media);\n    }\n\n    const Cue = getCueClass();\n    if (!Cue) {\n      return;\n    }\n\n    for (let i = 0; i < samples.length; i++) {\n      const type = samples[i].type;\n      if (\n        (type === MetadataSchema.emsg && !enableEmsgMetadataCues) ||\n        !enableID3MetadataCues\n      ) {\n        continue;\n      }\n\n      const frames = ID3.getID3Frames(samples[i].data);\n      if (frames) {\n        const startTime = samples[i].pts;\n        let endTime: number = startTime + samples[i].duration;\n\n        if (endTime > MAX_CUE_ENDTIME) {\n          endTime = MAX_CUE_ENDTIME;\n        }\n\n        const timeDiff = endTime - startTime;\n        if (timeDiff <= 0) {\n          endTime = startTime + MIN_CUE_DURATION;\n        }\n\n        for (let j = 0; j < frames.length; j++) {\n          const frame = frames[j];\n          // Safari doesn't put the timestamp frame in the TextTrack\n          if (!ID3.isTimeStampFrame(frame)) {\n            // add a bounds to any unbounded cues\n            this.updateId3CueEnds(startTime, type);\n            const cue = createCueWithDataFields(\n              Cue,\n              startTime,\n              endTime,\n              frame,\n              type,\n            );\n            if (cue) {\n              this.id3Track.addCue(cue);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  updateId3CueEnds(startTime: number, type: MetadataSchema) {\n    const cues = this.id3Track?.cues;\n    if (cues) {\n      for (let i = cues.length; i--; ) {\n        const cue = cues[i] as any;\n        if (\n          cue.type === type &&\n          cue.startTime < startTime &&\n          cue.endTime === MAX_CUE_ENDTIME\n        ) {\n          cue.endTime = startTime;\n        }\n      }\n    }\n  }\n\n  onBufferFlushing(\n    event: Events.BUFFER_FLUSHING,\n    { startOffset, endOffset, type }: BufferFlushingData,\n  ) {\n    const { id3Track, hls } = this;\n    if (!hls) {\n      return;\n    }\n\n    const {\n      config: { enableEmsgMetadataCues, enableID3MetadataCues },\n    } = hls;\n    if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {\n      let predicate;\n\n      if (type === 'audio') {\n        predicate = (cue) =>\n          (cue as any).type === MetadataSchema.audioId3 &&\n          enableID3MetadataCues;\n      } else if (type === 'video') {\n        predicate = (cue) =>\n          (cue as any).type === MetadataSchema.emsg && enableEmsgMetadataCues;\n      } else {\n        predicate = (cue) =>\n          ((cue as any).type === MetadataSchema.audioId3 &&\n            enableID3MetadataCues) ||\n          ((cue as any).type === MetadataSchema.emsg && enableEmsgMetadataCues);\n      }\n      removeCuesInRange(id3Track, startOffset, endOffset, predicate);\n    }\n  }\n\n  onLevelUpdated(event: Events.LEVEL_UPDATED, { details }: LevelUpdatedData) {\n    if (\n      !this.media ||\n      !details.hasProgramDateTime ||\n      !this.hls.config.enableDateRangeMetadataCues\n    ) {\n      return;\n    }\n    const { dateRangeCuesAppended, id3Track } = this;\n    const { dateRanges } = details;\n    const ids = Object.keys(dateRanges);\n    // Remove cues from track not found in details.dateRanges\n    if (id3Track) {\n      const idsToRemove = Object.keys(dateRangeCuesAppended).filter(\n        (id) => !ids.includes(id),\n      );\n      for (let i = idsToRemove.length; i--; ) {\n        const id = idsToRemove[i];\n        Object.keys(dateRangeCuesAppended[id].cues).forEach((key) => {\n          id3Track.removeCue(dateRangeCuesAppended[id].cues[key]);\n        });\n        delete dateRangeCuesAppended[id];\n      }\n    }\n    // Exit if the playlist does not have Date Ranges or does not have Program Date Time\n    const lastFragment = details.fragments[details.fragments.length - 1];\n    if (ids.length === 0 || !Number.isFinite(lastFragment?.programDateTime)) {\n      return;\n    }\n\n    if (!this.id3Track) {\n      this.id3Track = this.createTrack(this.media);\n    }\n\n    const dateTimeOffset =\n      (lastFragment.programDateTime as number) / 1000 - lastFragment.start;\n    const Cue = getCueClass();\n\n    for (let i = 0; i < ids.length; i++) {\n      const id = ids[i];\n      const dateRange = dateRanges[id];\n      const startTime = dateRangeDateToTimelineSeconds(\n        dateRange.startDate,\n        dateTimeOffset,\n      );\n\n      // Process DateRanges to determine end-time (known DURATION, END-DATE, or END-ON-NEXT)\n      const appendedDateRangeCues = dateRangeCuesAppended[id];\n      const cues = appendedDateRangeCues?.cues || {};\n      let durationKnown = appendedDateRangeCues?.durationKnown || false;\n      let endTime = MAX_CUE_ENDTIME;\n      const endDate = dateRange.endDate;\n      if (endDate) {\n        endTime = dateRangeDateToTimelineSeconds(endDate, dateTimeOffset);\n        durationKnown = true;\n      } else if (dateRange.endOnNext && !durationKnown) {\n        const nextDateRangeWithSameClass = ids.reduce(\n          (candidateDateRange: DateRange | null, id) => {\n            if (id !== dateRange.id) {\n              const otherDateRange = dateRanges[id];\n              if (\n                otherDateRange.class === dateRange.class &&\n                otherDateRange.startDate > dateRange.startDate &&\n                (!candidateDateRange ||\n                  dateRange.startDate < candidateDateRange.startDate)\n              ) {\n                return otherDateRange;\n              }\n            }\n            return candidateDateRange;\n          },\n          null,\n        );\n        if (nextDateRangeWithSameClass) {\n          endTime = dateRangeDateToTimelineSeconds(\n            nextDateRangeWithSameClass.startDate,\n            dateTimeOffset,\n          );\n          durationKnown = true;\n        }\n      }\n\n      // Create TextTrack Cues for each MetadataGroup Item (select DateRange attribute)\n      // This is to emulate Safari HLS playback handling of DateRange tags\n      const attributes = Object.keys(dateRange.attr);\n      for (let j = 0; j < attributes.length; j++) {\n        const key = attributes[j];\n        if (!isDateRangeCueAttribute(key)) {\n          continue;\n        }\n        const cue = cues[key];\n        if (cue) {\n          if (durationKnown && !appendedDateRangeCues.durationKnown) {\n            cue.endTime = endTime;\n          }\n        } else if (Cue) {\n          let data = dateRange.attr[key];\n          if (isSCTE35Attribute(key)) {\n            data = hexToArrayBuffer(data);\n          }\n          const cue = createCueWithDataFields(\n            Cue,\n            startTime,\n            endTime,\n            { key, data },\n            MetadataSchema.dateRange,\n          );\n          if (cue) {\n            cue.id = id;\n            this.id3Track.addCue(cue);\n            cues[key] = cue;\n          }\n        }\n      }\n\n      // Keep track of processed DateRanges by ID for updating cues with new DateRange tag attributes\n      dateRangeCuesAppended[id] = {\n        cues,\n        dateRange,\n        durationKnown,\n      };\n    }\n  }\n}\n\nexport default ID3TrackController;\n","import { LevelDetails } from '../loader/level-details';\nimport { ErrorDetails } from '../errors';\nimport { Events } from '../events';\nimport type {\n  ErrorData,\n  LevelUpdatedData,\n  MediaAttachingData,\n} from '../types/events';\nimport { logger } from '../utils/logger';\nimport type { ComponentAPI } from '../types/component-api';\nimport type Hls from '../hls';\nimport type { HlsConfig } from '../config';\n\nexport default class LatencyController implements ComponentAPI {\n  private hls: Hls;\n  private readonly config: HlsConfig;\n  private media: HTMLMediaElement | null = null;\n  private levelDetails: LevelDetails | null = null;\n  private currentTime: number = 0;\n  private stallCount: number = 0;\n  private _latency: number | null = null;\n  private timeupdateHandler = () => this.timeupdate();\n\n  constructor(hls: Hls) {\n    this.hls = hls;\n    this.config = hls.config;\n    this.registerListeners();\n  }\n\n  get latency(): number {\n    return this._latency || 0;\n  }\n\n  get maxLatency(): number {\n    const { config, levelDetails } = this;\n    if (config.liveMaxLatencyDuration !== undefined) {\n      return config.liveMaxLatencyDuration;\n    }\n    return levelDetails\n      ? config.liveMaxLatencyDurationCount * levelDetails.targetduration\n      : 0;\n  }\n\n  get targetLatency(): number | null {\n    const { levelDetails } = this;\n    if (levelDetails === null) {\n      return null;\n    }\n    const { holdBack, partHoldBack, targetduration } = levelDetails;\n    const { liveSyncDuration, liveSyncDurationCount, lowLatencyMode } =\n      this.config;\n    const userConfig = this.hls.userConfig;\n    let targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;\n    if (\n      userConfig.liveSyncDuration ||\n      userConfig.liveSyncDurationCount ||\n      targetLatency === 0\n    ) {\n      targetLatency =\n        liveSyncDuration !== undefined\n          ? liveSyncDuration\n          : liveSyncDurationCount * targetduration;\n    }\n    const maxLiveSyncOnStallIncrease = targetduration;\n    const liveSyncOnStallIncrease = 1.0;\n    return (\n      targetLatency +\n      Math.min(\n        this.stallCount * liveSyncOnStallIncrease,\n        maxLiveSyncOnStallIncrease,\n      )\n    );\n  }\n\n  get liveSyncPosition(): number | null {\n    const liveEdge = this.estimateLiveEdge();\n    const targetLatency = this.targetLatency;\n    const levelDetails = this.levelDetails;\n    if (liveEdge === null || targetLatency === null || levelDetails === null) {\n      return null;\n    }\n    const edge = levelDetails.edge;\n    const syncPosition = liveEdge - targetLatency - this.edgeStalled;\n    const min = edge - levelDetails.totalduration;\n    const max =\n      edge -\n      ((this.config.lowLatencyMode && levelDetails.partTarget) ||\n        levelDetails.targetduration);\n    return Math.min(Math.max(min, syncPosition), max);\n  }\n\n  get drift(): number {\n    const { levelDetails } = this;\n    if (levelDetails === null) {\n      return 1;\n    }\n    return levelDetails.drift;\n  }\n\n  get edgeStalled(): number {\n    const { levelDetails } = this;\n    if (levelDetails === null) {\n      return 0;\n    }\n    const maxLevelUpdateAge =\n      ((this.config.lowLatencyMode && levelDetails.partTarget) ||\n        levelDetails.targetduration) * 3;\n    return Math.max(levelDetails.age - maxLevelUpdateAge, 0);\n  }\n\n  private get forwardBufferLength(): number {\n    const { media, levelDetails } = this;\n    if (!media || !levelDetails) {\n      return 0;\n    }\n    const bufferedRanges = media.buffered.length;\n    return (\n      (bufferedRanges\n        ? media.buffered.end(bufferedRanges - 1)\n        : levelDetails.edge) - this.currentTime\n    );\n  }\n\n  public destroy(): void {\n    this.unregisterListeners();\n    this.onMediaDetaching();\n    this.levelDetails = null;\n    // @ts-ignore\n    this.hls = this.timeupdateHandler = null;\n  }\n\n  private registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    this.hls.on(Events.ERROR, this.onError, this);\n  }\n\n  private unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    this.hls.off(Events.ERROR, this.onError, this);\n  }\n\n  private onMediaAttached(\n    event: Events.MEDIA_ATTACHED,\n    data: MediaAttachingData,\n  ) {\n    this.media = data.media;\n    this.media.addEventListener('timeupdate', this.timeupdateHandler);\n  }\n\n  private onMediaDetaching() {\n    if (this.media) {\n      this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n      this.media = null;\n    }\n  }\n\n  private onManifestLoading() {\n    this.levelDetails = null;\n    this._latency = null;\n    this.stallCount = 0;\n  }\n\n  private onLevelUpdated(\n    event: Events.LEVEL_UPDATED,\n    { details }: LevelUpdatedData,\n  ) {\n    this.levelDetails = details;\n    if (details.advanced) {\n      this.timeupdate();\n    }\n    if (!details.live && this.media) {\n      this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n    }\n  }\n\n  private onError(event: Events.ERROR, data: ErrorData) {\n    if (data.details !== ErrorDetails.BUFFER_STALLED_ERROR) {\n      return;\n    }\n    this.stallCount++;\n    if (this.levelDetails?.live) {\n      logger.warn(\n        '[playback-rate-controller]: Stall detected, adjusting target latency',\n      );\n    }\n  }\n\n  private timeupdate() {\n    const { media, levelDetails } = this;\n    if (!media || !levelDetails) {\n      return;\n    }\n    this.currentTime = media.currentTime;\n\n    const latency = this.computeLatency();\n    if (latency === null) {\n      return;\n    }\n    this._latency = latency;\n\n    // Adapt playbackRate to meet target latency in low-latency mode\n    const { lowLatencyMode, maxLiveSyncPlaybackRate } = this.config;\n    if (\n      !lowLatencyMode ||\n      maxLiveSyncPlaybackRate === 1 ||\n      !levelDetails.live\n    ) {\n      return;\n    }\n    const targetLatency = this.targetLatency;\n    if (targetLatency === null) {\n      return;\n    }\n    const distanceFromTarget = latency - targetLatency;\n    // Only adjust playbackRate when within one target duration of targetLatency\n    // and more than one second from under-buffering.\n    // Playback further than one target duration from target can be considered DVR playback.\n    const liveMinLatencyDuration = Math.min(\n      this.maxLatency,\n      targetLatency + levelDetails.targetduration,\n    );\n    const inLiveRange = distanceFromTarget < liveMinLatencyDuration;\n\n    if (\n      inLiveRange &&\n      distanceFromTarget > 0.05 &&\n      this.forwardBufferLength > 1\n    ) {\n      const max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));\n      const rate =\n        Math.round(\n          (2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled))) *\n            20,\n        ) / 20;\n      media.playbackRate = Math.min(max, Math.max(1, rate));\n    } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {\n      media.playbackRate = 1;\n    }\n  }\n\n  private estimateLiveEdge(): number | null {\n    const { levelDetails } = this;\n    if (levelDetails === null) {\n      return null;\n    }\n    return levelDetails.edge + levelDetails.age;\n  }\n\n  private computeLatency(): number | null {\n    const liveEdge = this.estimateLiveEdge();\n    if (liveEdge === null) {\n      return null;\n    }\n    return liveEdge - this.currentTime;\n  }\n}\n","import type { MediaPlaylist } from './media-playlist';\nimport type { LevelDetails } from '../loader/level-details';\nimport type { AttrList } from '../utils/attr-list';\nimport type { MediaDecodingInfo } from '../utils/mediacapabilities-helper';\n\nexport interface LevelParsed {\n  attrs: LevelAttributes;\n  audioCodec?: string;\n  bitrate: number;\n  details?: LevelDetails;\n  height?: number;\n  id?: number;\n  name: string;\n  textCodec?: string;\n  unknownCodecs?: string[];\n  url: string;\n  videoCodec?: string;\n  width?: number;\n}\n\nexport interface LevelAttributes extends AttrList {\n  'ALLOWED-CPC'?: string;\n  AUDIO?: string;\n  'AVERAGE-BANDWIDTH'?: string;\n  BANDWIDTH?: string;\n  'CLOSED-CAPTIONS'?: string;\n  CODECS?: string;\n  'FRAME-RATE'?: string;\n  'HDCP-LEVEL'?: 'TYPE-0' | 'TYPE-1' | 'NONE';\n  'PATHWAY-ID'?: string;\n  RESOLUTION?: string;\n  SCORE?: string;\n  'STABLE-VARIANT-ID'?: string;\n  SUBTITLES?: string;\n  'SUPPLEMENTAL-CODECS'?: string;\n  VIDEO?: string;\n  'VIDEO-RANGE'?: VideoRange;\n}\n\nexport const HdcpLevels = ['NONE', 'TYPE-0', 'TYPE-1', null] as const;\nexport type HdcpLevel = (typeof HdcpLevels)[number];\n\nexport function isHdcpLevel(value: any): value is HdcpLevel {\n  return HdcpLevels.indexOf(value) > -1;\n}\n\nexport const VideoRangeValues = ['SDR', 'PQ', 'HLG'] as const;\nexport type VideoRange = (typeof VideoRangeValues)[number];\n\nexport function isVideoRange(value: any): value is VideoRange {\n  return !!value && VideoRangeValues.indexOf(value) > -1;\n}\n\nexport type VariableMap = Record<string, string>;\n\nexport const enum HlsSkip {\n  No = '',\n  Yes = 'YES',\n  v2 = 'v2',\n}\n\nexport function getSkipValue(details: LevelDetails): HlsSkip {\n  const { canSkipUntil, canSkipDateRanges, age } = details;\n  // A Client SHOULD NOT request a Playlist Delta Update unless it already\n  // has a version of the Playlist that is no older than one-half of the Skip Boundary.\n  // @see: https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis#section-6.3.7\n  const playlistRecentEnough = age < canSkipUntil / 2;\n  if (canSkipUntil && playlistRecentEnough) {\n    if (canSkipDateRanges) {\n      return HlsSkip.v2;\n    }\n    return HlsSkip.Yes;\n  }\n  return HlsSkip.No;\n}\n\nexport class HlsUrlParameters {\n  msn?: number;\n  part?: number;\n  skip?: HlsSkip;\n\n  constructor(msn?: number, part?: number, skip?: HlsSkip) {\n    this.msn = msn;\n    this.part = part;\n    this.skip = skip;\n  }\n\n  addDirectives(uri: string): string | never {\n    const url: URL = new self.URL(uri);\n    if (this.msn !== undefined) {\n      url.searchParams.set('_HLS_msn', this.msn.toString());\n    }\n    if (this.part !== undefined) {\n      url.searchParams.set('_HLS_part', this.part.toString());\n    }\n    if (this.skip) {\n      url.searchParams.set('_HLS_skip', this.skip);\n    }\n    return url.href;\n  }\n}\n\nexport class Level {\n  public readonly _attrs: LevelAttributes[];\n  public readonly audioCodec: string | undefined;\n  public readonly bitrate: number;\n  public readonly codecSet: string;\n  public readonly url: string[];\n  public readonly frameRate: number;\n  public readonly height: number;\n  public readonly id: number;\n  public readonly name: string;\n  public readonly videoCodec: string | undefined;\n  public readonly width: number;\n  public details?: LevelDetails;\n  public fragmentError: number = 0;\n  public loadError: number = 0;\n  public loaded?: { bytes: number; duration: number };\n  public realBitrate: number = 0;\n  public supportedPromise?: Promise<MediaDecodingInfo>;\n  public supportedResult?: MediaDecodingInfo;\n  private _avgBitrate: number = 0;\n  private _audioGroups?: (string | undefined)[];\n  private _subtitleGroups?: (string | undefined)[];\n  // Deprecated (retained for backwards compatibility)\n  private readonly _urlId: number = 0;\n\n  constructor(data: LevelParsed | MediaPlaylist) {\n    this.url = [data.url];\n    this._attrs = [data.attrs];\n    this.bitrate = data.bitrate;\n    if (data.details) {\n      this.details = data.details;\n    }\n    this.id = data.id || 0;\n    this.name = data.name;\n    this.width = data.width || 0;\n    this.height = data.height || 0;\n    this.frameRate = data.attrs.optionalFloat('FRAME-RATE', 0);\n    this._avgBitrate = data.attrs.decimalInteger('AVERAGE-BANDWIDTH');\n    this.audioCodec = data.audioCodec;\n    this.videoCodec = data.videoCodec;\n    this.codecSet = [data.videoCodec, data.audioCodec]\n      .filter((c) => !!c)\n      .map((s: string) => s.substring(0, 4))\n      .join(',');\n    this.addGroupId('audio', data.attrs.AUDIO);\n    this.addGroupId('text', data.attrs.SUBTITLES);\n  }\n\n  get maxBitrate(): number {\n    return Math.max(this.realBitrate, this.bitrate);\n  }\n\n  get averageBitrate(): number {\n    return this._avgBitrate || this.realBitrate || this.bitrate;\n  }\n\n  get attrs(): LevelAttributes {\n    return this._attrs[0];\n  }\n\n  get codecs(): string {\n    return this.attrs.CODECS || '';\n  }\n\n  get pathwayId(): string {\n    return this.attrs['PATHWAY-ID'] || '.';\n  }\n\n  get videoRange(): VideoRange {\n    return this.attrs['VIDEO-RANGE'] || 'SDR';\n  }\n\n  get score(): number {\n    return this.attrs.optionalFloat('SCORE', 0);\n  }\n\n  get uri(): string {\n    return this.url[0] || '';\n  }\n\n  hasAudioGroup(groupId: string | undefined): boolean {\n    return hasGroup(this._audioGroups, groupId);\n  }\n\n  hasSubtitleGroup(groupId: string | undefined): boolean {\n    return hasGroup(this._subtitleGroups, groupId);\n  }\n\n  get audioGroups(): (string | undefined)[] | undefined {\n    return this._audioGroups;\n  }\n\n  get subtitleGroups(): (string | undefined)[] | undefined {\n    return this._subtitleGroups;\n  }\n\n  addGroupId(type: string, groupId: string | undefined) {\n    if (!groupId) {\n      return;\n    }\n    if (type === 'audio') {\n      let audioGroups = this._audioGroups;\n      if (!audioGroups) {\n        audioGroups = this._audioGroups = [];\n      }\n      if (audioGroups.indexOf(groupId) === -1) {\n        audioGroups.push(groupId);\n      }\n    } else if (type === 'text') {\n      let subtitleGroups = this._subtitleGroups;\n      if (!subtitleGroups) {\n        subtitleGroups = this._subtitleGroups = [];\n      }\n      if (subtitleGroups.indexOf(groupId) === -1) {\n        subtitleGroups.push(groupId);\n      }\n    }\n  }\n\n  // Deprecated methods (retained for backwards compatibility)\n  get urlId(): number {\n    return 0;\n  }\n\n  set urlId(value: number) {}\n\n  get audioGroupIds(): (string | undefined)[] | undefined {\n    return this.audioGroups ? [this.audioGroupId] : undefined;\n  }\n\n  get textGroupIds(): (string | undefined)[] | undefined {\n    return this.subtitleGroups ? [this.textGroupId] : undefined;\n  }\n\n  get audioGroupId(): string | undefined {\n    return this.audioGroups?.[0];\n  }\n\n  get textGroupId(): string | undefined {\n    return this.subtitleGroups?.[0];\n  }\n\n  addFallback() {}\n}\n\nfunction hasGroup(\n  groups: (string | undefined)[] | undefined,\n  groupId: string | undefined,\n): boolean {\n  if (!groupId || !groups) {\n    return false;\n  }\n  return groups.indexOf(groupId) !== -1;\n}\n","/**\n * Provides methods dealing with playlist sliding and drift\n */\n\nimport { logger } from './logger';\nimport { Fragment, Part } from '../loader/fragment';\nimport { LevelDetails } from '../loader/level-details';\nimport type { Level } from '../types/level';\nimport { DateRange } from '../loader/date-range';\n\ntype FragmentIntersection = (\n  oldFrag: Fragment,\n  newFrag: Fragment,\n  newFragIndex: number,\n  newFragments: Fragment[],\n) => void;\ntype PartIntersection = (oldPart: Part, newPart: Part) => void;\n\nexport function updatePTS(\n  fragments: Fragment[],\n  fromIdx: number,\n  toIdx: number,\n): void {\n  const fragFrom = fragments[fromIdx];\n  const fragTo = fragments[toIdx];\n  updateFromToPTS(fragFrom, fragTo);\n}\n\nfunction updateFromToPTS(fragFrom: Fragment, fragTo: Fragment) {\n  const fragToPTS = fragTo.startPTS as number;\n  // if we know startPTS[toIdx]\n  if (Number.isFinite(fragToPTS)) {\n    // update fragment duration.\n    // it helps to fix drifts between playlist reported duration and fragment real duration\n    let duration: number = 0;\n    let frag: Fragment;\n    if (fragTo.sn > fragFrom.sn) {\n      duration = fragToPTS - fragFrom.start;\n      frag = fragFrom;\n    } else {\n      duration = fragFrom.start - fragToPTS;\n      frag = fragTo;\n    }\n    if (frag.duration !== duration) {\n      frag.duration = duration;\n    }\n    // we dont know startPTS[toIdx]\n  } else if (fragTo.sn > fragFrom.sn) {\n    const contiguous = fragFrom.cc === fragTo.cc;\n    // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS\n    if (contiguous && fragFrom.minEndPTS) {\n      fragTo.start = fragFrom.start + (fragFrom.minEndPTS - fragFrom.start);\n    } else {\n      fragTo.start = fragFrom.start + fragFrom.duration;\n    }\n  } else {\n    fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);\n  }\n}\n\nexport function updateFragPTSDTS(\n  details: LevelDetails | undefined,\n  frag: Fragment,\n  startPTS: number,\n  endPTS: number,\n  startDTS: number,\n  endDTS: number,\n): number {\n  const parsedMediaDuration = endPTS - startPTS;\n  if (parsedMediaDuration <= 0) {\n    logger.warn('Fragment should have a positive duration', frag);\n    endPTS = startPTS + frag.duration;\n    endDTS = startDTS + frag.duration;\n  }\n  let maxStartPTS = startPTS;\n  let minEndPTS = endPTS;\n  const fragStartPts = frag.startPTS as number;\n  const fragEndPts = frag.endPTS as number;\n  if (Number.isFinite(fragStartPts)) {\n    // delta PTS between audio and video\n    const deltaPTS = Math.abs(fragStartPts - startPTS);\n    if (!Number.isFinite(frag.deltaPTS as number)) {\n      frag.deltaPTS = deltaPTS;\n    } else {\n      frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS as number);\n    }\n\n    maxStartPTS = Math.max(startPTS, fragStartPts);\n    startPTS = Math.min(startPTS, fragStartPts);\n    startDTS = Math.min(startDTS, frag.startDTS);\n\n    minEndPTS = Math.min(endPTS, fragEndPts);\n    endPTS = Math.max(endPTS, fragEndPts);\n    endDTS = Math.max(endDTS, frag.endDTS);\n  }\n\n  const drift = startPTS - frag.start;\n  if (frag.start !== 0) {\n    frag.start = startPTS;\n  }\n  frag.duration = endPTS - frag.start;\n  frag.startPTS = startPTS;\n  frag.maxStartPTS = maxStartPTS;\n  frag.startDTS = startDTS;\n  frag.endPTS = endPTS;\n  frag.minEndPTS = minEndPTS;\n  frag.endDTS = endDTS;\n\n  const sn = frag.sn as number; // 'initSegment'\n  // exit if sn out of range\n  if (!details || sn < details.startSN || sn > details.endSN) {\n    return 0;\n  }\n  let i: number;\n  const fragIdx = sn - details.startSN;\n  const fragments = details.fragments;\n  // update frag reference in fragments array\n  // rationale is that fragments array might not contain this frag object.\n  // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\n  // if we don't update frag, we won't be able to propagate PTS info on the playlist\n  // resulting in invalid sliding computation\n  fragments[fragIdx] = frag;\n  // adjust fragment PTS/duration from seqnum-1 to frag 0\n  for (i = fragIdx; i > 0; i--) {\n    updateFromToPTS(fragments[i], fragments[i - 1]);\n  }\n\n  // adjust fragment PTS/duration from seqnum to last frag\n  for (i = fragIdx; i < fragments.length - 1; i++) {\n    updateFromToPTS(fragments[i], fragments[i + 1]);\n  }\n  if (details.fragmentHint) {\n    updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);\n  }\n\n  details.PTSKnown = details.alignedSliding = true;\n  return drift;\n}\n\nexport function mergeDetails(\n  oldDetails: LevelDetails,\n  newDetails: LevelDetails,\n): void {\n  // Track the last initSegment processed. Initialize it to the last one on the timeline.\n  let currentInitSegment: Fragment | null = null;\n  const oldFragments = oldDetails.fragments;\n  for (let i = oldFragments.length - 1; i >= 0; i--) {\n    const oldInit = oldFragments[i].initSegment;\n    if (oldInit) {\n      currentInitSegment = oldInit;\n      break;\n    }\n  }\n\n  if (oldDetails.fragmentHint) {\n    // prevent PTS and duration from being adjusted on the next hint\n    delete oldDetails.fragmentHint.endPTS;\n  }\n  // check if old/new playlists have fragments in common\n  // loop through overlapping SN and update startPTS, cc, and duration if any found\n  let PTSFrag: Fragment | undefined;\n  mapFragmentIntersection(\n    oldDetails,\n    newDetails,\n    (oldFrag, newFrag, newFragIndex, newFragments) => {\n      if (newDetails.skippedSegments) {\n        if (newFrag.cc !== oldFrag.cc) {\n          const ccOffset = oldFrag.cc - newFrag.cc;\n          for (let i = newFragIndex; i < newFragments.length; i++) {\n            newFragments[i].cc += ccOffset;\n          }\n        }\n      }\n      if (\n        Number.isFinite(oldFrag.startPTS) &&\n        Number.isFinite(oldFrag.endPTS)\n      ) {\n        newFrag.start = newFrag.startPTS = oldFrag.startPTS as number;\n        newFrag.startDTS = oldFrag.startDTS;\n        newFrag.maxStartPTS = oldFrag.maxStartPTS;\n\n        newFrag.endPTS = oldFrag.endPTS;\n        newFrag.endDTS = oldFrag.endDTS;\n        newFrag.minEndPTS = oldFrag.minEndPTS;\n        newFrag.duration =\n          (oldFrag.endPTS as number) - (oldFrag.startPTS as number);\n\n        if (newFrag.duration) {\n          PTSFrag = newFrag;\n        }\n\n        // PTS is known when any segment has startPTS and endPTS\n        newDetails.PTSKnown = newDetails.alignedSliding = true;\n      }\n      newFrag.elementaryStreams = oldFrag.elementaryStreams;\n      newFrag.loader = oldFrag.loader;\n      newFrag.stats = oldFrag.stats;\n      if (oldFrag.initSegment) {\n        newFrag.initSegment = oldFrag.initSegment;\n        currentInitSegment = oldFrag.initSegment;\n      }\n    },\n  );\n\n  const newFragments = newDetails.fragments;\n  if (currentInitSegment) {\n    const fragmentsToCheck = newDetails.fragmentHint\n      ? newFragments.concat(newDetails.fragmentHint)\n      : newFragments;\n    fragmentsToCheck.forEach((frag) => {\n      if (\n        frag &&\n        (!frag.initSegment ||\n          frag.initSegment.relurl === currentInitSegment?.relurl)\n      ) {\n        frag.initSegment = currentInitSegment;\n      }\n    });\n  }\n\n  if (newDetails.skippedSegments) {\n    newDetails.deltaUpdateFailed = newFragments.some((frag) => !frag);\n    if (newDetails.deltaUpdateFailed) {\n      logger.warn(\n        '[level-helper] Previous playlist missing segments skipped in delta playlist',\n      );\n      for (let i = newDetails.skippedSegments; i--; ) {\n        newFragments.shift();\n      }\n      newDetails.startSN = newFragments[0].sn as number;\n    } else {\n      if (newDetails.canSkipDateRanges) {\n        newDetails.dateRanges = mergeDateRanges(\n          oldDetails.dateRanges,\n          newDetails.dateRanges,\n          newDetails.recentlyRemovedDateranges,\n        );\n      }\n    }\n    newDetails.startCC = newDetails.fragments[0].cc;\n    newDetails.endCC = newFragments[newFragments.length - 1].cc;\n  }\n\n  // Merge parts\n  mapPartIntersection(\n    oldDetails.partList,\n    newDetails.partList,\n    (oldPart: Part, newPart: Part) => {\n      newPart.elementaryStreams = oldPart.elementaryStreams;\n      newPart.stats = oldPart.stats;\n    },\n  );\n\n  // if at least one fragment contains PTS info, recompute PTS information for all fragments\n  if (PTSFrag) {\n    updateFragPTSDTS(\n      newDetails,\n      PTSFrag,\n      PTSFrag.startPTS as number,\n      PTSFrag.endPTS as number,\n      PTSFrag.startDTS as number,\n      PTSFrag.endDTS as number,\n    );\n  } else {\n    // ensure that delta is within oldFragments range\n    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\n    // in that case we also need to adjust start offset of all fragments\n    adjustSliding(oldDetails, newDetails);\n  }\n\n  if (newFragments.length) {\n    newDetails.totalduration = newDetails.edge - newFragments[0].start;\n  }\n\n  newDetails.driftStartTime = oldDetails.driftStartTime;\n  newDetails.driftStart = oldDetails.driftStart;\n  const advancedDateTime = newDetails.advancedDateTime;\n  if (newDetails.advanced && advancedDateTime) {\n    const edge = newDetails.edge;\n    if (!newDetails.driftStart) {\n      newDetails.driftStartTime = advancedDateTime;\n      newDetails.driftStart = edge;\n    }\n    newDetails.driftEndTime = advancedDateTime;\n    newDetails.driftEnd = edge;\n  } else {\n    newDetails.driftEndTime = oldDetails.driftEndTime;\n    newDetails.driftEnd = oldDetails.driftEnd;\n    newDetails.advancedDateTime = oldDetails.advancedDateTime;\n  }\n}\n\nfunction mergeDateRanges(\n  oldDateRanges: Record<string, DateRange>,\n  deltaDateRanges: Record<string, DateRange>,\n  recentlyRemovedDateranges: string[] | undefined,\n): Record<string, DateRange> {\n  const dateRanges = Object.assign({}, oldDateRanges);\n  if (recentlyRemovedDateranges) {\n    recentlyRemovedDateranges.forEach((id) => {\n      delete dateRanges[id];\n    });\n  }\n  Object.keys(deltaDateRanges).forEach((id) => {\n    const dateRange = new DateRange(deltaDateRanges[id].attr, dateRanges[id]);\n    if (dateRange.isValid) {\n      dateRanges[id] = dateRange;\n    } else {\n      logger.warn(\n        `Ignoring invalid Playlist Delta Update DATERANGE tag: \"${JSON.stringify(\n          deltaDateRanges[id].attr,\n        )}\"`,\n      );\n    }\n  });\n  return dateRanges;\n}\n\nexport function mapPartIntersection(\n  oldParts: Part[] | null,\n  newParts: Part[] | null,\n  intersectionFn: PartIntersection,\n) {\n  if (oldParts && newParts) {\n    let delta = 0;\n    for (let i = 0, len = oldParts.length; i <= len; i++) {\n      const oldPart = oldParts[i];\n      const newPart = newParts[i + delta];\n      if (\n        oldPart &&\n        newPart &&\n        oldPart.index === newPart.index &&\n        oldPart.fragment.sn === newPart.fragment.sn\n      ) {\n        intersectionFn(oldPart, newPart);\n      } else {\n        delta--;\n      }\n    }\n  }\n}\n\nexport function mapFragmentIntersection(\n  oldDetails: LevelDetails,\n  newDetails: LevelDetails,\n  intersectionFn: FragmentIntersection,\n): void {\n  const skippedSegments = newDetails.skippedSegments;\n  const start =\n    Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;\n  const end =\n    (oldDetails.fragmentHint ? 1 : 0) +\n    (skippedSegments\n      ? newDetails.endSN\n      : Math.min(oldDetails.endSN, newDetails.endSN)) -\n    newDetails.startSN;\n  const delta = newDetails.startSN - oldDetails.startSN;\n  const newFrags = newDetails.fragmentHint\n    ? newDetails.fragments.concat(newDetails.fragmentHint)\n    : newDetails.fragments;\n  const oldFrags = oldDetails.fragmentHint\n    ? oldDetails.fragments.concat(oldDetails.fragmentHint)\n    : oldDetails.fragments;\n\n  for (let i = start; i <= end; i++) {\n    const oldFrag = oldFrags[delta + i];\n    let newFrag = newFrags[i];\n    if (skippedSegments && !newFrag && i < skippedSegments) {\n      // Fill in skipped segments in delta playlist\n      newFrag = newDetails.fragments[i] = oldFrag;\n    }\n    if (oldFrag && newFrag) {\n      intersectionFn(oldFrag, newFrag, i, newFrags);\n    }\n  }\n}\n\nexport function adjustSliding(\n  oldDetails: LevelDetails,\n  newDetails: LevelDetails,\n): void {\n  const delta =\n    newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;\n  const oldFragments = oldDetails.fragments;\n  if (delta < 0 || delta >= oldFragments.length) {\n    return;\n  }\n  addSliding(newDetails, oldFragments[delta].start);\n}\n\nexport function addSliding(details: LevelDetails, start: number) {\n  if (start) {\n    const fragments = details.fragments;\n    for (let i = details.skippedSegments; i < fragments.length; i++) {\n      fragments[i].start += start;\n    }\n    if (details.fragmentHint) {\n      details.fragmentHint.start += start;\n    }\n  }\n}\n\nexport function computeReloadInterval(\n  newDetails: LevelDetails,\n  distanceToLiveEdgeMs: number = Infinity,\n): number {\n  let reloadInterval = 1000 * newDetails.targetduration;\n\n  if (newDetails.updated) {\n    // Use last segment duration when shorter than target duration and near live edge\n    const fragments = newDetails.fragments;\n    const liveEdgeMaxTargetDurations = 4;\n    if (\n      fragments.length &&\n      reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs\n    ) {\n      const lastSegmentDuration =\n        fragments[fragments.length - 1].duration * 1000;\n      if (lastSegmentDuration < reloadInterval) {\n        reloadInterval = lastSegmentDuration;\n      }\n    }\n  } else {\n    // estimate = 'miss half average';\n    // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\n    // changed then it MUST wait for a period of one-half the target\n    // duration before retrying.\n    reloadInterval /= 2;\n  }\n\n  return Math.round(reloadInterval);\n}\n\nexport function getFragmentWithSN(\n  level: Level,\n  sn: number,\n  fragCurrent: Fragment | null,\n): Fragment | null {\n  if (!level?.details) {\n    return null;\n  }\n  const levelDetails = level.details;\n  let fragment: Fragment | undefined =\n    levelDetails.fragments[sn - levelDetails.startSN];\n  if (fragment) {\n    return fragment;\n  }\n  fragment = levelDetails.fragmentHint;\n  if (fragment && fragment.sn === sn) {\n    return fragment;\n  }\n  if (sn < levelDetails.startSN && fragCurrent && fragCurrent.sn === sn) {\n    return fragCurrent;\n  }\n  return null;\n}\n\nexport function getPartWith(\n  level: Level,\n  sn: number,\n  partIndex: number,\n): Part | null {\n  if (!level?.details) {\n    return null;\n  }\n  return findPart(level.details?.partList, sn, partIndex);\n}\n\nexport function findPart(\n  partList: Part[] | null | undefined,\n  sn: number,\n  partIndex: number,\n): Part | null {\n  if (partList) {\n    for (let i = partList.length; i--; ) {\n      const part = partList[i];\n      if (part.index === partIndex && part.fragment.sn === sn) {\n        return part;\n      }\n    }\n  }\n  return null;\n}\n\nexport function reassignFragmentLevelIndexes(levels: Level[]) {\n  levels.forEach((level, index) => {\n    const { details } = level;\n    if (details?.fragments) {\n      details.fragments.forEach((fragment) => {\n        fragment.level = index;\n      });\n    }\n  });\n}\n","import { ErrorDetails } from '../errors';\nimport type { LoadPolicy, LoaderConfig, RetryConfig } from '../config';\nimport type { ErrorData } from '../types/events';\nimport type { LoaderResponse } from '../types/loader';\n\nexport function isTimeoutError(error: ErrorData): boolean {\n  switch (error.details) {\n    case ErrorDetails.FRAG_LOAD_TIMEOUT:\n    case ErrorDetails.KEY_LOAD_TIMEOUT:\n    case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n    case ErrorDetails.MANIFEST_LOAD_TIMEOUT:\n      return true;\n  }\n  return false;\n}\n\nexport function getRetryConfig(\n  loadPolicy: LoadPolicy,\n  error: ErrorData,\n): RetryConfig | null {\n  const isTimeout = isTimeoutError(error);\n  return loadPolicy.default[`${isTimeout ? 'timeout' : 'error'}Retry`];\n}\n\nexport function getRetryDelay(\n  retryConfig: RetryConfig,\n  retryCount: number,\n): number {\n  // exponential backoff capped to max retry delay\n  const backoffFactor =\n    retryConfig.backoff === 'linear' ? 1 : Math.pow(2, retryCount);\n  return Math.min(\n    backoffFactor * retryConfig.retryDelayMs,\n    retryConfig.maxRetryDelayMs,\n  );\n}\n\nexport function getLoaderConfigWithoutReties(\n  loderConfig: LoaderConfig,\n): LoaderConfig {\n  return {\n    ...loderConfig,\n    ...{\n      errorRetry: null,\n      timeoutRetry: null,\n    },\n  };\n}\n\nexport function shouldRetry(\n  retryConfig: RetryConfig | null | undefined,\n  retryCount: number,\n  isTimeout: boolean,\n  loaderResponse?: LoaderResponse | undefined,\n): retryConfig is RetryConfig & boolean {\n  if (!retryConfig) {\n    return false;\n  }\n  const httpStatus = loaderResponse?.code;\n  const retry =\n    retryCount < retryConfig.maxNumRetry &&\n    (retryForHttpStatus(httpStatus) || !!isTimeout);\n  return retryConfig.shouldRetry\n    ? retryConfig.shouldRetry(\n        retryConfig,\n        retryCount,\n        isTimeout,\n        loaderResponse,\n        retry,\n      )\n    : retry;\n}\n\nexport function retryForHttpStatus(httpStatus: number | undefined) {\n  // Do not retry on status 4xx, status 0 (CORS error), or undefined (decrypt/gap/parse error)\n  return (\n    (httpStatus === 0 && navigator.onLine === false) ||\n    (!!httpStatus && (httpStatus < 400 || httpStatus > 499))\n  );\n}\n","type BinarySearchComparison<T> = (candidate: T) => -1 | 0 | 1;\n\nconst BinarySearch = {\n  /**\n   * Searches for an item in an array which matches a certain condition.\n   * This requires the condition to only match one item in the array,\n   * and for the array to be ordered.\n   *\n   * @param list The array to search.\n   * @param comparisonFn\n   *      Called and provided a candidate item as the first argument.\n   *      Should return:\n   *          > -1 if the item should be located at a lower index than the provided item.\n   *          > 1 if the item should be located at a higher index than the provided item.\n   *          > 0 if the item is the item you're looking for.\n   *\n   * @returns the object if found, otherwise returns null\n   */\n  search: function <T>(\n    list: T[],\n    comparisonFn: BinarySearchComparison<T>,\n  ): T | null {\n    let minIndex: number = 0;\n    let maxIndex: number = list.length - 1;\n    let currentIndex: number | null = null;\n    let currentElement: T | null = null;\n\n    while (minIndex <= maxIndex) {\n      currentIndex = ((minIndex + maxIndex) / 2) | 0;\n      currentElement = list[currentIndex];\n\n      const comparisonResult = comparisonFn(currentElement);\n      if (comparisonResult > 0) {\n        minIndex = currentIndex + 1;\n      } else if (comparisonResult < 0) {\n        maxIndex = currentIndex - 1;\n      } else {\n        return currentElement;\n      }\n    }\n\n    return null;\n  },\n};\n\nexport default BinarySearch;\n","import BinarySearch from '../utils/binary-search';\nimport { Fragment } from '../loader/fragment';\n\n/**\n * Returns first fragment whose endPdt value exceeds the given PDT, or null.\n * @param fragments - The array of candidate fragments\n * @param PDTValue - The PDT value which must be exceeded\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n */\nexport function findFragmentByPDT(\n  fragments: Array<Fragment>,\n  PDTValue: number | null,\n  maxFragLookUpTolerance: number,\n): Fragment | null {\n  if (\n    PDTValue === null ||\n    !Array.isArray(fragments) ||\n    !fragments.length ||\n    !Number.isFinite(PDTValue)\n  ) {\n    return null;\n  }\n\n  // if less than start\n  const startPDT = fragments[0].programDateTime;\n  if (PDTValue < (startPDT || 0)) {\n    return null;\n  }\n\n  const endPDT = fragments[fragments.length - 1].endProgramDateTime;\n  if (PDTValue >= (endPDT || 0)) {\n    return null;\n  }\n\n  maxFragLookUpTolerance = maxFragLookUpTolerance || 0;\n  for (let seg = 0; seg < fragments.length; ++seg) {\n    const frag = fragments[seg];\n    if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {\n      return frag;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.\n * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus\n * breaking any traps which would cause the same fragment to be continuously selected within a small range.\n * @param fragPrevious - The last frag successfully appended\n * @param fragments - The array of candidate fragments\n * @param bufferEnd - The end of the contiguous buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n * @returns a matching fragment or null\n */\nexport function findFragmentByPTS(\n  fragPrevious: Fragment | null,\n  fragments: Array<Fragment>,\n  bufferEnd: number = 0,\n  maxFragLookUpTolerance: number = 0,\n  nextFragLookupTolerance: number = 0.005,\n): Fragment | null {\n  let fragNext: Fragment | null = null;\n  if (fragPrevious) {\n    fragNext =\n      fragments[\n        (fragPrevious.sn as number) - (fragments[0].sn as number) + 1\n      ] || null;\n    // check for buffer-end rounding error\n    const bufferEdgeError = fragPrevious.endDTS - bufferEnd;\n    if (bufferEdgeError > 0 && bufferEdgeError < 0.0000015) {\n      bufferEnd += 0.0000015;\n    }\n  } else if (bufferEnd === 0 && fragments[0].start === 0) {\n    fragNext = fragments[0];\n  }\n  // Prefer the next fragment if it's within tolerance\n  if (\n    fragNext &&\n    (((!fragPrevious || fragPrevious.level === fragNext.level) &&\n      fragmentWithinToleranceTest(\n        bufferEnd,\n        maxFragLookUpTolerance,\n        fragNext,\n      ) === 0) ||\n      fragmentWithinFastStartSwitch(\n        fragNext,\n        fragPrevious,\n        Math.min(nextFragLookupTolerance, maxFragLookUpTolerance),\n      ))\n  ) {\n    return fragNext;\n  }\n  // We might be seeking past the tolerance so find the best match\n  const foundFragment = BinarySearch.search(\n    fragments,\n    fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance),\n  );\n  if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {\n    return foundFragment;\n  }\n  // If no match was found return the next fragment after fragPrevious, or null\n  return fragNext;\n}\n\nfunction fragmentWithinFastStartSwitch(\n  fragNext: Fragment,\n  fragPrevious: Fragment | null,\n  nextFragLookupTolerance: number,\n): boolean {\n  if (\n    fragPrevious &&\n    fragPrevious.start === 0 &&\n    fragPrevious.level < fragNext.level &&\n    (fragPrevious.endPTS || 0) > 0\n  ) {\n    const firstDuration = fragPrevious.tagList.reduce((duration, tag) => {\n      if (tag[0] === 'INF') {\n        duration += parseFloat(tag[1]);\n      }\n      return duration;\n    }, nextFragLookupTolerance);\n    return fragNext.start <= firstDuration;\n  }\n  return false;\n}\n\n/**\n * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.\n * @param candidate - The fragment to test\n * @param bufferEnd - The end of the current buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns 0 if it matches, 1 if too low, -1 if too high\n */\nexport function fragmentWithinToleranceTest(\n  bufferEnd = 0,\n  maxFragLookUpTolerance = 0,\n  candidate: Fragment,\n) {\n  // eagerly accept an accurate match (no tolerance)\n  if (\n    candidate.start <= bufferEnd &&\n    candidate.start + candidate.duration > bufferEnd\n  ) {\n    return 0;\n  }\n  // offset should be within fragment boundary - config.maxFragLookUpTolerance\n  // this is to cope with situations like\n  // bufferEnd = 9.991\n  // frag[Ø] : [0,10]\n  // frag[1] : [10,20]\n  // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n  //              frag start               frag start+duration\n  //                  |-----------------------------|\n  //              <--->                         <--->\n  //  ...--------><-----------------------------><---------....\n  // previous frag         matching fragment         next frag\n  //  return -1             return 0                 return 1\n  // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n  // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n  const candidateLookupTolerance = Math.min(\n    maxFragLookUpTolerance,\n    candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0),\n  );\n  if (\n    candidate.start + candidate.duration - candidateLookupTolerance <=\n    bufferEnd\n  ) {\n    return 1;\n  } else if (\n    candidate.start - candidateLookupTolerance > bufferEnd &&\n    candidate.start\n  ) {\n    // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n    return -1;\n  }\n\n  return 0;\n}\n\n/**\n * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.\n * This function tests the candidate's program date time values, as represented in Unix time\n * @param candidate - The fragment to test\n * @param pdtBufferEnd - The Unix time representing the end of the current buffered range\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns true if contiguous, false otherwise\n */\nexport function pdtWithinToleranceTest(\n  pdtBufferEnd: number,\n  maxFragLookUpTolerance: number,\n  candidate: Fragment,\n): boolean {\n  const candidateLookupTolerance =\n    Math.min(\n      maxFragLookUpTolerance,\n      candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0),\n    ) * 1000;\n\n  // endProgramDateTime can be null, default to zero\n  const endProgramDateTime = candidate.endProgramDateTime || 0;\n  return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;\n}\n\nexport function findFragWithCC(\n  fragments: Fragment[],\n  cc: number,\n): Fragment | null {\n  return BinarySearch.search(fragments, (candidate) => {\n    if (candidate.cc < cc) {\n      return 1;\n    } else if (candidate.cc > cc) {\n      return -1;\n    } else {\n      return 0;\n    }\n  });\n}\n","import { Events } from '../events';\nimport { ErrorDetails, ErrorTypes } from '../errors';\nimport { PlaylistContextType, PlaylistLevelType } from '../types/loader';\nimport {\n  getRetryConfig,\n  isTimeoutError,\n  shouldRetry,\n} from '../utils/error-helper';\nimport { findFragmentByPTS } from './fragment-finders';\nimport { HdcpLevel, HdcpLevels } from '../types/level';\nimport { logger } from '../utils/logger';\nimport type Hls from '../hls';\nimport type { RetryConfig } from '../config';\nimport type { NetworkComponentAPI } from '../types/component-api';\nimport type { ErrorData } from '../types/events';\nimport type { Fragment } from '../loader/fragment';\nimport type { LevelDetails } from '../loader/level-details';\n\nexport const enum NetworkErrorAction {\n  DoNothing = 0,\n  SendEndCallback = 1, // Reserved for future use\n  SendAlternateToPenaltyBox = 2,\n  RemoveAlternatePermanently = 3, // Reserved for future use\n  InsertDiscontinuity = 4, // Reserved for future use\n  RetryRequest = 5,\n}\n\nexport const enum ErrorActionFlags {\n  None = 0,\n  MoveAllAlternatesMatchingHost = 1,\n  MoveAllAlternatesMatchingHDCP = 1 << 1,\n  SwitchToSDR = 1 << 2, // Reserved for future use\n}\n\nexport type IErrorAction = {\n  action: NetworkErrorAction;\n  flags: ErrorActionFlags;\n  retryCount?: number;\n  retryConfig?: RetryConfig;\n  hdcpLevel?: HdcpLevel;\n  nextAutoLevel?: number;\n  resolved?: boolean;\n};\n\ntype PenalizedRendition = {\n  lastErrorPerfMs: number;\n  errors: ErrorData[];\n  details?: LevelDetails;\n};\n\ntype PenalizedRenditions = { [key: number]: PenalizedRendition };\n\nexport default class ErrorController implements NetworkComponentAPI {\n  private readonly hls: Hls;\n  private playlistError: number = 0;\n  private penalizedRenditions: PenalizedRenditions = {};\n  private log: (msg: any) => void;\n  private warn: (msg: any) => void;\n  private error: (msg: any) => void;\n\n  constructor(hls: Hls) {\n    this.hls = hls;\n    this.log = logger.log.bind(logger, `[info]:`);\n    this.warn = logger.warn.bind(logger, `[warning]:`);\n    this.error = logger.error.bind(logger, `[error]:`);\n    this.registerListeners();\n  }\n\n  private registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n\n  private unregisterListeners() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.ERROR, this.onErrorOut, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n\n  destroy() {\n    this.unregisterListeners();\n    // @ts-ignore\n    this.hls = null;\n    this.penalizedRenditions = {};\n  }\n\n  startLoad(startPosition: number): void {}\n\n  stopLoad(): void {\n    this.playlistError = 0;\n  }\n\n  private getVariantLevelIndex(frag: Fragment | undefined): number {\n    return frag?.type === PlaylistLevelType.MAIN\n      ? frag.level\n      : this.hls.loadLevel;\n  }\n\n  private onManifestLoading() {\n    this.playlistError = 0;\n    this.penalizedRenditions = {};\n  }\n\n  private onLevelUpdated() {\n    this.playlistError = 0;\n  }\n\n  private onError(event: Events.ERROR, data: ErrorData) {\n    if (data.fatal) {\n      return;\n    }\n    const hls = this.hls;\n    const context = data.context;\n\n    switch (data.details) {\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        data.errorAction = this.getFragRetryOrSwitchAction(data);\n        return;\n      case ErrorDetails.FRAG_PARSING_ERROR:\n        // ignore empty segment errors marked as gap\n        if (data.frag?.gap) {\n          data.errorAction = {\n            action: NetworkErrorAction.DoNothing,\n            flags: ErrorActionFlags.None,\n          };\n          return;\n        }\n      // falls through\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_DECRYPT_ERROR: {\n        // Switch level if possible, otherwise allow retry count to reach max error retries\n        data.errorAction = this.getFragRetryOrSwitchAction(data);\n        data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n        return;\n      }\n      case ErrorDetails.LEVEL_EMPTY_ERROR:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        {\n          // Only retry when empty and live\n          const levelIndex =\n            data.parent === PlaylistLevelType.MAIN\n              ? (data.level as number)\n              : hls.loadLevel;\n          if (\n            data.details === ErrorDetails.LEVEL_EMPTY_ERROR &&\n            !!data.context?.levelDetails?.live\n          ) {\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(\n              data,\n              levelIndex,\n            );\n          } else {\n            // Escalate to fatal if not retrying or switching\n            data.levelRetry = false;\n            data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n          }\n        }\n        return;\n      case ErrorDetails.LEVEL_LOAD_ERROR:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n        if (typeof context?.level === 'number') {\n          data.errorAction = this.getPlaylistRetryOrSwitchAction(\n            data,\n            context.level,\n          );\n        }\n        return;\n      case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n      case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n      case ErrorDetails.SUBTITLE_LOAD_ERROR:\n      case ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT:\n        if (context) {\n          const level = hls.levels[hls.loadLevel];\n          if (\n            level &&\n            ((context.type === PlaylistContextType.AUDIO_TRACK &&\n              level.hasAudioGroup(context.groupId)) ||\n              (context.type === PlaylistContextType.SUBTITLE_TRACK &&\n                level.hasSubtitleGroup(context.groupId)))\n          ) {\n            // Perform Pathway switch or Redundant failover if possible for fastest recovery\n            // otherwise allow playlist retry count to reach max error retries\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(\n              data,\n              hls.loadLevel,\n            );\n            data.errorAction.action =\n              NetworkErrorAction.SendAlternateToPenaltyBox;\n            data.errorAction.flags =\n              ErrorActionFlags.MoveAllAlternatesMatchingHost;\n            return;\n          }\n        }\n        return;\n      case ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:\n        {\n          const level = hls.levels[hls.loadLevel];\n          const restrictedHdcpLevel = level?.attrs['HDCP-LEVEL'];\n          if (restrictedHdcpLevel) {\n            data.errorAction = {\n              action: NetworkErrorAction.SendAlternateToPenaltyBox,\n              flags: ErrorActionFlags.MoveAllAlternatesMatchingHDCP,\n              hdcpLevel: restrictedHdcpLevel,\n            };\n          } else {\n            this.keySystemError(data);\n          }\n        }\n        return;\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.REMUX_ALLOC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        data.errorAction = this.getLevelSwitchAction(\n          data,\n          data.level ?? hls.loadLevel,\n        );\n        return;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n      case ErrorDetails.BUFFER_APPENDING_ERROR:\n      case ErrorDetails.BUFFER_FULL_ERROR:\n      case ErrorDetails.LEVEL_SWITCH_ERROR:\n      case ErrorDetails.BUFFER_STALLED_ERROR:\n      case ErrorDetails.BUFFER_SEEK_OVER_HOLE:\n      case ErrorDetails.BUFFER_NUDGE_ON_STALL:\n        data.errorAction = {\n          action: NetworkErrorAction.DoNothing,\n          flags: ErrorActionFlags.None,\n        };\n        return;\n    }\n\n    if (data.type === ErrorTypes.KEY_SYSTEM_ERROR) {\n      this.keySystemError(data);\n    }\n  }\n\n  private keySystemError(data: ErrorData) {\n    const levelIndex = this.getVariantLevelIndex(data.frag);\n    // Do not retry level. Escalate to fatal if switching levels fails.\n    data.levelRetry = false;\n    data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n  }\n\n  private getPlaylistRetryOrSwitchAction(\n    data: ErrorData,\n    levelIndex: number | null | undefined,\n  ): IErrorAction {\n    const hls = this.hls;\n    const retryConfig = getRetryConfig(hls.config.playlistLoadPolicy, data);\n    const retryCount = this.playlistError++;\n    const retry = shouldRetry(\n      retryConfig,\n      retryCount,\n      isTimeoutError(data),\n      data.response,\n    );\n    if (retry) {\n      return {\n        action: NetworkErrorAction.RetryRequest,\n        flags: ErrorActionFlags.None,\n        retryConfig,\n        retryCount,\n      };\n    }\n    const errorAction = this.getLevelSwitchAction(data, levelIndex);\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = retryCount;\n    }\n    return errorAction;\n  }\n\n  private getFragRetryOrSwitchAction(data: ErrorData): IErrorAction {\n    const hls = this.hls;\n    // Share fragment error count accross media options (main, audio, subs)\n    // This allows for level based rendition switching when media option assets fail\n    const variantLevelIndex = this.getVariantLevelIndex(data.frag);\n    const level = hls.levels[variantLevelIndex];\n    const { fragLoadPolicy, keyLoadPolicy } = hls.config;\n    const retryConfig = getRetryConfig(\n      data.details.startsWith('key') ? keyLoadPolicy : fragLoadPolicy,\n      data,\n    );\n    const fragmentErrors = hls.levels.reduce(\n      (acc, level) => acc + level.fragmentError,\n      0,\n    );\n    // Switch levels when out of retried or level index out of bounds\n    if (level) {\n      if (data.details !== ErrorDetails.FRAG_GAP) {\n        level.fragmentError++;\n      }\n      const retry = shouldRetry(\n        retryConfig,\n        fragmentErrors,\n        isTimeoutError(data),\n        data.response,\n      );\n      if (retry) {\n        return {\n          action: NetworkErrorAction.RetryRequest,\n          flags: ErrorActionFlags.None,\n          retryConfig,\n          retryCount: fragmentErrors,\n        };\n      }\n    }\n    // Reach max retry count, or Missing level reference\n    // Switch to valid index\n    const errorAction = this.getLevelSwitchAction(data, variantLevelIndex);\n    // Add retry details to allow skipping of FRAG_PARSING_ERROR\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = fragmentErrors;\n    }\n    return errorAction;\n  }\n\n  private getLevelSwitchAction(\n    data: ErrorData,\n    levelIndex: number | null | undefined,\n  ): IErrorAction {\n    const hls = this.hls;\n    if (levelIndex === null || levelIndex === undefined) {\n      levelIndex = hls.loadLevel;\n    }\n    const level = this.hls.levels[levelIndex];\n    if (level) {\n      const errorDetails = data.details;\n      level.loadError++;\n      if (errorDetails === ErrorDetails.BUFFER_APPEND_ERROR) {\n        level.fragmentError++;\n      }\n      // Search for next level to retry\n      let nextLevel = -1;\n      const { levels, loadLevel, minAutoLevel, maxAutoLevel } = hls;\n      if (!hls.autoLevelEnabled) {\n        hls.loadLevel = -1;\n      }\n      const fragErrorType = data.frag?.type;\n      // Find alternate audio codec if available on audio codec error\n      const isAudioCodecError =\n        (fragErrorType === PlaylistLevelType.AUDIO &&\n          errorDetails === ErrorDetails.FRAG_PARSING_ERROR) ||\n        (data.sourceBufferName === 'audio' &&\n          (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR ||\n            errorDetails === ErrorDetails.BUFFER_APPEND_ERROR));\n      const findAudioCodecAlternate =\n        isAudioCodecError &&\n        levels.some(({ audioCodec }) => level.audioCodec !== audioCodec);\n      // Find alternate video codec if available on video codec error\n      const isVideoCodecError =\n        data.sourceBufferName === 'video' &&\n        (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR ||\n          errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n      const findVideoCodecAlternate =\n        isVideoCodecError &&\n        levels.some(\n          ({ codecSet, audioCodec }) =>\n            level.codecSet !== codecSet && level.audioCodec === audioCodec,\n        );\n      const { type: playlistErrorType, groupId: playlistErrorGroupId } =\n        data.context ?? {};\n      for (let i = levels.length; i--; ) {\n        const candidate = (i + loadLevel) % levels.length;\n        if (\n          candidate !== loadLevel &&\n          candidate >= minAutoLevel &&\n          candidate <= maxAutoLevel &&\n          levels[candidate].loadError === 0\n        ) {\n          const levelCandidate = levels[candidate];\n          // Skip level switch if GAP tag is found in next level at same position\n          if (\n            errorDetails === ErrorDetails.FRAG_GAP &&\n            fragErrorType === PlaylistLevelType.MAIN &&\n            data.frag\n          ) {\n            const levelDetails = levels[candidate].details;\n            if (levelDetails) {\n              const fragCandidate = findFragmentByPTS(\n                data.frag,\n                levelDetails.fragments,\n                data.frag.start,\n              );\n              if (fragCandidate?.gap) {\n                continue;\n              }\n            }\n          } else if (\n            (playlistErrorType === PlaylistContextType.AUDIO_TRACK &&\n              levelCandidate.hasAudioGroup(playlistErrorGroupId)) ||\n            (playlistErrorType === PlaylistContextType.SUBTITLE_TRACK &&\n              levelCandidate.hasSubtitleGroup(playlistErrorGroupId))\n          ) {\n            // For audio/subs playlist errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          } else if (\n            (fragErrorType === PlaylistLevelType.AUDIO &&\n              level.audioGroups?.some((groupId) =>\n                levelCandidate.hasAudioGroup(groupId),\n              )) ||\n            (fragErrorType === PlaylistLevelType.SUBTITLE &&\n              level.subtitleGroups?.some((groupId) =>\n                levelCandidate.hasSubtitleGroup(groupId),\n              )) ||\n            (findAudioCodecAlternate &&\n              level.audioCodec === levelCandidate.audioCodec) ||\n            (!findAudioCodecAlternate &&\n              level.audioCodec !== levelCandidate.audioCodec) ||\n            (findVideoCodecAlternate &&\n              level.codecSet === levelCandidate.codecSet)\n          ) {\n            // For video/audio/subs frag errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          }\n          nextLevel = candidate;\n          break;\n        }\n      }\n      if (nextLevel > -1 && hls.loadLevel !== nextLevel) {\n        data.levelRetry = true;\n        this.playlistError = 0;\n        return {\n          action: NetworkErrorAction.SendAlternateToPenaltyBox,\n          flags: ErrorActionFlags.None,\n          nextAutoLevel: nextLevel,\n        };\n      }\n    }\n    // No levels to switch / Manual level selection / Level not found\n    // Resolve with Pathway switch, Redundant fail-over, or stay on lowest Level\n    return {\n      action: NetworkErrorAction.SendAlternateToPenaltyBox,\n      flags: ErrorActionFlags.MoveAllAlternatesMatchingHost,\n    };\n  }\n\n  public onErrorOut(event: Events.ERROR, data: ErrorData) {\n    switch (data.errorAction?.action) {\n      case NetworkErrorAction.DoNothing:\n        break;\n      case NetworkErrorAction.SendAlternateToPenaltyBox:\n        this.sendAlternateToPenaltyBox(data);\n        if (\n          !data.errorAction.resolved &&\n          data.details !== ErrorDetails.FRAG_GAP\n        ) {\n          data.fatal = true;\n        } else if (/MediaSource readyState: ended/.test(data.error.message)) {\n          this.warn(\n            `MediaSource ended after \"${data.sourceBufferName}\" sourceBuffer append error. Attempting to recover from media error.`,\n          );\n          this.hls.recoverMediaError();\n        }\n        break;\n      case NetworkErrorAction.RetryRequest:\n        // handled by stream and playlist/level controllers\n        break;\n    }\n\n    if (data.fatal) {\n      this.hls.stopLoad();\n      return;\n    }\n  }\n\n  private sendAlternateToPenaltyBox(data: ErrorData) {\n    const hls = this.hls;\n    const errorAction = data.errorAction;\n    if (!errorAction) {\n      return;\n    }\n    const { flags, hdcpLevel, nextAutoLevel } = errorAction;\n\n    switch (flags) {\n      case ErrorActionFlags.None:\n        this.switchLevel(data, nextAutoLevel);\n        break;\n      case ErrorActionFlags.MoveAllAlternatesMatchingHDCP:\n        if (hdcpLevel) {\n          hls.maxHdcpLevel = HdcpLevels[HdcpLevels.indexOf(hdcpLevel) - 1];\n          errorAction.resolved = true;\n        }\n        this.warn(\n          `Restricting playback to HDCP-LEVEL of \"${hls.maxHdcpLevel}\" or lower`,\n        );\n        break;\n    }\n    // If not resolved by previous actions try to switch to next level\n    if (!errorAction.resolved) {\n      this.switchLevel(data, nextAutoLevel);\n    }\n  }\n\n  private switchLevel(data: ErrorData, levelIndex: number | undefined) {\n    if (levelIndex !== undefined && data.errorAction) {\n      this.warn(`switching to level ${levelIndex} after ${data.details}`);\n      this.hls.nextAutoLevel = levelIndex;\n      data.errorAction.resolved = true;\n      // Stream controller is responsible for this but won't switch on false start\n      this.hls.nextLoadLevel = this.hls.nextAutoLevel;\n    }\n  }\n}\n","import type Hls from '../hls';\nimport type { NetworkComponentAPI } from '../types/component-api';\nimport { getSkipValue, HlsSkip, HlsUrlParameters, Level } from '../types/level';\nimport { computeReloadInterval, mergeDetails } from '../utils/level-helper';\nimport { ErrorData } from '../types/events';\nimport { getRetryDelay, isTimeoutError } from '../utils/error-helper';\nimport { NetworkErrorAction } from './error-controller';\nimport { logger } from '../utils/logger';\nimport type { LevelDetails } from '../loader/level-details';\nimport type { MediaPlaylist } from '../types/media-playlist';\nimport type {\n  AudioTrackLoadedData,\n  LevelLoadedData,\n  TrackLoadedData,\n} from '../types/events';\n\nexport default class BasePlaylistController implements NetworkComponentAPI {\n  protected hls: Hls;\n  protected timer: number = -1;\n  protected requestScheduled: number = -1;\n  protected canLoad: boolean = false;\n  protected log: (msg: any) => void;\n  protected warn: (msg: any) => void;\n\n  constructor(hls: Hls, logPrefix: string) {\n    this.log = logger.log.bind(logger, `${logPrefix}:`);\n    this.warn = logger.warn.bind(logger, `${logPrefix}:`);\n    this.hls = hls;\n  }\n\n  public destroy(): void {\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this.log = this.warn = null;\n  }\n\n  protected clearTimer(): void {\n    if (this.timer !== -1) {\n      self.clearTimeout(this.timer);\n      this.timer = -1;\n    }\n  }\n\n  public startLoad(): void {\n    this.canLoad = true;\n    this.requestScheduled = -1;\n    this.loadPlaylist();\n  }\n\n  public stopLoad(): void {\n    this.canLoad = false;\n    this.clearTimer();\n  }\n\n  protected switchParams(\n    playlistUri: string,\n    previous: LevelDetails | undefined,\n    current: LevelDetails | undefined,\n  ): HlsUrlParameters | undefined {\n    const renditionReports = previous?.renditionReports;\n    if (renditionReports) {\n      let foundIndex = -1;\n      for (let i = 0; i < renditionReports.length; i++) {\n        const attr = renditionReports[i];\n        let uri: string;\n        try {\n          uri = new self.URL(attr.URI, previous.url).href;\n        } catch (error) {\n          logger.warn(\n            `Could not construct new URL for Rendition Report: ${error}`,\n          );\n          uri = attr.URI || '';\n        }\n        // Use exact match. Otherwise, the last partial match, if any, will be used\n        // (Playlist URI includes a query string that the Rendition Report does not)\n        if (uri === playlistUri) {\n          foundIndex = i;\n          break;\n        } else if (uri === playlistUri.substring(0, uri.length)) {\n          foundIndex = i;\n        }\n      }\n      if (foundIndex !== -1) {\n        const attr = renditionReports[foundIndex];\n        const msn = parseInt(attr['LAST-MSN']) || previous?.lastPartSn;\n        let part = parseInt(attr['LAST-PART']) || previous?.lastPartIndex;\n        if (this.hls.config.lowLatencyMode) {\n          const currentGoal = Math.min(\n            previous.age - previous.partTarget,\n            previous.targetduration,\n          );\n          if (part >= 0 && currentGoal > previous.partTarget) {\n            part += 1;\n          }\n        }\n        const skip = current && getSkipValue(current);\n        return new HlsUrlParameters(msn, part >= 0 ? part : undefined, skip);\n      }\n    }\n  }\n\n  protected loadPlaylist(hlsUrlParameters?: HlsUrlParameters): void {\n    if (this.requestScheduled === -1) {\n      this.requestScheduled = self.performance.now();\n    }\n    // Loading is handled by the subclasses\n  }\n\n  protected shouldLoadPlaylist(\n    playlist: Level | MediaPlaylist | null | undefined,\n  ): boolean {\n    return (\n      this.canLoad &&\n      !!playlist &&\n      !!playlist.url &&\n      (!playlist.details || playlist.details.live)\n    );\n  }\n\n  protected shouldReloadPlaylist(\n    playlist: Level | MediaPlaylist | null | undefined,\n  ): boolean {\n    return (\n      this.timer === -1 &&\n      this.requestScheduled === -1 &&\n      this.shouldLoadPlaylist(playlist)\n    );\n  }\n\n  protected playlistLoaded(\n    index: number,\n    data: LevelLoadedData | AudioTrackLoadedData | TrackLoadedData,\n    previousDetails?: LevelDetails,\n  ) {\n    const { details, stats } = data;\n\n    // Set last updated date-time\n    const now = self.performance.now();\n    const elapsed = stats.loading.first\n      ? Math.max(0, now - stats.loading.first)\n      : 0;\n    details.advancedDateTime = Date.now() - elapsed;\n\n    // if current playlist is a live playlist, arm a timer to reload it\n    if (details.live || previousDetails?.live) {\n      details.reloaded(previousDetails);\n      if (previousDetails) {\n        this.log(\n          `live playlist ${index} ${\n            details.advanced\n              ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex\n              : details.updated\n                ? 'UPDATED'\n                : 'MISSED'\n          }`,\n        );\n      }\n      // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments\n      if (previousDetails && details.fragments.length > 0) {\n        mergeDetails(previousDetails, details);\n      }\n      if (!this.canLoad || !details.live) {\n        return;\n      }\n      let deliveryDirectives: HlsUrlParameters | undefined;\n      let msn: number | undefined = undefined;\n      let part: number | undefined = undefined;\n      if (details.canBlockReload && details.endSN && details.advanced) {\n        // Load level with LL-HLS delivery directives\n        const lowLatencyMode = this.hls.config.lowLatencyMode;\n        const lastPartSn = details.lastPartSn;\n        const endSn = details.endSN;\n        const lastPartIndex = details.lastPartIndex;\n        const hasParts = lastPartIndex !== -1;\n        const lastPart = lastPartSn === endSn;\n        // When low latency mode is disabled, we'll skip part requests once the last part index is found\n        const nextSnStartIndex = lowLatencyMode ? 0 : lastPartIndex;\n        if (hasParts) {\n          msn = lastPart ? endSn + 1 : lastPartSn;\n          part = lastPart ? nextSnStartIndex : lastPartIndex + 1;\n        } else {\n          msn = endSn + 1;\n        }\n        // Low-Latency CDN Tune-in: \"age\" header and time since load indicates we're behind by more than one part\n        // Update directives to obtain the Playlist that has the estimated additional duration of media\n        const lastAdvanced = details.age;\n        const cdnAge = lastAdvanced + details.ageHeader;\n        let currentGoal = Math.min(\n          cdnAge - details.partTarget,\n          details.targetduration * 1.5,\n        );\n        if (currentGoal > 0) {\n          if (previousDetails && currentGoal > previousDetails.tuneInGoal) {\n            // If we attempted to get the next or latest playlist update, but currentGoal increased,\n            // then we either can't catchup, or the \"age\" header cannot be trusted.\n            this.warn(\n              `CDN Tune-in goal increased from: ${previousDetails.tuneInGoal} to: ${currentGoal} with playlist age: ${details.age}`,\n            );\n            currentGoal = 0;\n          } else {\n            const segments = Math.floor(currentGoal / details.targetduration);\n            msn += segments;\n            if (part !== undefined) {\n              const parts = Math.round(\n                (currentGoal % details.targetduration) / details.partTarget,\n              );\n              part += parts;\n            }\n            this.log(\n              `CDN Tune-in age: ${\n                details.ageHeader\n              }s last advanced ${lastAdvanced.toFixed(\n                2,\n              )}s goal: ${currentGoal} skip sn ${segments} to part ${part}`,\n            );\n          }\n          details.tuneInGoal = currentGoal;\n        }\n        deliveryDirectives = this.getDeliveryDirectives(\n          details,\n          data.deliveryDirectives,\n          msn,\n          part,\n        );\n        if (lowLatencyMode || !lastPart) {\n          this.loadPlaylist(deliveryDirectives);\n          return;\n        }\n      } else if (details.canBlockReload || details.canSkipUntil) {\n        deliveryDirectives = this.getDeliveryDirectives(\n          details,\n          data.deliveryDirectives,\n          msn,\n          part,\n        );\n      }\n      const bufferInfo = this.hls.mainForwardBufferInfo;\n      const position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;\n      const distanceToLiveEdgeMs = (details.edge - position) * 1000;\n      const reloadInterval = computeReloadInterval(\n        details,\n        distanceToLiveEdgeMs,\n      );\n      if (details.updated && now > this.requestScheduled + reloadInterval) {\n        this.requestScheduled = stats.loading.start;\n      }\n\n      if (msn !== undefined && details.canBlockReload) {\n        this.requestScheduled =\n          stats.loading.first +\n          reloadInterval -\n          (details.partTarget * 1000 || 1000);\n      } else if (\n        this.requestScheduled === -1 ||\n        this.requestScheduled + reloadInterval < now\n      ) {\n        this.requestScheduled = now;\n      } else if (this.requestScheduled - now <= 0) {\n        this.requestScheduled += reloadInterval;\n      }\n      let estimatedTimeUntilUpdate = this.requestScheduled - now;\n      estimatedTimeUntilUpdate = Math.max(0, estimatedTimeUntilUpdate);\n      this.log(\n        `reload live playlist ${index} in ${Math.round(\n          estimatedTimeUntilUpdate,\n        )} ms`,\n      );\n      // this.log(\n      //   `live reload ${details.updated ? 'REFRESHED' : 'MISSED'}\n      // reload in ${estimatedTimeUntilUpdate / 1000}\n      // round trip ${(stats.loading.end - stats.loading.start) / 1000}\n      // diff ${\n      //   (reloadInterval -\n      //     (estimatedTimeUntilUpdate +\n      //       stats.loading.end -\n      //       stats.loading.start)) /\n      //   1000\n      // }\n      // reload interval ${reloadInterval / 1000}\n      // target duration ${details.targetduration}\n      // distance to edge ${distanceToLiveEdgeMs / 1000}`\n      // );\n\n      this.timer = self.setTimeout(\n        () => this.loadPlaylist(deliveryDirectives),\n        estimatedTimeUntilUpdate,\n      );\n    } else {\n      this.clearTimer();\n    }\n  }\n\n  private getDeliveryDirectives(\n    details: LevelDetails,\n    previousDeliveryDirectives: HlsUrlParameters | null,\n    msn?: number,\n    part?: number,\n  ): HlsUrlParameters {\n    let skip = getSkipValue(details);\n    if (previousDeliveryDirectives?.skip && details.deltaUpdateFailed) {\n      msn = previousDeliveryDirectives.msn;\n      part = previousDeliveryDirectives.part;\n      skip = HlsSkip.No;\n    }\n    return new HlsUrlParameters(msn, part, skip);\n  }\n\n  protected checkRetry(errorEvent: ErrorData): boolean {\n    const errorDetails = errorEvent.details;\n    const isTimeout = isTimeoutError(errorEvent);\n    const errorAction = errorEvent.errorAction;\n    const { action, retryCount = 0, retryConfig } = errorAction || {};\n    const retry =\n      !!errorAction &&\n      !!retryConfig &&\n      (action === NetworkErrorAction.RetryRequest ||\n        (!errorAction.resolved &&\n          action === NetworkErrorAction.SendAlternateToPenaltyBox));\n    if (retry) {\n      this.requestScheduled = -1;\n      if (retryCount >= retryConfig.maxNumRetry) {\n        return false;\n      }\n      if (isTimeout && errorEvent.context?.deliveryDirectives) {\n        // The LL-HLS request already timed out so retry immediately\n        this.warn(\n          `Retrying playlist loading ${retryCount + 1}/${\n            retryConfig.maxNumRetry\n          } after \"${errorDetails}\" without delivery-directives`,\n        );\n        this.loadPlaylist();\n      } else {\n        const delay = getRetryDelay(retryConfig, retryCount);\n        // Schedule level/track reload\n        this.timer = self.setTimeout(() => this.loadPlaylist(), delay);\n        this.warn(\n          `Retrying playlist loading ${retryCount + 1}/${\n            retryConfig.maxNumRetry\n          } after \"${errorDetails}\" in ${delay}ms`,\n        );\n      }\n      // `levelRetry = true` used to inform other controllers that a retry is happening\n      errorEvent.levelRetry = true;\n      errorAction.resolved = true;\n    }\n    return retry;\n  }\n}\n","/*\n * compute an Exponential Weighted moving average\n * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n *  - heavily inspired from shaka-player\n */\n\nclass EWMA {\n  public readonly halfLife: number;\n  private alpha_: number;\n  private estimate_: number;\n  private totalWeight_: number;\n\n  //  About half of the estimated value will be from the last |halfLife| samples by weight.\n  constructor(halfLife: number, estimate: number = 0, weight: number = 0) {\n    this.halfLife = halfLife;\n    // Larger values of alpha expire historical data more slowly.\n    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\n    this.estimate_ = estimate;\n    this.totalWeight_ = weight;\n  }\n\n  sample(weight: number, value: number) {\n    const adjAlpha = Math.pow(this.alpha_, weight);\n    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\n    this.totalWeight_ += weight;\n  }\n\n  getTotalWeight(): number {\n    return this.totalWeight_;\n  }\n\n  getEstimate(): number {\n    if (this.alpha_) {\n      const zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\n      if (zeroFactor) {\n        return this.estimate_ / zeroFactor;\n      }\n    }\n    return this.estimate_;\n  }\n}\n\nexport default EWMA;\n","/*\n * EWMA Bandwidth Estimator\n *  - heavily inspired from shaka-player\n * Tracks bandwidth samples and estimates available bandwidth.\n * Based on the minimum of two exponentially-weighted moving averages with\n * different half-lives.\n */\n\nimport EWMA from '../utils/ewma';\n\nclass EwmaBandWidthEstimator {\n  private defaultEstimate_: number;\n  private minWeight_: number;\n  private minDelayMs_: number;\n  private slow_: EWMA;\n  private fast_: EWMA;\n  private defaultTTFB_: number;\n  private ttfb_: EWMA;\n\n  constructor(\n    slow: number,\n    fast: number,\n    defaultEstimate: number,\n    defaultTTFB: number = 100,\n  ) {\n    this.defaultEstimate_ = defaultEstimate;\n    this.minWeight_ = 0.001;\n    this.minDelayMs_ = 50;\n    this.slow_ = new EWMA(slow);\n    this.fast_ = new EWMA(fast);\n    this.defaultTTFB_ = defaultTTFB;\n    this.ttfb_ = new EWMA(slow);\n  }\n\n  update(slow: number, fast: number) {\n    const { slow_, fast_, ttfb_ } = this;\n    if (slow_.halfLife !== slow) {\n      this.slow_ = new EWMA(slow, slow_.getEstimate(), slow_.getTotalWeight());\n    }\n    if (fast_.halfLife !== fast) {\n      this.fast_ = new EWMA(fast, fast_.getEstimate(), fast_.getTotalWeight());\n    }\n    if (ttfb_.halfLife !== slow) {\n      this.ttfb_ = new EWMA(slow, ttfb_.getEstimate(), ttfb_.getTotalWeight());\n    }\n  }\n\n  sample(durationMs: number, numBytes: number) {\n    durationMs = Math.max(durationMs, this.minDelayMs_);\n    const numBits = 8 * numBytes;\n    // weight is duration in seconds\n    const durationS = durationMs / 1000;\n    // value is bandwidth in bits/s\n    const bandwidthInBps = numBits / durationS;\n    this.fast_.sample(durationS, bandwidthInBps);\n    this.slow_.sample(durationS, bandwidthInBps);\n  }\n\n  sampleTTFB(ttfb: number) {\n    // weight is frequency curve applied to TTFB in seconds\n    // (longer times have less weight with expected input under 1 second)\n    const seconds = ttfb / 1000;\n    const weight = Math.sqrt(2) * Math.exp(-Math.pow(seconds, 2) / 2);\n    this.ttfb_.sample(weight, Math.max(ttfb, 5));\n  }\n\n  canEstimate(): boolean {\n    return this.fast_.getTotalWeight() >= this.minWeight_;\n  }\n\n  getEstimate(): number {\n    if (this.canEstimate()) {\n      // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\n      // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\n      // Take the minimum of these two estimates.  This should have the effect of\n      // adapting down quickly, but up more slowly.\n      return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\n    } else {\n      return this.defaultEstimate_;\n    }\n  }\n\n  getEstimateTTFB(): number {\n    if (this.ttfb_.getTotalWeight() >= this.minWeight_) {\n      return this.ttfb_.getEstimate();\n    } else {\n      return this.defaultTTFB_;\n    }\n  }\n\n  destroy() {}\n}\nexport default EwmaBandWidthEstimator;\n","import { mimeTypeForCodec } from './codecs';\nimport type { Level, VideoRange } from '../types/level';\nimport type { AudioSelectionOption } from '../types/media-playlist';\nimport type { AudioTracksByGroup } from './rendition-helper';\n\nexport type MediaDecodingInfo = {\n  supported: boolean;\n  configurations: readonly MediaDecodingConfiguration[];\n  decodingInfoResults: readonly MediaCapabilitiesDecodingInfo[];\n  error?: Error;\n};\n\ntype BaseVideoConfiguration = Omit<VideoConfiguration, 'contentType'>;\n\nexport const SUPPORTED_INFO_DEFAULT: MediaDecodingInfo = {\n  supported: true,\n  configurations: [] as MediaDecodingConfiguration[],\n  decodingInfoResults: [\n    {\n      supported: true,\n      powerEfficient: true,\n      smooth: true,\n    },\n  ],\n} as const;\n\nexport const SUPPORTED_INFO_CACHE: Record<\n  string,\n  Promise<MediaCapabilitiesDecodingInfo>\n> = {};\n\nexport function requiresMediaCapabilitiesDecodingInfo(\n  level: Level,\n  audioTracksByGroup: AudioTracksByGroup,\n  currentVideoRange: VideoRange | undefined,\n  currentFrameRate: number,\n  currentBw: number,\n  audioPreference: AudioSelectionOption | undefined,\n): boolean {\n  // Only test support when configuration is exceeds minimum options\n  const audioGroups = level.audioCodec ? level.audioGroups : null;\n  const audioCodecPreference = audioPreference?.audioCodec;\n  const channelsPreference = audioPreference?.channels;\n  const maxChannels = channelsPreference\n    ? parseInt(channelsPreference)\n    : audioCodecPreference\n      ? Infinity\n      : 2;\n  let audioChannels: Record<string, number> | null = null;\n  if (audioGroups?.length) {\n    try {\n      if (audioGroups.length === 1 && audioGroups[0]) {\n        audioChannels = audioTracksByGroup.groups[audioGroups[0]].channels;\n      } else {\n        audioChannels = audioGroups.reduce(\n          (acc, groupId) => {\n            if (groupId) {\n              const audioTrackGroup = audioTracksByGroup.groups[groupId];\n              if (!audioTrackGroup) {\n                throw new Error(`Audio track group ${groupId} not found`);\n              }\n              // Sum all channel key values\n              Object.keys(audioTrackGroup.channels).forEach((key) => {\n                acc[key] = (acc[key] || 0) + audioTrackGroup.channels[key];\n              });\n            }\n            return acc;\n          },\n          { 2: 0 },\n        );\n      }\n    } catch (error) {\n      return true;\n    }\n  }\n  return (\n    (level.videoCodec !== undefined &&\n      ((level.width > 1920 && level.height > 1088) ||\n        (level.height > 1920 && level.width > 1088) ||\n        level.frameRate > Math.max(currentFrameRate, 30) ||\n        (level.videoRange !== 'SDR' &&\n          level.videoRange !== currentVideoRange) ||\n        level.bitrate > Math.max(currentBw, 8e6))) ||\n    (!!audioChannels &&\n      Number.isFinite(maxChannels) &&\n      Object.keys(audioChannels).some(\n        (channels) => parseInt(channels) > maxChannels,\n      ))\n  );\n}\n\nexport function getMediaDecodingInfoPromise(\n  level: Level,\n  audioTracksByGroup: AudioTracksByGroup,\n  mediaCapabilities: MediaCapabilities | undefined,\n): Promise<MediaDecodingInfo> {\n  const videoCodecs = level.videoCodec;\n  const audioCodecs = level.audioCodec;\n  if (!videoCodecs || !audioCodecs || !mediaCapabilities) {\n    return Promise.resolve(SUPPORTED_INFO_DEFAULT);\n  }\n\n  const baseVideoConfiguration: BaseVideoConfiguration = {\n    width: level.width,\n    height: level.height,\n    bitrate: Math.ceil(Math.max(level.bitrate * 0.9, level.averageBitrate)),\n    // Assume a framerate of 30fps since MediaCapabilities will not accept Level default of 0.\n    framerate: level.frameRate || 30,\n  };\n\n  const videoRange = level.videoRange;\n  if (videoRange !== 'SDR') {\n    baseVideoConfiguration.transferFunction =\n      videoRange.toLowerCase() as TransferFunction;\n  }\n\n  const configurations: MediaDecodingConfiguration[] = videoCodecs\n    .split(',')\n    .map((videoCodec) => ({\n      type: 'media-source',\n      video: {\n        ...baseVideoConfiguration,\n        contentType: mimeTypeForCodec(videoCodec, 'video'),\n      },\n    }));\n\n  if (audioCodecs && level.audioGroups) {\n    level.audioGroups.forEach((audioGroupId) => {\n      if (!audioGroupId) {\n        return;\n      }\n      audioTracksByGroup.groups[audioGroupId]?.tracks.forEach((audioTrack) => {\n        if (audioTrack.groupId === audioGroupId) {\n          const channels = audioTrack.channels || '';\n          const channelsNumber = parseFloat(channels);\n          if (Number.isFinite(channelsNumber) && channelsNumber > 2) {\n            configurations.push.apply(\n              configurations,\n              audioCodecs.split(',').map((audioCodec) => ({\n                type: 'media-source',\n                audio: {\n                  contentType: mimeTypeForCodec(audioCodec, 'audio'),\n                  channels: '' + channelsNumber,\n                  // spatialRendering:\n                  //   audioCodec === 'ec-3' && channels.indexOf('JOC'),\n                },\n              })),\n            );\n          }\n        }\n      });\n    });\n  }\n\n  return Promise.all(\n    configurations.map((configuration) => {\n      // Cache MediaCapabilities promises\n      const decodingInfoKey = getMediaDecodingInfoKey(configuration);\n      return (\n        SUPPORTED_INFO_CACHE[decodingInfoKey] ||\n        (SUPPORTED_INFO_CACHE[decodingInfoKey] =\n          mediaCapabilities.decodingInfo(configuration))\n      );\n    }),\n  )\n    .then((decodingInfoResults) => ({\n      supported: !decodingInfoResults.some((info) => !info.supported),\n      configurations,\n      decodingInfoResults,\n    }))\n    .catch((error) => ({\n      supported: false,\n      configurations,\n      decodingInfoResults: [] as MediaCapabilitiesDecodingInfo[],\n      error,\n    }));\n}\n\nfunction getMediaDecodingInfoKey(config: MediaDecodingConfiguration): string {\n  const { audio, video } = config;\n  const mediaConfig = video || audio;\n  if (mediaConfig) {\n    const codec = mediaConfig.contentType.split('\"')[1];\n    if (video) {\n      return `r${video.height}x${video.width}f${Math.ceil(video.framerate)}${\n        video.transferFunction || 'sd'\n      }_${codec}_${Math.ceil(video.bitrate / 1e5)}`;\n    }\n    if (audio) {\n      return `c${audio.channels}${audio.spatialRendering ? 's' : 'n'}_${codec}`;\n    }\n  }\n  return '';\n}\n","import { type VideoRange, VideoRangeValues } from '../types/level';\nimport type { VideoSelectionOption } from '../types/media-playlist';\n\n/**\n * @returns Whether we can detect and validate HDR capability within the window context\n */\nexport function isHdrSupported() {\n  if (typeof matchMedia === 'function') {\n    const mediaQueryList = matchMedia('(dynamic-range: high)');\n    const badQuery = matchMedia('bad query');\n    if (mediaQueryList.media !== badQuery.media) {\n      return mediaQueryList.matches === true;\n    }\n  }\n  return false;\n}\n\n/**\n * Sanitizes inputs to return the active video selection options for HDR/SDR.\n * When both inputs are null:\n *\n *    `{ preferHDR: false, allowedVideoRanges: [] }`\n *\n * When `currentVideoRange` non-null, maintain the active range:\n *\n *    `{ preferHDR: currentVideoRange !== 'SDR', allowedVideoRanges: [currentVideoRange] }`\n *\n * When VideoSelectionOption non-null:\n *\n *  - Allow all video ranges if `allowedVideoRanges` unspecified.\n *  - If `preferHDR` is non-null use the value to filter `allowedVideoRanges`.\n *  - Else check window for HDR support and set `preferHDR` to the result.\n *\n * @param currentVideoRange\n * @param videoPreference\n */\nexport function getVideoSelectionOptions(\n  currentVideoRange: VideoRange | undefined,\n  videoPreference: VideoSelectionOption | undefined,\n) {\n  let preferHDR = false;\n  let allowedVideoRanges: Array<VideoRange> = [];\n\n  if (currentVideoRange) {\n    preferHDR = currentVideoRange !== 'SDR';\n    allowedVideoRanges = [currentVideoRange];\n  }\n\n  if (videoPreference) {\n    allowedVideoRanges =\n      videoPreference.allowedVideoRanges || VideoRangeValues.slice(0);\n    preferHDR =\n      videoPreference.preferHDR !== undefined\n        ? videoPreference.preferHDR\n        : isHdrSupported();\n\n    if (preferHDR) {\n      allowedVideoRanges = allowedVideoRanges.filter(\n        (range: VideoRange) => range !== 'SDR',\n      );\n    } else {\n      allowedVideoRanges = ['SDR'];\n    }\n  }\n\n  return {\n    preferHDR,\n    allowedVideoRanges,\n  };\n}\n","import { codecsSetSelectionPreferenceValue } from './codecs';\nimport { getVideoSelectionOptions } from './hdr';\nimport { logger } from './logger';\nimport type { Level, VideoRange } from '../types/level';\nimport type {\n  AudioSelectionOption,\n  MediaPlaylist,\n  SubtitleSelectionOption,\n  VideoSelectionOption,\n} from '../types/media-playlist';\n\nexport type CodecSetTier = {\n  minBitrate: number;\n  minHeight: number;\n  minFramerate: number;\n  maxScore: number;\n  videoRanges: Record<string, number>;\n  channels: Record<string, number>;\n  hasDefaultAudio: boolean;\n  fragmentError: number;\n};\n\ntype AudioTrackGroup = {\n  tracks: MediaPlaylist[];\n  channels: Record<string, number>;\n  hasDefault: boolean;\n  hasAutoSelect: boolean;\n};\ntype StartParameters = {\n  codecSet: string | undefined;\n  videoRanges: Array<VideoRange>;\n  preferHDR: boolean;\n  minFramerate: number;\n  minBitrate: number;\n};\n\nexport function getStartCodecTier(\n  codecTiers: Record<string, CodecSetTier>,\n  currentVideoRange: VideoRange | undefined,\n  currentBw: number,\n  audioPreference: AudioSelectionOption | undefined,\n  videoPreference: VideoSelectionOption | undefined,\n): StartParameters {\n  const codecSets = Object.keys(codecTiers);\n  const channelsPreference = audioPreference?.channels;\n  const audioCodecPreference = audioPreference?.audioCodec;\n  const preferStereo = channelsPreference && parseInt(channelsPreference) === 2;\n  // Use first level set to determine stereo, and minimum resolution and framerate\n  let hasStereo = true;\n  let hasCurrentVideoRange = false;\n  let minHeight = Infinity;\n  let minFramerate = Infinity;\n  let minBitrate = Infinity;\n  let selectedScore = 0;\n  let videoRanges: Array<VideoRange> = [];\n\n  const { preferHDR, allowedVideoRanges } = getVideoSelectionOptions(\n    currentVideoRange,\n    videoPreference,\n  );\n\n  for (let i = codecSets.length; i--; ) {\n    const tier = codecTiers[codecSets[i]];\n    hasStereo = tier.channels[2] > 0;\n    minHeight = Math.min(minHeight, tier.minHeight);\n    minFramerate = Math.min(minFramerate, tier.minFramerate);\n    minBitrate = Math.min(minBitrate, tier.minBitrate);\n    const matchingVideoRanges = allowedVideoRanges.filter(\n      (range) => tier.videoRanges[range] > 0,\n    );\n    if (matchingVideoRanges.length > 0) {\n      hasCurrentVideoRange = true;\n      videoRanges = matchingVideoRanges;\n    }\n  }\n  minHeight = Number.isFinite(minHeight) ? minHeight : 0;\n  minFramerate = Number.isFinite(minFramerate) ? minFramerate : 0;\n  const maxHeight = Math.max(1080, minHeight);\n  const maxFramerate = Math.max(30, minFramerate);\n  minBitrate = Number.isFinite(minBitrate) ? minBitrate : currentBw;\n  currentBw = Math.max(minBitrate, currentBw);\n  // If there are no variants with matching preference, set currentVideoRange to undefined\n  if (!hasCurrentVideoRange) {\n    currentVideoRange = undefined;\n    videoRanges = [];\n  }\n  const codecSet = codecSets.reduce(\n    (selected: string | undefined, candidate: string) => {\n      // Remove candiates which do not meet bitrate, default audio, stereo or channels preference, 1080p or lower, 30fps or lower, or SDR/HDR selection if present\n      const candidateTier = codecTiers[candidate];\n      if (candidate === selected) {\n        return selected;\n      }\n      if (candidateTier.minBitrate > currentBw) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `min bitrate of ${candidateTier.minBitrate} > current estimate of ${currentBw}`,\n        );\n        return selected;\n      }\n      if (!candidateTier.hasDefaultAudio) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `no renditions with default or auto-select sound found`,\n        );\n        return selected;\n      }\n      if (\n        audioCodecPreference &&\n        candidate.indexOf(audioCodecPreference.substring(0, 4)) % 5 !== 0\n      ) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `audio codec preference \"${audioCodecPreference}\" not found`,\n        );\n        return selected;\n      }\n      if (channelsPreference && !preferStereo) {\n        if (!candidateTier.channels[channelsPreference]) {\n          logStartCodecCandidateIgnored(\n            candidate,\n            `no renditions with ${channelsPreference} channel sound found (channels options: ${Object.keys(\n              candidateTier.channels,\n            )})`,\n          );\n          return selected;\n        }\n      } else if (\n        (!audioCodecPreference || preferStereo) &&\n        hasStereo &&\n        candidateTier.channels['2'] === 0\n      ) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `no renditions with stereo sound found`,\n        );\n        return selected;\n      }\n      if (candidateTier.minHeight > maxHeight) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `min resolution of ${candidateTier.minHeight} > maximum of ${maxHeight}`,\n        );\n        return selected;\n      }\n      if (candidateTier.minFramerate > maxFramerate) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `min framerate of ${candidateTier.minFramerate} > maximum of ${maxFramerate}`,\n        );\n        return selected;\n      }\n      if (!videoRanges.some((range) => candidateTier.videoRanges[range] > 0)) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `no variants with VIDEO-RANGE of ${JSON.stringify(\n            videoRanges,\n          )} found`,\n        );\n        return selected;\n      }\n      if (candidateTier.maxScore < selectedScore) {\n        logStartCodecCandidateIgnored(\n          candidate,\n          `max score of ${candidateTier.maxScore} < selected max of ${selectedScore}`,\n        );\n        return selected;\n      }\n      // Remove candiates with less preferred codecs or more errors\n      if (\n        selected &&\n        (codecsSetSelectionPreferenceValue(candidate) >=\n          codecsSetSelectionPreferenceValue(selected) ||\n          candidateTier.fragmentError > codecTiers[selected].fragmentError)\n      ) {\n        return selected;\n      }\n      selectedScore = candidateTier.maxScore;\n      return candidate;\n    },\n    undefined,\n  );\n  return {\n    codecSet,\n    videoRanges,\n    preferHDR,\n    minFramerate,\n    minBitrate,\n  };\n}\n\nfunction logStartCodecCandidateIgnored(codeSet: string, reason: string) {\n  logger.log(\n    `[abr] start candidates with \"${codeSet}\" ignored because ${reason}`,\n  );\n}\n\nexport type AudioTracksByGroup = {\n  hasDefaultAudio: boolean;\n  hasAutoSelectAudio: boolean;\n  groups: Record<string, AudioTrackGroup>;\n};\n\nexport function getAudioTracksByGroup(allAudioTracks: MediaPlaylist[]) {\n  return allAudioTracks.reduce(\n    (audioTracksByGroup: AudioTracksByGroup, track) => {\n      let trackGroup = audioTracksByGroup.groups[track.groupId];\n      if (!trackGroup) {\n        trackGroup = audioTracksByGroup.groups[track.groupId] = {\n          tracks: [],\n          channels: { 2: 0 },\n          hasDefault: false,\n          hasAutoSelect: false,\n        };\n      }\n      trackGroup.tracks.push(track);\n      const channelsKey = track.channels || '2';\n      trackGroup.channels[channelsKey] =\n        (trackGroup.channels[channelsKey] || 0) + 1;\n      trackGroup.hasDefault = trackGroup.hasDefault || track.default;\n      trackGroup.hasAutoSelect = trackGroup.hasAutoSelect || track.autoselect;\n      if (trackGroup.hasDefault) {\n        audioTracksByGroup.hasDefaultAudio = true;\n      }\n      if (trackGroup.hasAutoSelect) {\n        audioTracksByGroup.hasAutoSelectAudio = true;\n      }\n      return audioTracksByGroup;\n    },\n    {\n      hasDefaultAudio: false,\n      hasAutoSelectAudio: false,\n      groups: {},\n    },\n  );\n}\n\nexport function getCodecTiers(\n  levels: Level[],\n  audioTracksByGroup: AudioTracksByGroup,\n  minAutoLevel: number,\n  maxAutoLevel: number,\n): Record<string, CodecSetTier> {\n  return levels\n    .slice(minAutoLevel, maxAutoLevel + 1)\n    .reduce((tiers: Record<string, CodecSetTier>, level) => {\n      if (!level.codecSet) {\n        return tiers;\n      }\n      const audioGroups = level.audioGroups;\n      let tier = tiers[level.codecSet];\n      if (!tier) {\n        tiers[level.codecSet] = tier = {\n          minBitrate: Infinity,\n          minHeight: Infinity,\n          minFramerate: Infinity,\n          maxScore: 0,\n          videoRanges: { SDR: 0 },\n          channels: { '2': 0 },\n          hasDefaultAudio: !audioGroups,\n          fragmentError: 0,\n        };\n      }\n      tier.minBitrate = Math.min(tier.minBitrate, level.bitrate);\n      const lesserWidthOrHeight = Math.min(level.height, level.width);\n      tier.minHeight = Math.min(tier.minHeight, lesserWidthOrHeight);\n      tier.minFramerate = Math.min(tier.minFramerate, level.frameRate);\n      tier.maxScore = Math.max(tier.maxScore, level.score);\n      tier.fragmentError += level.fragmentError;\n      tier.videoRanges[level.videoRange] =\n        (tier.videoRanges[level.videoRange] || 0) + 1;\n      if (__USE_ALT_AUDIO__ && audioGroups) {\n        audioGroups.forEach((audioGroupId) => {\n          if (!audioGroupId) {\n            return;\n          }\n          const audioGroup = audioTracksByGroup.groups[audioGroupId];\n          if (!audioGroup) {\n            return;\n          }\n          // Default audio is any group with DEFAULT=YES, or if missing then any group with AUTOSELECT=YES, or all variants\n          tier.hasDefaultAudio =\n            tier.hasDefaultAudio || audioTracksByGroup.hasDefaultAudio\n              ? audioGroup.hasDefault\n              : audioGroup.hasAutoSelect ||\n                (!audioTracksByGroup.hasDefaultAudio &&\n                  !audioTracksByGroup.hasAutoSelectAudio);\n          Object.keys(audioGroup.channels).forEach((channels) => {\n            tier.channels[channels] =\n              (tier.channels[channels] || 0) + audioGroup.channels[channels];\n          });\n        });\n      }\n      return tiers;\n    }, {});\n}\n\nexport function findMatchingOption(\n  option: MediaPlaylist | AudioSelectionOption | SubtitleSelectionOption,\n  tracks: MediaPlaylist[],\n  matchPredicate?: (\n    option: MediaPlaylist | AudioSelectionOption | SubtitleSelectionOption,\n    track: MediaPlaylist,\n  ) => boolean,\n): number {\n  if ('attrs' in option) {\n    const index = tracks.indexOf(option);\n    if (index !== -1) {\n      return index;\n    }\n  }\n  for (let i = 0; i < tracks.length; i++) {\n    const track = tracks[i];\n    if (matchesOption(option, track, matchPredicate)) {\n      return i;\n    }\n  }\n  return -1;\n}\n\nexport function matchesOption(\n  option: MediaPlaylist | AudioSelectionOption | SubtitleSelectionOption,\n  track: MediaPlaylist,\n  matchPredicate?: (\n    option: MediaPlaylist | AudioSelectionOption | SubtitleSelectionOption,\n    track: MediaPlaylist,\n  ) => boolean,\n): boolean {\n  const { groupId, name, lang, assocLang, default: isDefault } = option;\n  const forced = (option as SubtitleSelectionOption).forced;\n  return (\n    (groupId === undefined || track.groupId === groupId) &&\n    (name === undefined || track.name === name) &&\n    (lang === undefined || track.lang === lang) &&\n    (lang === undefined || track.assocLang === assocLang) &&\n    (isDefault === undefined || track.default === isDefault) &&\n    (forced === undefined || track.forced === forced) &&\n    (!('characteristics' in option) ||\n      characteristicsMatch(\n        option.characteristics || '',\n        track.characteristics,\n      )) &&\n    (matchPredicate === undefined || matchPredicate(option, track))\n  );\n}\n\nfunction characteristicsMatch(\n  characteristicsA: string,\n  characteristicsB: string = '',\n): boolean {\n  const arrA = characteristicsA.split(',');\n  const arrB = characteristicsB.split(',');\n  // Expects each item to be unique:\n  return (\n    arrA.length === arrB.length && !arrA.some((el) => arrB.indexOf(el) === -1)\n  );\n}\n\nexport function audioMatchPredicate(\n  option: MediaPlaylist | AudioSelectionOption,\n  track: MediaPlaylist,\n) {\n  const { audioCodec, channels } = option;\n  return (\n    (audioCodec === undefined ||\n      (track.audioCodec || '').substring(0, 4) ===\n        audioCodec.substring(0, 4)) &&\n    (channels === undefined || channels === (track.channels || '2'))\n  );\n}\n\nexport function findClosestLevelWithAudioGroup(\n  option: MediaPlaylist | AudioSelectionOption,\n  levels: Level[],\n  allAudioTracks: MediaPlaylist[],\n  searchIndex: number,\n  matchPredicate: (\n    option: MediaPlaylist | AudioSelectionOption,\n    track: MediaPlaylist,\n  ) => boolean,\n): number {\n  const currentLevel = levels[searchIndex];\n  // Are there variants with same URI as current level?\n  // If so, find a match that does not require any level URI change\n  const variants = levels.reduce(\n    (variantMap: { [uri: string]: number[] }, level, index) => {\n      const uri = level.uri;\n      const renditions = variantMap[uri] || (variantMap[uri] = []);\n      renditions.push(index);\n      return variantMap;\n    },\n    {},\n  );\n  const renditions = variants[currentLevel.uri];\n  if (renditions.length > 1) {\n    searchIndex = Math.max.apply(Math, renditions);\n  }\n  // Find best match\n  const currentVideoRange = currentLevel.videoRange;\n  const currentFrameRate = currentLevel.frameRate;\n  const currentVideoCodec = currentLevel.codecSet.substring(0, 4);\n  const matchingVideo = searchDownAndUpList(\n    levels,\n    searchIndex,\n    (level: Level) => {\n      if (\n        level.videoRange !== currentVideoRange ||\n        level.frameRate !== currentFrameRate ||\n        level.codecSet.substring(0, 4) !== currentVideoCodec\n      ) {\n        return false;\n      }\n      const audioGroups = level.audioGroups;\n      const tracks = allAudioTracks.filter(\n        (track): boolean =>\n          !audioGroups || audioGroups.indexOf(track.groupId) !== -1,\n      );\n      return findMatchingOption(option, tracks, matchPredicate) > -1;\n    },\n  );\n  if (matchingVideo > -1) {\n    return matchingVideo;\n  }\n  return searchDownAndUpList(levels, searchIndex, (level: Level) => {\n    const audioGroups = level.audioGroups;\n    const tracks = allAudioTracks.filter(\n      (track): boolean =>\n        !audioGroups || audioGroups.indexOf(track.groupId) !== -1,\n    );\n    return findMatchingOption(option, tracks, matchPredicate) > -1;\n  });\n}\n\nfunction searchDownAndUpList(\n  arr: any[],\n  searchIndex: number,\n  predicate: (item: any) => boolean,\n): number {\n  for (let i = searchIndex; i > -1; i--) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  for (let i = searchIndex + 1; i < arr.length; i++) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  return -1;\n}\n","import EwmaBandWidthEstimator from '../utils/ewma-bandwidth-estimator';\nimport { Events } from '../events';\nimport { ErrorDetails } from '../errors';\nimport { PlaylistLevelType } from '../types/loader';\nimport { logger } from '../utils/logger';\nimport {\n  SUPPORTED_INFO_DEFAULT,\n  getMediaDecodingInfoPromise,\n  requiresMediaCapabilitiesDecodingInfo,\n} from '../utils/mediacapabilities-helper';\nimport {\n  getAudioTracksByGroup,\n  getCodecTiers,\n  getStartCodecTier,\n  type AudioTracksByGroup,\n  type CodecSetTier,\n} from '../utils/rendition-helper';\nimport type { Fragment } from '../loader/fragment';\nimport type { Part } from '../loader/fragment';\nimport type { Level, VideoRange } from '../types/level';\nimport type { LoaderStats } from '../types/loader';\nimport type Hls from '../hls';\nimport type {\n  FragLoadingData,\n  FragLoadedData,\n  FragBufferedData,\n  LevelLoadedData,\n  LevelSwitchingData,\n  ManifestLoadingData,\n  ErrorData,\n} from '../types/events';\nimport type { AbrComponentAPI } from '../types/component-api';\n\nclass AbrController implements AbrComponentAPI {\n  protected hls: Hls;\n  private lastLevelLoadSec: number = 0;\n  private lastLoadedFragLevel: number = -1;\n  private firstSelection: number = -1;\n  private _nextAutoLevel: number = -1;\n  private nextAutoLevelKey: string = '';\n  private audioTracksByGroup: AudioTracksByGroup | null = null;\n  private codecTiers: Record<string, CodecSetTier> | null = null;\n  private timer: number = -1;\n  private fragCurrent: Fragment | null = null;\n  private partCurrent: Part | null = null;\n  private bitrateTestDelay: number = 0;\n\n  public bwEstimator: EwmaBandWidthEstimator;\n\n  constructor(hls: Hls) {\n    this.hls = hls;\n    this.bwEstimator = this.initEstimator();\n    this.registerListeners();\n  }\n\n  public resetEstimator(abrEwmaDefaultEstimate?: number) {\n    if (abrEwmaDefaultEstimate) {\n      logger.log(`setting initial bwe to ${abrEwmaDefaultEstimate}`);\n      this.hls.config.abrEwmaDefaultEstimate = abrEwmaDefaultEstimate;\n    }\n    this.firstSelection = -1;\n    this.bwEstimator = this.initEstimator();\n  }\n\n  private initEstimator(): EwmaBandWidthEstimator {\n    const config = this.hls.config;\n    return new EwmaBandWidthEstimator(\n      config.abrEwmaSlowVoD,\n      config.abrEwmaFastVoD,\n      config.abrEwmaDefaultEstimate,\n    );\n  }\n\n  protected registerListeners() {\n    const { hls } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n\n  protected unregisterListeners() {\n    const { hls } = this;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n\n  public destroy() {\n    this.unregisterListeners();\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this._abandonRulesCheck = null;\n    this.fragCurrent = this.partCurrent = null;\n  }\n\n  protected onManifestLoading(\n    event: Events.MANIFEST_LOADING,\n    data: ManifestLoadingData,\n  ) {\n    this.lastLoadedFragLevel = -1;\n    this.firstSelection = -1;\n    this.lastLevelLoadSec = 0;\n    this.fragCurrent = this.partCurrent = null;\n    this.onLevelsUpdated();\n    this.clearTimer();\n  }\n\n  private onLevelsUpdated() {\n    if (this.lastLoadedFragLevel > -1 && this.fragCurrent) {\n      this.lastLoadedFragLevel = this.fragCurrent.level;\n    }\n    this._nextAutoLevel = -1;\n    this.onMaxAutoLevelUpdated();\n    this.codecTiers = null;\n    this.audioTracksByGroup = null;\n  }\n\n  private onMaxAutoLevelUpdated() {\n    this.firstSelection = -1;\n    this.nextAutoLevelKey = '';\n  }\n\n  protected onFragLoading(event: Events.FRAG_LOADING, data: FragLoadingData) {\n    const frag = data.frag;\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    if (!frag.bitrateTest) {\n      this.fragCurrent = frag;\n      this.partCurrent = data.part ?? null;\n    }\n    this.clearTimer();\n    this.timer = self.setInterval(this._abandonRulesCheck, 100);\n  }\n\n  protected onLevelSwitching(\n    event: Events.LEVEL_SWITCHING,\n    data: LevelSwitchingData,\n  ): void {\n    this.clearTimer();\n  }\n\n  protected onError(event: Events.ERROR, data: ErrorData) {\n    if (data.fatal) {\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        // Reset last loaded level so that a new selection can be made after calling recoverMediaError\n        this.lastLoadedFragLevel = -1;\n        this.firstSelection = -1;\n        break;\n      case ErrorDetails.FRAG_LOAD_TIMEOUT: {\n        const frag = data.frag;\n        const { fragCurrent, partCurrent: part } = this;\n        if (\n          frag &&\n          fragCurrent &&\n          frag.sn === fragCurrent.sn &&\n          frag.level === fragCurrent.level\n        ) {\n          const now = performance.now();\n          const stats: LoaderStats = part ? part.stats : frag.stats;\n          const timeLoading = now - stats.loading.start;\n          const ttfb = stats.loading.first\n            ? stats.loading.first - stats.loading.start\n            : -1;\n          const loadedFirstByte = stats.loaded && ttfb > -1;\n          if (loadedFirstByte) {\n            const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n            this.bwEstimator.sample(\n              timeLoading - Math.min(ttfbEstimate, ttfb),\n              stats.loaded,\n            );\n          } else {\n            this.bwEstimator.sampleTTFB(timeLoading);\n          }\n        }\n        break;\n      }\n    }\n  }\n\n  private getTimeToLoadFrag(\n    timeToFirstByteSec: number,\n    bandwidth: number,\n    fragSizeBits: number,\n    isSwitch: boolean,\n  ): number {\n    const fragLoadSec = timeToFirstByteSec + fragSizeBits / bandwidth;\n    const playlistLoadSec = isSwitch ? this.lastLevelLoadSec : 0;\n    return fragLoadSec + playlistLoadSec;\n  }\n\n  protected onLevelLoaded(event: Events.LEVEL_LOADED, data: LevelLoadedData) {\n    const config = this.hls.config;\n    const { loading } = data.stats;\n    const timeLoadingMs = loading.end - loading.start;\n    if (Number.isFinite(timeLoadingMs)) {\n      this.lastLevelLoadSec = timeLoadingMs / 1000;\n    }\n    if (data.details.live) {\n      this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);\n    } else {\n      this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);\n    }\n  }\n\n  /*\n      This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load\n      quickly enough to prevent underbuffering\n    */\n  private _abandonRulesCheck = () => {\n    const { fragCurrent: frag, partCurrent: part, hls } = this;\n    const { autoLevelEnabled, media } = hls;\n    if (!frag || !media) {\n      return;\n    }\n\n    const now = performance.now();\n    const stats: LoaderStats = part ? part.stats : frag.stats;\n    const duration = part ? part.duration : frag.duration;\n    const timeLoading = now - stats.loading.start;\n    const minAutoLevel = hls.minAutoLevel;\n    // If frag loading is aborted, complete, or from lowest level, stop timer and return\n    if (\n      stats.aborted ||\n      (stats.loaded && stats.loaded === stats.total) ||\n      frag.level <= minAutoLevel\n    ) {\n      this.clearTimer();\n      // reset forced auto level value so that next level will be selected\n      this._nextAutoLevel = -1;\n      return;\n    }\n\n    // This check only runs if we're in ABR mode and actually playing\n    if (\n      !autoLevelEnabled ||\n      media.paused ||\n      !media.playbackRate ||\n      !media.readyState\n    ) {\n      return;\n    }\n\n    const bufferInfo = hls.mainForwardBufferInfo;\n    if (bufferInfo === null) {\n      return;\n    }\n\n    const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n    const playbackRate = Math.abs(media.playbackRate);\n    // To maintain stable adaptive playback, only begin monitoring frag loading after half or more of its playback duration has passed\n    if (\n      timeLoading <=\n      Math.max(ttfbEstimate, 1000 * (duration / (playbackRate * 2)))\n    ) {\n      return;\n    }\n\n    // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer\n    const bufferStarvationDelay = bufferInfo.len / playbackRate;\n    const ttfb = stats.loading.first\n      ? stats.loading.first - stats.loading.start\n      : -1;\n    const loadedFirstByte = stats.loaded && ttfb > -1;\n    const bwEstimate: number = this.getBwEstimate();\n    const levels = hls.levels;\n    const level = levels[frag.level];\n    const expectedLen =\n      stats.total ||\n      Math.max(stats.loaded, Math.round((duration * level.averageBitrate) / 8));\n    let timeStreaming = loadedFirstByte ? timeLoading - ttfb : timeLoading;\n    if (timeStreaming < 1 && loadedFirstByte) {\n      timeStreaming = Math.min(timeLoading, (stats.loaded * 8) / bwEstimate);\n    }\n    const loadRate = loadedFirstByte\n      ? (stats.loaded * 1000) / timeStreaming\n      : 0;\n    // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment\n    const fragLoadedDelay = loadRate\n      ? (expectedLen - stats.loaded) / loadRate\n      : (expectedLen * 8) / bwEstimate + ttfbEstimate / 1000;\n    // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left\n    if (fragLoadedDelay <= bufferStarvationDelay) {\n      return;\n    }\n\n    const bwe = loadRate ? loadRate * 8 : bwEstimate;\n    let fragLevelNextLoadedDelay: number = Number.POSITIVE_INFINITY;\n    let nextLoadLevel: number;\n    // Iterate through lower level and try to find the largest one that avoids rebuffering\n    for (\n      nextLoadLevel = frag.level - 1;\n      nextLoadLevel > minAutoLevel;\n      nextLoadLevel--\n    ) {\n      // compute time to load next fragment at lower level\n      // 8 = bits per byte (bps/Bps)\n      const levelNextBitrate = levels[nextLoadLevel].maxBitrate;\n      fragLevelNextLoadedDelay = this.getTimeToLoadFrag(\n        ttfbEstimate / 1000,\n        bwe,\n        duration * levelNextBitrate,\n        !levels[nextLoadLevel].details,\n      );\n      if (fragLevelNextLoadedDelay < bufferStarvationDelay) {\n        break;\n      }\n    }\n    // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing\n    // to load the current one\n    if (fragLevelNextLoadedDelay >= fragLoadedDelay) {\n      return;\n    }\n\n    // if estimated load time of new segment is completely unreasonable, ignore and do not emergency switch down\n    if (fragLevelNextLoadedDelay > duration * 10) {\n      return;\n    }\n    hls.nextLoadLevel = hls.nextAutoLevel = nextLoadLevel;\n    if (loadedFirstByte) {\n      // If there has been loading progress, sample bandwidth using loading time offset by minimum TTFB time\n      this.bwEstimator.sample(\n        timeLoading - Math.min(ttfbEstimate, ttfb),\n        stats.loaded,\n      );\n    } else {\n      // If there has been no loading progress, sample TTFB\n      this.bwEstimator.sampleTTFB(timeLoading);\n    }\n    const nextLoadLevelBitrate = levels[nextLoadLevel].maxBitrate;\n    if (\n      this.getBwEstimate() * this.hls.config.abrBandWidthUpFactor >\n      nextLoadLevelBitrate\n    ) {\n      this.resetEstimator(nextLoadLevelBitrate);\n    }\n\n    this.clearTimer();\n    logger.warn(`[abr] Fragment ${frag.sn}${\n      part ? ' part ' + part.index : ''\n    } of level ${frag.level} is loading too slowly;\n      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s\n      Estimated load time for current fragment: ${fragLoadedDelay.toFixed(3)} s\n      Estimated load time for down switch fragment: ${fragLevelNextLoadedDelay.toFixed(\n        3,\n      )} s\n      TTFB estimate: ${ttfb | 0} ms\n      Current BW estimate: ${\n        Number.isFinite(bwEstimate) ? bwEstimate | 0 : 'Unknown'\n      } bps\n      New BW estimate: ${this.getBwEstimate() | 0} bps\n      Switching to level ${nextLoadLevel} @ ${nextLoadLevelBitrate | 0} bps`);\n    hls.trigger(Events.FRAG_LOAD_EMERGENCY_ABORTED, { frag, part, stats });\n  };\n\n  protected onFragLoaded(\n    event: Events.FRAG_LOADED,\n    { frag, part }: FragLoadedData,\n  ) {\n    const stats = part ? part.stats : frag.stats;\n    if (frag.type === PlaylistLevelType.MAIN) {\n      this.bwEstimator.sampleTTFB(stats.loading.first - stats.loading.start);\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // stop monitoring bw once frag loaded\n    this.clearTimer();\n    // reset forced auto level value so that next level will be selected\n    if (frag.level === this._nextAutoLevel) {\n      this._nextAutoLevel = -1;\n    }\n    this.firstSelection = -1;\n\n    // compute level average bitrate\n    if (this.hls.config.abrMaxWithRealBitrate) {\n      const duration = part ? part.duration : frag.duration;\n      const level = this.hls.levels[frag.level];\n      const loadedBytes =\n        (level.loaded ? level.loaded.bytes : 0) + stats.loaded;\n      const loadedDuration =\n        (level.loaded ? level.loaded.duration : 0) + duration;\n      level.loaded = { bytes: loadedBytes, duration: loadedDuration };\n      level.realBitrate = Math.round((8 * loadedBytes) / loadedDuration);\n    }\n    if (frag.bitrateTest) {\n      const fragBufferedData: FragBufferedData = {\n        stats,\n        frag,\n        part,\n        id: frag.type,\n      };\n      this.onFragBuffered(Events.FRAG_BUFFERED, fragBufferedData);\n      frag.bitrateTest = false;\n    } else {\n      // store level id after successful fragment load for playback\n      this.lastLoadedFragLevel = frag.level;\n    }\n  }\n\n  protected onFragBuffered(\n    event: Events.FRAG_BUFFERED,\n    data: FragBufferedData,\n  ) {\n    const { frag, part } = data;\n    const stats = part?.stats.loaded ? part.stats : frag.stats;\n\n    if (stats.aborted) {\n      return;\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;\n    // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch\n    // is used. If we used buffering in that case, our BW estimate sample will be very large.\n    const processingMs =\n      stats.parsing.end -\n      stats.loading.start -\n      Math.min(\n        stats.loading.first - stats.loading.start,\n        this.bwEstimator.getEstimateTTFB(),\n      );\n    this.bwEstimator.sample(processingMs, stats.loaded);\n    stats.bwEstimate = this.getBwEstimate();\n    if (frag.bitrateTest) {\n      this.bitrateTestDelay = processingMs / 1000;\n    } else {\n      this.bitrateTestDelay = 0;\n    }\n  }\n\n  private ignoreFragment(frag: Fragment): boolean {\n    // Only count non-alt-audio frags which were actually buffered in our BW calculations\n    return frag.type !== PlaylistLevelType.MAIN || frag.sn === 'initSegment';\n  }\n\n  public clearTimer() {\n    if (this.timer > -1) {\n      self.clearInterval(this.timer);\n      this.timer = -1;\n    }\n  }\n\n  public get firstAutoLevel(): number {\n    const { maxAutoLevel, minAutoLevel } = this.hls;\n    const bwEstimate = this.getBwEstimate();\n    const maxStartDelay = this.hls.config.maxStarvationDelay;\n    const abrAutoLevel = this.findBestLevel(\n      bwEstimate,\n      minAutoLevel,\n      maxAutoLevel,\n      0,\n      maxStartDelay,\n      1,\n      1,\n    );\n    if (abrAutoLevel > -1) {\n      return abrAutoLevel;\n    }\n    const firstLevel = this.hls.firstLevel;\n    const clamped = Math.min(Math.max(firstLevel, minAutoLevel), maxAutoLevel);\n    logger.warn(\n      `[abr] Could not find best starting auto level. Defaulting to first in playlist ${firstLevel} clamped to ${clamped}`,\n    );\n    return clamped;\n  }\n\n  public get forcedAutoLevel(): number {\n    if (this.nextAutoLevelKey) {\n      return -1;\n    }\n    return this._nextAutoLevel;\n  }\n\n  // return next auto level\n  public get nextAutoLevel(): number {\n    const forcedAutoLevel = this.forcedAutoLevel;\n    const bwEstimator = this.bwEstimator;\n    const useEstimate = bwEstimator.canEstimate();\n    const loadedFirstFrag = this.lastLoadedFragLevel > -1;\n    // in case next auto level has been forced, and bw not available or not reliable, return forced value\n    if (\n      forcedAutoLevel !== -1 &&\n      (!useEstimate ||\n        !loadedFirstFrag ||\n        this.nextAutoLevelKey === this.getAutoLevelKey())\n    ) {\n      return forcedAutoLevel;\n    }\n\n    // compute next level using ABR logic\n    const nextABRAutoLevel =\n      useEstimate && loadedFirstFrag\n        ? this.getNextABRAutoLevel()\n        : this.firstAutoLevel;\n\n    // use forced auto level while it hasn't errored more than ABR selection\n    if (forcedAutoLevel !== -1) {\n      const levels = this.hls.levels;\n      if (\n        levels.length > Math.max(forcedAutoLevel, nextABRAutoLevel) &&\n        levels[forcedAutoLevel].loadError <= levels[nextABRAutoLevel].loadError\n      ) {\n        return forcedAutoLevel;\n      }\n    }\n\n    // save result until state has changed\n    this._nextAutoLevel = nextABRAutoLevel;\n    this.nextAutoLevelKey = this.getAutoLevelKey();\n\n    return nextABRAutoLevel;\n  }\n\n  private getAutoLevelKey(): string {\n    return `${this.getBwEstimate()}_${this.getStarvationDelay().toFixed(2)}`;\n  }\n\n  private getNextABRAutoLevel(): number {\n    const { fragCurrent, partCurrent, hls } = this;\n    const { maxAutoLevel, config, minAutoLevel } = hls;\n    const currentFragDuration = partCurrent\n      ? partCurrent.duration\n      : fragCurrent\n        ? fragCurrent.duration\n        : 0;\n    const avgbw = this.getBwEstimate();\n    // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\n    const bufferStarvationDelay = this.getStarvationDelay();\n\n    let bwFactor = config.abrBandWidthFactor;\n    let bwUpFactor = config.abrBandWidthUpFactor;\n\n    // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\n    if (bufferStarvationDelay) {\n      const bestLevel = this.findBestLevel(\n        avgbw,\n        minAutoLevel,\n        maxAutoLevel,\n        bufferStarvationDelay,\n        0,\n        bwFactor,\n        bwUpFactor,\n      );\n      if (bestLevel >= 0) {\n        return bestLevel;\n      }\n    }\n    // not possible to get rid of rebuffering... try to find level that will guarantee less than maxStarvationDelay of rebuffering\n    let maxStarvationDelay = currentFragDuration\n      ? Math.min(currentFragDuration, config.maxStarvationDelay)\n      : config.maxStarvationDelay;\n\n    if (!bufferStarvationDelay) {\n      // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\n      const bitrateTestDelay = this.bitrateTestDelay;\n      if (bitrateTestDelay) {\n        // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\n        // max video loading delay used in  automatic start level selection :\n        // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\n        // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\n        // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\n        const maxLoadingDelay = currentFragDuration\n          ? Math.min(currentFragDuration, config.maxLoadingDelay)\n          : config.maxLoadingDelay;\n        maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\n        logger.info(\n          `[abr] bitrate test took ${Math.round(\n            1000 * bitrateTestDelay,\n          )}ms, set first fragment max fetchDuration to ${Math.round(\n            1000 * maxStarvationDelay,\n          )} ms`,\n        );\n        // don't use conservative factor on bitrate test\n        bwFactor = bwUpFactor = 1;\n      }\n    }\n    const bestLevel = this.findBestLevel(\n      avgbw,\n      minAutoLevel,\n      maxAutoLevel,\n      bufferStarvationDelay,\n      maxStarvationDelay,\n      bwFactor,\n      bwUpFactor,\n    );\n    logger.info(\n      `[abr] ${\n        bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty'\n      }, optimal quality level ${bestLevel}`,\n    );\n    if (bestLevel > -1) {\n      return bestLevel;\n    }\n    // If no matching level found, see if min auto level would be a better option\n    const minLevel = hls.levels[minAutoLevel];\n    const autoLevel = hls.levels[hls.loadLevel];\n    if (minLevel?.bitrate < autoLevel?.bitrate) {\n      return minAutoLevel;\n    }\n    // or if bitrate is not lower, continue to use loadLevel\n    return hls.loadLevel;\n  }\n\n  private getStarvationDelay(): number {\n    const hls = this.hls;\n    const media = hls.media;\n    if (!media) {\n      return Infinity;\n    }\n    // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as\n    // if we're playing back at the normal rate.\n    const playbackRate =\n      media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;\n    const bufferInfo = hls.mainForwardBufferInfo;\n    return (bufferInfo ? bufferInfo.len : 0) / playbackRate;\n  }\n\n  private getBwEstimate(): number {\n    return this.bwEstimator.canEstimate()\n      ? this.bwEstimator.getEstimate()\n      : this.hls.config.abrEwmaDefaultEstimate;\n  }\n\n  private findBestLevel(\n    currentBw: number,\n    minAutoLevel: number,\n    maxAutoLevel: number,\n    bufferStarvationDelay: number,\n    maxStarvationDelay: number,\n    bwFactor: number,\n    bwUpFactor: number,\n  ): number {\n    const maxFetchDuration: number = bufferStarvationDelay + maxStarvationDelay;\n    const lastLoadedFragLevel = this.lastLoadedFragLevel;\n    const selectionBaseLevel =\n      lastLoadedFragLevel === -1 ? this.hls.firstLevel : lastLoadedFragLevel;\n    const { fragCurrent, partCurrent } = this;\n    const { levels, allAudioTracks, loadLevel, config } = this.hls;\n    if (levels.length === 1) {\n      return 0;\n    }\n    const level: Level | undefined = levels[selectionBaseLevel];\n    const live = !!level?.details?.live;\n    const firstSelection = loadLevel === -1 || lastLoadedFragLevel === -1;\n    let currentCodecSet: string | undefined;\n    let currentVideoRange: VideoRange | undefined = 'SDR';\n    let currentFrameRate = level?.frameRate || 0;\n\n    const { audioPreference, videoPreference } = config;\n    const audioTracksByGroup =\n      this.audioTracksByGroup ||\n      (this.audioTracksByGroup = getAudioTracksByGroup(allAudioTracks));\n    if (firstSelection) {\n      if (this.firstSelection !== -1) {\n        return this.firstSelection;\n      }\n      const codecTiers =\n        this.codecTiers ||\n        (this.codecTiers = getCodecTiers(\n          levels,\n          audioTracksByGroup,\n          minAutoLevel,\n          maxAutoLevel,\n        ));\n      const startTier = getStartCodecTier(\n        codecTiers,\n        currentVideoRange,\n        currentBw,\n        audioPreference,\n        videoPreference,\n      );\n      const { codecSet, videoRanges, minFramerate, minBitrate, preferHDR } =\n        startTier;\n      currentCodecSet = codecSet;\n      currentVideoRange = preferHDR\n        ? videoRanges[videoRanges.length - 1]\n        : videoRanges[0];\n      currentFrameRate = minFramerate;\n      currentBw = Math.max(currentBw, minBitrate);\n      logger.log(`[abr] picked start tier ${JSON.stringify(startTier)}`);\n    } else {\n      currentCodecSet = level?.codecSet;\n      currentVideoRange = level?.videoRange;\n    }\n\n    const currentFragDuration = partCurrent\n      ? partCurrent.duration\n      : fragCurrent\n        ? fragCurrent.duration\n        : 0;\n\n    const ttfbEstimateSec = this.bwEstimator.getEstimateTTFB() / 1000;\n    const levelsSkipped: number[] = [];\n    for (let i = maxAutoLevel; i >= minAutoLevel; i--) {\n      const levelInfo = levels[i];\n      const upSwitch = i > selectionBaseLevel;\n      if (!levelInfo) {\n        continue;\n      }\n      if (\n        __USE_MEDIA_CAPABILITIES__ &&\n        config.useMediaCapabilities &&\n        !levelInfo.supportedResult &&\n        !levelInfo.supportedPromise\n      ) {\n        const mediaCapabilities = navigator.mediaCapabilities as\n          | MediaCapabilities\n          | undefined;\n        if (\n          typeof mediaCapabilities?.decodingInfo === 'function' &&\n          requiresMediaCapabilitiesDecodingInfo(\n            levelInfo,\n            audioTracksByGroup,\n            currentVideoRange,\n            currentFrameRate,\n            currentBw,\n            audioPreference,\n          )\n        ) {\n          levelInfo.supportedPromise = getMediaDecodingInfoPromise(\n            levelInfo,\n            audioTracksByGroup,\n            mediaCapabilities,\n          );\n          levelInfo.supportedPromise.then((decodingInfo) => {\n            if (!this.hls) {\n              return;\n            }\n            levelInfo.supportedResult = decodingInfo;\n            const levels = this.hls.levels;\n            const index = levels.indexOf(levelInfo);\n            if (decodingInfo.error) {\n              logger.warn(\n                `[abr] MediaCapabilities decodingInfo error: \"${\n                  decodingInfo.error\n                }\" for level ${index} ${JSON.stringify(decodingInfo)}`,\n              );\n            } else if (!decodingInfo.supported) {\n              logger.warn(\n                `[abr] Unsupported MediaCapabilities decodingInfo result for level ${index} ${JSON.stringify(\n                  decodingInfo,\n                )}`,\n              );\n              if (index > -1 && levels.length > 1) {\n                logger.log(`[abr] Removing unsupported level ${index}`);\n                this.hls.removeLevel(index);\n              }\n            }\n          });\n        } else {\n          levelInfo.supportedResult = SUPPORTED_INFO_DEFAULT;\n        }\n      }\n\n      // skip candidates which change codec-family or video-range,\n      // and which decrease or increase frame-rate for up and down-switch respectfully\n      if (\n        (currentCodecSet && levelInfo.codecSet !== currentCodecSet) ||\n        (currentVideoRange && levelInfo.videoRange !== currentVideoRange) ||\n        (upSwitch && currentFrameRate > levelInfo.frameRate) ||\n        (!upSwitch &&\n          currentFrameRate > 0 &&\n          currentFrameRate < levelInfo.frameRate) ||\n        (levelInfo.supportedResult &&\n          !levelInfo.supportedResult.decodingInfoResults?.[0].smooth)\n      ) {\n        levelsSkipped.push(i);\n        continue;\n      }\n\n      const levelDetails = levelInfo.details;\n      const avgDuration =\n        (partCurrent\n          ? levelDetails?.partTarget\n          : levelDetails?.averagetargetduration) || currentFragDuration;\n\n      let adjustedbw: number;\n      // follow algorithm captured from stagefright :\n      // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\n      // Pick the highest bandwidth stream below or equal to estimated bandwidth.\n      // consider only 80% of the available bandwidth, but if we are switching up,\n      // be even more conservative (70%) to avoid overestimating and immediately\n      // switching back.\n      if (!upSwitch) {\n        adjustedbw = bwFactor * currentBw;\n      } else {\n        adjustedbw = bwUpFactor * currentBw;\n      }\n\n      // Use average bitrate when starvation delay (buffer length) is gt or eq two segment durations and rebuffering is not expected (maxStarvationDelay > 0)\n      const bitrate: number =\n        currentFragDuration &&\n        bufferStarvationDelay >= currentFragDuration * 2 &&\n        maxStarvationDelay === 0\n          ? levels[i].averageBitrate\n          : levels[i].maxBitrate;\n      const fetchDuration: number = this.getTimeToLoadFrag(\n        ttfbEstimateSec,\n        adjustedbw,\n        bitrate * avgDuration,\n        levelDetails === undefined,\n      );\n\n      const canSwitchWithinTolerance =\n        // if adjusted bw is greater than level bitrate AND\n        adjustedbw >= bitrate &&\n        // no level change, or new level has no error history\n        (i === lastLoadedFragLevel ||\n          (levelInfo.loadError === 0 && levelInfo.fragmentError === 0)) &&\n        // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\n        // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\n        // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1\n        (fetchDuration <= ttfbEstimateSec ||\n          !Number.isFinite(fetchDuration) ||\n          (live && !this.bitrateTestDelay) ||\n          fetchDuration < maxFetchDuration);\n      if (canSwitchWithinTolerance) {\n        const forcedAutoLevel = this.forcedAutoLevel;\n        if (\n          i !== loadLevel &&\n          (forcedAutoLevel === -1 || forcedAutoLevel !== loadLevel)\n        ) {\n          if (levelsSkipped.length) {\n            logger.trace(\n              `[abr] Skipped level(s) ${levelsSkipped.join(\n                ',',\n              )} of ${maxAutoLevel} max with CODECS and VIDEO-RANGE:\"${\n                levels[levelsSkipped[0]].codecs\n              }\" ${levels[levelsSkipped[0]].videoRange}; not compatible with \"${\n                level.codecs\n              }\" ${currentVideoRange}`,\n            );\n          }\n          logger.info(\n            `[abr] switch candidate:${selectionBaseLevel}->${i} adjustedbw(${Math.round(\n              adjustedbw,\n            )})-bitrate=${Math.round(\n              adjustedbw - bitrate,\n            )} ttfb:${ttfbEstimateSec.toFixed(\n              1,\n            )} avgDuration:${avgDuration.toFixed(\n              1,\n            )} maxFetchDuration:${maxFetchDuration.toFixed(\n              1,\n            )} fetchDuration:${fetchDuration.toFixed(\n              1,\n            )} firstSelection:${firstSelection} codecSet:${currentCodecSet} videoRange:${currentVideoRange} hls.loadLevel:${loadLevel}`,\n          );\n        }\n        if (firstSelection) {\n          this.firstSelection = i;\n        }\n        // as we are looping from highest to lowest, this will return the best achievable quality level\n        return i;\n      }\n    }\n    // not enough time budget even with quality level 0 ... rebuffering might happen\n    return -1;\n  }\n\n  public set nextAutoLevel(nextLevel: number) {\n    const { maxAutoLevel, minAutoLevel } = this.hls;\n    const value = Math.min(Math.max(nextLevel, minAutoLevel), maxAutoLevel);\n    if (this._nextAutoLevel !== value) {\n      this.nextAutoLevelKey = '';\n      this._nextAutoLevel = value;\n    }\n  }\n}\n\nexport default AbrController;\n","/**\n * @ignore\n * Sub-class specialization of EventHandler base class.\n *\n * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,\n * scheduled asynchroneously, avoiding recursive calls in the same tick.\n *\n * The task itself is implemented in `doTick`. It can be requested and called for single execution\n * using the `tick` method.\n *\n * It will be assured that the task execution method (`tick`) only gets called once per main loop \"tick\",\n * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.\n *\n * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,\n * and cancelled with `clearNextTick`.\n *\n * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).\n *\n * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.\n *\n * Further explanations:\n *\n * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously\n * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.\n *\n * When the task execution (`tick` method) is called in re-entrant way this is detected and\n * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further\n * task processing on the next main loop iteration (also known as \"next tick\" in the Node/JS runtime lingo).\n */\nexport default class TaskLoop {\n  private readonly _boundTick: () => void;\n  private _tickTimer: number | null = null;\n  private _tickInterval: number | null = null;\n  private _tickCallCount = 0;\n\n  constructor() {\n    this._boundTick = this.tick.bind(this);\n  }\n\n  public destroy() {\n    this.onHandlerDestroying();\n    this.onHandlerDestroyed();\n  }\n\n  protected onHandlerDestroying() {\n    // clear all timers before unregistering from event bus\n    this.clearNextTick();\n    this.clearInterval();\n  }\n\n  protected onHandlerDestroyed() {}\n\n  public hasInterval(): boolean {\n    return !!this._tickInterval;\n  }\n\n  public hasNextTick(): boolean {\n    return !!this._tickTimer;\n  }\n\n  /**\n   * @param millis - Interval time (ms)\n   * @eturns True when interval has been scheduled, false when already scheduled (no effect)\n   */\n  public setInte